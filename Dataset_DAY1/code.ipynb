{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"/Users/andreasalinetti/Documents/HACK4SDS/Dataset_DAY1/Data/train_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='external_score_ver03', hue= 'juridical_form', data= train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Plot the distribution using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_dataset, x='external_score_ver03')\n",
    "plt.xlabel('Category Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of external_score_ver03')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Clean and encode Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features\n",
    "def Drop_unneed_columns(test, dataset):\n",
    "    cols= ['days_to_default', 'application_ID', 'decision_date', 'company_ID']\n",
    "    if test:\n",
    "        cols.remove('days_to_default')\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    else:\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find columns with to many Nan's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_values(dataset):\n",
    "    column_names = dataset.columns.tolist()\n",
    "    drop_columns = []\n",
    "    for name in column_names:\n",
    "        nan_count = dataset[name].isna().sum()\n",
    "        print(f\"column {name}: {nan_count}\")\n",
    "        if (nan_count/28000) > 0.5:\n",
    "            print(f\"Number of NaN values in column '{name}': {nan_count}\")\n",
    "            drop_columns.append(name)\n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_cate_to_value(column_name, dataset):\n",
    "    # Extract categories\n",
    "\n",
    "    # Extract unique category names from the column\n",
    "    unique_categories = dataset[column_name].unique()\n",
    "\n",
    "    # convert 'numpy.ndarray' in to a python list\n",
    "    l = unique_categories.tolist()\n",
    "    \n",
    "    if 'MISSING' in l:\n",
    "        l.remove('MISSING')\n",
    "        l.sort(reverse=True)\n",
    "    # print(unique_categories)\n",
    "\n",
    "    # print(f\"remove{l}\")\n",
    "    dic = { l[i]:i+1 for i in range(0, len(l))}\n",
    "\n",
    "    # dic = {}\n",
    "\n",
    "    # for name in unique_categories:\n",
    "    #     if name != \"MISSING\":\n",
    "    #         dic{}\n",
    "    # print(dic)\n",
    "\n",
    "    # Replace values in the column based on the dictionary mapping\n",
    "    dataset[column_name] = dataset[column_name].replace(dic)\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Category_values(dataset):\n",
    "    column_names = ['industry_sector', 'region', 'geo_area','external_score_ver03', 'province','juridical_form']\n",
    "    dic = {}\n",
    "    for column_name in column_names:\n",
    "        category_dic, dataset = Replace_cate_to_value(column_name, dataset)\n",
    "        dic[column_name] = category_dic\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace True and False values to numerical values in Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_bool_toNumbers(dataset):\n",
    "    dataset['cr_available'] = [int(dataset['cr_available'][i]) for i in range(len(dataset['cr_available']))]\n",
    "    dataset['cr_available']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of external score var 03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var03(dataset):\n",
    "    s0, s1, c0, c1 = 0,0,0,0\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row['external_score_ver03'] != 'MISSING':\n",
    "            if row['target'] == 0:\n",
    "                s0 += row['external_score_ver03']\n",
    "                c0 +=1\n",
    "            elif row['target'] == 1:\n",
    "                s1 +=  row['external_score_ver03']\n",
    "                c1 += 1\n",
    "\n",
    "    m0 = round(s0/c0)\n",
    "    m1 = round(s1/c1)\n",
    "    print(m0)\n",
    "    print(m1)\n",
    "    return m0,m1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace MISSING values to Mean finded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing(dataset, m0, m1):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset['target'] == 1) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m1\n",
    "    dataset.loc[(dataset['target'] == 0) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m0\n",
    "    dataset['external_score_ver03']\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Main code for train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns \n",
    "train_dataset = Drop_unneed_columns(False,train_dataset)\n",
    "drop_columns = Nan_values(train_dataset)\n",
    "train_dataset = train_dataset.drop(columns=drop_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace bool values to numerical ones \n",
    "category_dics, train_dataset = Category_values(train_dataset)\n",
    "train_dataset = Replace_bool_toNumbers(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# v03 column with missing values \n",
    "m0, m1= mean_var03(train_dataset)\n",
    "train_dataset = Replace_missing(train_dataset, m0, m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Normalise Datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the \",\" to \".\", in such a way to pass from object to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Main code Normalise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = normalized_data(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Build a Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_dataframe_by_label(df, label_column, label_value_1, label_value_2, sample_size):\n",
    "    # Separate the DataFrame based on the labels\n",
    "    subset_1 = df[df[label_column] == label_value_1]\n",
    "    subset_2 = df[df[label_column] == label_value_2]\n",
    "    \n",
    "    # Take a random sample of rows from each subset\n",
    "    subset_1_sampled = subset_1.sample(n=sample_size, random_state=42)\n",
    "    subset_2_sampled = subset_2.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Concatenate the sampled subsets to form the final split\n",
    "    final_split = pd.concat([subset_1_sampled, subset_2_sampled], ignore_index=True)\n",
    "\n",
    "    return final_split\n",
    "\n",
    "train_dataset = split_dataframe_by_label(train_dataset, 'target', 0, 1, 6894)\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = train_dataset['target']\n",
    "\n",
    "# Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_dataset.drop(columns='target'))\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=30)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca,Y, test_size=0.1, stratify=Y, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# classifier = svm.SVC(C=0.1 ,kernel='linear', gamma=0.001, class_weight=\"balanced\")\n",
    "classifier = svm.SVC(C=0.1, kernel='linear', gamma='scale', class_weight='balanced', verbose=True)\n",
    "\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_prediction = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming classifier is your trained SVM model and X_test, y_test are your test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Split the dataset into features (X) and target variable (y)\n",
    "X = train_dataset.drop(columns=['target'])  # Assuming 'target_column' is your target variable\n",
    "y = train_dataset['target']\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 4: Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Compute the F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = train_dataset.drop(columns=['target'])  # Assuming 'target' is your target variable\n",
    "y = train_dataset['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "gnb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = gnb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Create the Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Perform 5-fold cross-validation\n",
    "cv_scores = cross_val_score(gnb_classifier, X, y, cv=5)\n",
    "\n",
    "# Print the cross-validation scores\n",
    "print(\"Cross-validation Scores:\", cv_scores)\n",
    "\n",
    "# Calculate and print the mean cross-validation score\n",
    "mean_cv_score = cv_scores.mean()\n",
    "print(\"Mean Cross-validation Score:\", mean_cv_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "# Split the dataset into features (X) and target variable (y)\n",
    "X = train_dataset.drop(columns=['target'])  # Assuming 'target' is your target variable\n",
    "y = train_dataset['target']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Perform feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Perform feature selection\n",
    "selector = SelectKBest(score_func=f_classif, k=39)  # Select top 20 features\n",
    "X_train_selected = selector.fit_transform(X_train_scaled, y_train)\n",
    "X_test_selected = selector.transform(X_test_scaled)\n",
    "\n",
    "# Create the Gaussian Naive Bayes classifier\n",
    "gnb_classifier = GaussianNB()\n",
    "\n",
    "# Train the classifier on the selected features\n",
    "gnb_classifier.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on the testing data\n",
    "y_pred = gnb_classifier.predict(X_test_selected)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Compute the F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create KNN classifier\n",
    "k = 5  # Number of neighbors\n",
    "knn = KNeighborsClassifier(n_neighbors=k, weights='distance', algorithm='auto', metric='manhattan')\n",
    "\n",
    "# Train the classifier\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = knn.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f'Accuracy: {accuracy:.2f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Compute the F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Prima Neural Network "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the neural network architecture\n",
    "# class NeuralNetwork(nn.Module):\n",
    "#     def __init__(self, input_size):\n",
    "#         super(NeuralNetwork, self).__init__()\n",
    "#         self.fc1 = nn.Linear(input_size, 16)  \n",
    "#         self.fc2 = nn.Linear(16,8)\n",
    "#         self.relu = nn.ReLU()\n",
    "#         self.fc3 = nn.Linear(8, 1)\n",
    "#         self.dropout = nn.Dropout(p=0.2)\n",
    "#         self.fc4 = nn.Linear(8, 1)  # Output layer with 1 neuron for binary classification\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.fc1(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc2(x)\n",
    "#         x = self.relu(x)\n",
    "#         x = self.dropout(x)\n",
    "#         x = self.fc3(x)\n",
    "#         x = self.relu(x)\n",
    "#         #x = self.fc4(x)\n",
    "#         return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "# accuracy_values = []\n",
    "# loss_values = []\n",
    "# X = train_dataset.iloc[:, :-1].to_numpy()\n",
    "# y = train_dataset.iloc[:, -1].to_numpy()\n",
    "\n",
    "# num_folds = 5\n",
    "# input_size = 39\n",
    "# num_epochs = 40\n",
    "# num_models = 1\n",
    "\n",
    "# kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "# criterion = nn.BCELoss() \n",
    "# l1_lambda = 0.01\n",
    "# l2_lambda = 0.01\n",
    "# fold_params = []\n",
    "\n",
    "# for model_index in range(num_models):\n",
    "\n",
    "#     for fold, (train_indices, val_indices) in enumerate(kf.split(X)):\n",
    "#         print(f'Fold {fold+1}/{num_folds}')\n",
    "\n",
    "#         #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "#         # Split the data into training and validation sets\n",
    "#         X_train, X_val = X[train_indices], X[val_indices]\n",
    "#         y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "#         # Convert data to PyTorch tensors\n",
    "#         X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "#         y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "#         X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "#         y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "        \n",
    "#         model = NeuralNetwork(input_size)\n",
    "#         optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "#         # Train the neural network\n",
    "\n",
    "#         for epoch in range(num_epochs):\n",
    "#             # Forward pass\n",
    "#             outputs = model(X_train_tensor)\n",
    "#             loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "#             loss_values.append(loss.item())\n",
    "\n",
    "#             l1_reg = torch.tensor(0., requires_grad=True)\n",
    "#             for param in model.parameters():\n",
    "#                 l1_reg = l1_reg + torch.norm(param, p=1)\n",
    "#             loss = loss + l1_lambda * l1_reg\n",
    "\n",
    "#             # L2 regularization\n",
    "#             l2_reg = torch.tensor(0., requires_grad=True)\n",
    "#             for param in model.parameters():\n",
    "#                 l2_reg = l2_reg + torch.norm(param, p=2)\n",
    "#             loss = loss + l2_lambda * l2_reg\n",
    "            \n",
    "#             # Backward pass and optimization\n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "\n",
    "#         fold_params.append(model.state_dict())\n",
    "#         print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Fold:{fold}')\n",
    "\n",
    "#         # Evaluate the model\n",
    "#         with torch.no_grad():\n",
    "#             # Predict probabilities on the test set\n",
    "#             outputs = model(X_val_tensor)\n",
    "#             predicted = (outputs >= 0.5).float()\n",
    "            \n",
    "#             # Calculate accuracy\n",
    "#             accuracy = (predicted == y_val_tensor.view(-1, 1)).float().mean()\n",
    "#             accuracy_values.append(accuracy)\n",
    "#             print(f'Accuracy on test set: {accuracy.item()*100:.2f}%')\n",
    "#     torch.save(model.state_dict(), f'model_{model_index}.pth')\n",
    "\n",
    "# avg_params = {}\n",
    "\n",
    "# for key in fold_params[0].keys():\n",
    "#     avg_params[key] = torch.stack([params[key] for params in fold_params]).mean(dim=0)\n",
    "\n",
    "# # Create a new model with the average parameters\n",
    "# average_model = NeuralNetwork(input_size)\n",
    "# average_model.load_state_dict(avg_params)\n",
    "# print(f'Averagea ccuracy on test set: {np.array(accuracy_values).mean()*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Loss Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# # Plot the loss values\n",
    "# plt.plot(loss_values, label='Training Loss')\n",
    "# plt.xlabel('Epoch')\n",
    "# plt.ylabel('Loss')\n",
    "# plt.title('Training Loss Over Epochs')\n",
    "# plt.legend()\n",
    "# plt.grid(True)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.metrics import f1_score\n",
    "\n",
    "# true_labels = y_val_tensor.numpy().astype(int)\n",
    "# predicted_labels = 1-(predicted.numpy())\n",
    "# # Calculate F1 score\n",
    "# f1 = f1_score(true_labels, predicted_labels)\n",
    "# print(f'F1 score on test set: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"/Users/andreasalinetti/Documents/HACK4SDS/Dataset_DAY1/Data/test_set.csv\", delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns \n",
    "test_dataset = Drop_unneed_columns(True,test_dataset)\n",
    "\n",
    "test_dataset = test_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_dics[\"juridical_form\"][\"SS\"] = 15\n",
    "category_dics[\"juridical_form\"][\"OS\"] = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(category_dics[\"juridical_form\"])\n",
    "for k,v in category_dics.items():\n",
    "    test_dataset.replace({k:v}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns with MISSING values \n",
    "columns = []\n",
    "for column in list(test_dataset.columns):\n",
    "    # Check if there is a value \"MISSING\" in the 'column_name' column\n",
    "    missing_values = test_dataset[column] == 'MISSING'\n",
    "\n",
    "    # Check if any row contains the value \"MISSING\" in the specified column\n",
    "    if missing_values.any():\n",
    "        print(f\"'MISSING' in the column: {column}\")\n",
    "        columns.append(column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum values in the specified columns\n",
    "dic = {}\n",
    "for column in columns:\n",
    "    column_name = column\n",
    "\n",
    "    count = 0\n",
    "    sum_values = 0\n",
    "    # Iterate over the DataFrame\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        # Access the value of the specified column for each row\n",
    "        count +=1\n",
    "        if isinstance(row[column_name], str):\n",
    "            continue\n",
    "        elif isinstance(row[column_name], int):\n",
    "            sum_values += row[column_name]\n",
    "    \n",
    "    dic[column] = int(sum_values/count)\n",
    "\n",
    "print(dic)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing_test(dataset,val, column):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset[column] == 'MISSING'), column] = val\n",
    "\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dic.items():\n",
    "    test_dataset = Replace_missing_test(test_dataset,v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Replace_bool_toNumbers(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalise test dataset \n",
    "def normalized_tdata(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    # print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset\n",
    "test_dataset = normalized_tdata(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">SVM Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=30)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_pca,Y, test_size=0.1, stratify=Y, random_state=2)\n",
    "\n",
    "# print(X_train.shape, X_test.shape)\n",
    "\n",
    "# classifier = svm.SVC(C=0.1 ,kernel='linear', gamma=0.001, class_weight=\"balanced\")\n",
    "# classifier = svm.SVC(C=0.1, kernel='linear', gamma='scale', class_weight='balanced', verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = classifier.predict(X_pca)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_SVM = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_SVM.to_csv('predictions_SVM.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = rf_classifier.predict(X_scaled)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_RF = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_RF.to_csv('predictions_rf.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = gnb_classifier.predict(X_scaled)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_GNB = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_GNB.to_csv('predictions_gnb.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> KNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = knn.predict(X_scaled)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_KNN = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_KNN.to_csv('predictions_knn.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Voting Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = voting_classifier.predict(X_scaled)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_df = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions_voting.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.0048, 0.2641, 0.7179, 0.0131])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/n1/mmz1673950vccvt3z8vby3580000gn/T/ipykernel_35135/986956926.py:3: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  weights = F.softmax(torch.tensor([3.0,7.0,8.0,4.0]))\n"
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch\n",
    "weights = F.softmax(torch.tensor([3.0, 7.0, 8.0, 4.0]))\n",
    "print(weights)\n",
    "\n",
    "prediction_mean = ((0.18*(1-predictions_RF) + 0.28*predictions_KNN + 0.9*predictions_GNB + 0.4*(1-predictions_SVM))).astype(int)\n",
    "prediction_mean.to_csv('predictions_voting2.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export The CSV File"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
