{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"/Users/danielguarnizo/Desktop/HACK4SDS/Dataset_DAY1/Data/train_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ej2yjUAA</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>7256587870</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q2X00000ZWC5LUAX</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>6178307100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q2X00000XcCCQUA3</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>7692855390</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ejSs3UAE</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>5752241730</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000eiRidUAE</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>7533506540</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ej2yjUAA    2021-11-30  7256587870                    10   \n",
       "1  a1Q2X00000ZWC5LUAX    2020-10-06  6178307100                     7   \n",
       "2  a1Q2X00000XcCCQUA3    2020-02-11  7692855390                     7   \n",
       "3  a1Q7R00000ejSs3UAE    2022-01-18  5752241730                     8   \n",
       "4  a1Q7R00000eiRidUAE    2021-09-16  7533506540                     4   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     3                 NaN   \n",
       "1                     3                 NaN   \n",
       "2                     3                 NaN   \n",
       "3                     2                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     NaN                      NaN   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  ...  avg_count_enti_affidanti  \\\n",
       "0                     NaN              MISSING  ...                         1   \n",
       "1                     NaN                    H  ...                         1   \n",
       "2                     NaN              MISSING  ...                         1   \n",
       "3                     NaN              MISSING  ...                         1   \n",
       "4                     NaN              MISSING  ...                         0   \n",
       "\n",
       "  std_count_enti_affidanti max_count_enti_affidanti last_count_enti_affidanti  \\\n",
       "0                        0                        1                         1   \n",
       "1                        0                        1                         1   \n",
       "2                        0                        1                         1   \n",
       "3                        0                        1                         1   \n",
       "4                        0                        0                         0   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0                           0                           0   \n",
       "1                           2                           0   \n",
       "2                           1                           0   \n",
       "3                         0,5           0,522232967867094   \n",
       "4                           0                           0   \n",
       "\n",
       "  max_count_numero_prima_info last_count_numero_prima_info days_to_default  \\\n",
       "0                           0                            0             522   \n",
       "1                           2                            2            1498   \n",
       "2                           1                            1             779   \n",
       "3                           1                            0            1498   \n",
       "4                           0                            0            1498   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>age</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>4824.000000</td>\n",
       "      <td>4824.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.772040</td>\n",
       "      <td>1.942433</td>\n",
       "      <td>9.286532</td>\n",
       "      <td>5.891505</td>\n",
       "      <td>6.039594</td>\n",
       "      <td>6.168947</td>\n",
       "      <td>8.972715</td>\n",
       "      <td>1.824894</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>2.691964</td>\n",
       "      <td>1.146354</td>\n",
       "      <td>0.976773</td>\n",
       "      <td>1281.800356</td>\n",
       "      <td>0.215222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.764166</td>\n",
       "      <td>0.786342</td>\n",
       "      <td>2.760645</td>\n",
       "      <td>1.244978</td>\n",
       "      <td>1.302913</td>\n",
       "      <td>1.343487</td>\n",
       "      <td>9.003956</td>\n",
       "      <td>0.621009</td>\n",
       "      <td>3.321439</td>\n",
       "      <td>3.105271</td>\n",
       "      <td>1.494643</td>\n",
       "      <td>1.314287</td>\n",
       "      <td>426.997217</td>\n",
       "      <td>0.410983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       external_score_ver01  external_score_ver02  late_payment_score  \\\n",
       "count          32032.000000          32032.000000         4544.000000   \n",
       "mean               6.772040              1.942433            9.286532   \n",
       "std                1.764166              0.786342            2.760645   \n",
       "min                2.000000              1.000000            1.000000   \n",
       "25%                6.000000              1.000000            7.000000   \n",
       "50%                6.000000              2.000000            9.000000   \n",
       "75%                8.000000              3.000000           10.000000   \n",
       "max               10.000000              3.000000           20.000000   \n",
       "\n",
       "       external_score_late_payment_integrated  external_score_moderate  \\\n",
       "count                             4544.000000              4824.000000   \n",
       "mean                                 5.891505                 6.039594   \n",
       "std                                  1.244978                 1.302913   \n",
       "min                                  2.000000                 2.000000   \n",
       "25%                                  5.000000                 5.000000   \n",
       "50%                                  6.000000                 6.000000   \n",
       "75%                                  7.000000                 7.000000   \n",
       "max                                 10.000000                10.000000   \n",
       "\n",
       "       external_score_adverse           age  last_statement_age  \\\n",
       "count             4824.000000  32032.000000        32032.000000   \n",
       "mean                 6.168947      8.972715            1.824894   \n",
       "std                  1.343487      9.003956            0.621009   \n",
       "min                  2.000000      0.000000            0.000000   \n",
       "25%                  5.000000      3.000000            1.000000   \n",
       "50%                  6.000000      6.000000            2.000000   \n",
       "75%                  7.000000     11.000000            2.000000   \n",
       "max                 10.000000    106.000000            7.000000   \n",
       "\n",
       "       max_count_enti_affidanti  last_count_enti_affidanti  \\\n",
       "count              32032.000000               32032.000000   \n",
       "mean                   2.928571                   2.691964   \n",
       "std                    3.321439                   3.105271   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    1.000000                   1.000000   \n",
       "50%                    2.000000                   2.000000   \n",
       "75%                    4.000000                   4.000000   \n",
       "max                   50.000000                  45.000000   \n",
       "\n",
       "       max_count_numero_prima_info  last_count_numero_prima_info  \\\n",
       "count                 32032.000000                  32032.000000   \n",
       "mean                      1.146354                      0.976773   \n",
       "std                       1.494643                      1.314287   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       1.000000                      1.000000   \n",
       "75%                       2.000000                      1.000000   \n",
       "max                      12.000000                     12.000000   \n",
       "\n",
       "       days_to_default        target  \n",
       "count     32032.000000  32032.000000  \n",
       "mean       1281.800356      0.215222  \n",
       "std         426.997217      0.410983  \n",
       "min           1.000000      0.000000  \n",
       "25%        1498.000000      0.000000  \n",
       "50%        1498.000000      0.000000  \n",
       "75%        1498.000000      0.000000  \n",
       "max        1498.000000      1.000000  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='external_score_ver03', ylabel='count'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='external_score_ver03', hue= 'juridical_form', data= train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Plot the distribution using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_dataset, x='external_score_ver03')\n",
    "plt.xlabel('Category Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of external_score_ver03')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Clean and encode Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features\n",
    "def Drop_unneed_columns(test, dataset):\n",
    "    cols= ['days_to_default', 'application_ID', 'decision_date', 'company_ID']\n",
    "    if test:\n",
    "        cols.remove('days_to_default')\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    else:\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find columns with to many Nan's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_values(dataset):\n",
    "    column_names = dataset.columns.tolist()\n",
    "    drop_columns = []\n",
    "    for name in column_names:\n",
    "        nan_count = dataset[name].isna().sum()\n",
    "        print(f\"column {name}: {nan_count}\")\n",
    "        if (nan_count/28000) > 0.5:\n",
    "            print(f\"Number of NaN values in column '{name}': {nan_count}\")\n",
    "            drop_columns.append(name)\n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_cate_to_value(column_name, dataset):\n",
    "    # Extract categories\n",
    "\n",
    "    # Extract unique category names from the column\n",
    "    unique_categories = dataset[column_name].unique()\n",
    "\n",
    "    # convert 'numpy.ndarray' in to a python list\n",
    "    l = unique_categories.tolist()\n",
    "    \n",
    "    if 'MISSING' in l:\n",
    "        l.remove('MISSING')\n",
    "        l.sort(reverse=True)\n",
    "    # print(unique_categories)\n",
    "\n",
    "    # print(f\"remove{l}\")\n",
    "    dic = { l[i]:i+1 for i in range(0, len(l))}\n",
    "\n",
    "    # dic = {}\n",
    "\n",
    "    # for name in unique_categories:\n",
    "    #     if name != \"MISSING\":\n",
    "    #         dic{}\n",
    "    # print(dic)\n",
    "\n",
    "    # Replace values in the column based on the dictionary mapping\n",
    "    dataset[column_name] = dataset[column_name].replace(dic)\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Category_values(dataset):\n",
    "    column_names = ['industry_sector', 'region', 'geo_area','external_score_ver03', 'province','juridical_form']\n",
    "    dic = {}\n",
    "    for column_name in column_names:\n",
    "        category_dic, dataset = Replace_cate_to_value(column_name, dataset)\n",
    "        dic[column_name] = category_dic\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace True and False values to numerical values in Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_bool_toNumbers(dataset):\n",
    "    dataset['cr_available'] = [int(dataset['cr_available'][i]) for i in range(len(dataset['cr_available']))]\n",
    "    dataset['cr_available']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of external score var 03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var03(dataset):\n",
    "    s0, s1, c0, c1 = 0,0,0,0\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row['external_score_ver03'] != 'MISSING':\n",
    "            if row['target'] == 0:\n",
    "                s0 += row['external_score_ver03']\n",
    "                c0 +=1\n",
    "            elif row['target'] == 1:\n",
    "                s1 +=  row['external_score_ver03']\n",
    "                c1 += 1\n",
    "\n",
    "    m0 = round(s0/c0)\n",
    "    m1 = round(s1/c1)\n",
    "    print(m0)\n",
    "    print(m1)\n",
    "    return m0,m1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace MISSING values to Mean finded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing(dataset, m0, m1):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset['target'] == 1) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m1\n",
    "    dataset.loc[(dataset['target'] == 0) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m0\n",
    "    dataset['external_score_ver03']\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Main code for train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column external_score_ver01: 0\n",
      "column external_score_ver02: 0\n",
      "column late_payment_score: 27488\n",
      "Number of NaN values in column 'late_payment_score': 27488\n",
      "column external_score_late_payment_integrated: 27488\n",
      "Number of NaN values in column 'external_score_late_payment_integrated': 27488\n",
      "column external_score_moderate: 27208\n",
      "Number of NaN values in column 'external_score_moderate': 27208\n",
      "column external_score_adverse: 27208\n",
      "Number of NaN values in column 'external_score_adverse': 27208\n",
      "column external_score_ver03: 0\n",
      "column age: 0\n",
      "column province: 2654\n",
      "column juridical_form: 0\n",
      "column industry_sector: 0\n",
      "column gross_margin_ratio: 0\n",
      "column core_income_ratio: 0\n",
      "column cash_asset_ratio: 0\n",
      "column consolidated_liabilities_ratio: 0\n",
      "column tangible_assets_ratio: 0\n",
      "column revenues: 0\n",
      "column cr_available: 0\n",
      "column region: 0\n",
      "column geo_area: 0\n",
      "column last_statement_age: 0\n",
      "column overrun_freq_a_revoca_autoliquidanti: 0\n",
      "column avg_tension_a_revoca_autoliquidanti: 0\n",
      "column std_tension_a_revoca_autoliquidanti: 0\n",
      "column max_tension_a_revoca_autoliquidanti: 0\n",
      "column last_tension_a_revoca_autoliquidanti: 0\n",
      "column avg_rel_used_a_revoca_autoliquidanti: 0\n",
      "column std_rel_used_a_revoca_autoliquidanti: 0\n",
      "column max_rel_used_a_revoca_autoliquidanti: 0\n",
      "column last_rel_used_a_revoca_autoliquidanti: 0\n",
      "column overrun_freq_a_scadenza: 0\n",
      "column avg_rel_used_a_scadenza: 0\n",
      "column std_rel_used_a_scadenza: 0\n",
      "column max_rel_used_a_scadenza: 0\n",
      "column last_rel_used_a_scadenza: 0\n",
      "column avg_count_enti_affidanti: 0\n",
      "column std_count_enti_affidanti: 0\n",
      "column max_count_enti_affidanti: 0\n",
      "column last_count_enti_affidanti: 0\n",
      "column avg_count_numero_prima_info: 0\n",
      "column std_count_numero_prima_info: 0\n",
      "column max_count_numero_prima_info: 0\n",
      "column last_count_numero_prima_info: 0\n",
      "column target: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop columns \n",
    "train_dataset = Drop_unneed_columns(False,train_dataset)\n",
    "drop_columns = Nan_values(train_dataset)\n",
    "train_dataset = train_dataset.drop(columns=drop_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_5651/238755991.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[column_name] = dataset[column_name].replace(dic)\n"
     ]
    }
   ],
   "source": [
    "# replace bool values to numerical ones \n",
    "category_dics, train_dataset = Category_values(train_dataset)\n",
    "train_dataset = Replace_bool_toNumbers(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# v03 column with missing values \n",
    "m0, m1= mean_var03(train_dataset)\n",
    "train_dataset = Replace_missing(train_dataset, m0, m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Normalise Datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the \",\" to \".\", in such a way to pass from object to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Main code Normalise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                  int64\n",
      "juridical_form                            int64\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                    int64\n",
      "geo_area                                  int64\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "target                                    int64\n",
      "dtype: object\n",
      "DataFrame does not contain any NaN values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_5651/2113528616.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset = dataset.replace(',', '.', regex=True)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = normalized_data(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.176975</td>\n",
       "      <td>2.111932e-03</td>\n",
       "      <td>0.179073</td>\n",
       "      <td>0.172032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151754</td>\n",
       "      <td>6.806286e-03</td>\n",
       "      <td>0.164755</td>\n",
       "      <td>0.146385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.136150</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>598.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>2.619898e-02</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.673177</td>\n",
       "      <td>0.026609</td>\n",
       "      <td>0.192248</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.060680</td>\n",
       "      <td>3.722236e-02</td>\n",
       "      <td>0.146051</td>\n",
       "      <td>0.146051</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.307391</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.080271</td>\n",
       "      <td>0.157611</td>\n",
       "      <td>0.843066</td>\n",
       "      <td>12209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458545</td>\n",
       "      <td>0.248584</td>\n",
       "      <td>0.790275</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>0.027610</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>2.002530e-02</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.037795</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.457291</td>\n",
       "      <td>0.068892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>43775.539062</td>\n",
       "      <td>151643.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>4.360371e-04</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.221461</td>\n",
       "      <td>-0.045290</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.715017</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.153680</td>\n",
       "      <td>0.132710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701977</td>\n",
       "      <td>0.145203</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.670731</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>0.064536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041406</td>\n",
       "      <td>1.724269e-02</td>\n",
       "      <td>0.059721</td>\n",
       "      <td>0.055987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.502591</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.676364</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>5.174890e-02</td>\n",
       "      <td>0.229672</td>\n",
       "      <td>0.214628</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1.083625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>0.034757</td>\n",
       "      <td>0.216390</td>\n",
       "      <td>0.423127</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642653</td>\n",
       "      <td>0.159023</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>0.615092</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.047999</td>\n",
       "      <td>0.259955</td>\n",
       "      <td>0.187009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234372</td>\n",
       "      <td>5.594047e-02</td>\n",
       "      <td>0.285388</td>\n",
       "      <td>0.265908</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>-0.095941</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.126657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>6.285652e-03</td>\n",
       "      <td>0.358538</td>\n",
       "      <td>0.339361</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.361522</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.284884</td>\n",
       "      <td>0.072614</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396210</td>\n",
       "      <td>0.120278</td>\n",
       "      <td>0.609917</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.039988</td>\n",
       "      <td>0.201627</td>\n",
       "      <td>0.097028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182228</td>\n",
       "      <td>1.410236e-02</td>\n",
       "      <td>0.210419</td>\n",
       "      <td>0.176218</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.501767</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.323009</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>2.898975e-17</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.335260</td>\n",
       "      <td>0.066454</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>0.554913</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169214</td>\n",
       "      <td>0.255193</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081779</td>\n",
       "      <td>1.744957e-02</td>\n",
       "      <td>0.095847</td>\n",
       "      <td>0.095847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.447154</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332279</td>\n",
       "      <td>0.171461</td>\n",
       "      <td>0.658733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634728</td>\n",
       "      <td>7.677177e-02</td>\n",
       "      <td>0.746165</td>\n",
       "      <td>0.746165</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>913.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>2.430452e-02</td>\n",
       "      <td>0.049733</td>\n",
       "      <td>0.048723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.961410</td>\n",
       "      <td>0.166273</td>\n",
       "      <td>1.179400</td>\n",
       "      <td>1.172486</td>\n",
       "      <td>0.074173</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>1.291411e-02</td>\n",
       "      <td>0.092295</td>\n",
       "      <td>0.083193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325444</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177833</td>\n",
       "      <td>0.330063</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266932</td>\n",
       "      <td>6.039229e-03</td>\n",
       "      <td>0.286109</td>\n",
       "      <td>0.286109</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486056</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.422311</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051943</td>\n",
       "      <td>0.053098</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>1.210318e-02</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.229962</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>2.898975e-17</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.167748</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.478309</td>\n",
       "      <td>-0.066730</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.389321</td>\n",
       "      <td>0.109012</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.061643</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.747864e-03</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.419901</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.085131</td>\n",
       "      <td>0.240817</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.031521</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>1.642027e-03</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.129804</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.046128</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>1.114067</td>\n",
       "      <td>1.006933</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180244</td>\n",
       "      <td>3.767771e-02</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.218543</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.420786</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.093870</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.867331</td>\n",
       "      <td>0.073822</td>\n",
       "      <td>0.967480</td>\n",
       "      <td>0.936377</td>\n",
       "      <td>0.290532</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.332647</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252414</td>\n",
       "      <td>4.928930e-02</td>\n",
       "      <td>0.393825</td>\n",
       "      <td>0.393825</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>1.240112</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.029857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    external_score_ver01  external_score_ver02  external_score_ver03   age  \\\n",
       "0                   10.0                   3.0                  10.0  15.0   \n",
       "1                    7.0                   3.0                   7.0   5.0   \n",
       "2                    7.0                   3.0                  10.0   5.0   \n",
       "3                    8.0                   2.0                   8.0   6.0   \n",
       "4                    4.0                   1.0                   8.0   5.0   \n",
       "5                    6.0                   1.0                  12.0   2.0   \n",
       "6                    7.0                   3.0                  10.0   3.0   \n",
       "7                    6.0                   1.0                  10.0   9.0   \n",
       "8                   10.0                   3.0                  10.0   2.0   \n",
       "9                    7.0                   2.0                   8.0  12.0   \n",
       "10                  10.0                   2.0                   7.0   0.0   \n",
       "11                   5.0                   2.0                   9.0   6.0   \n",
       "12                   6.0                   2.0                   8.0   8.0   \n",
       "13                   6.0                   1.0                   8.0  14.0   \n",
       "14                   5.0                   3.0                   8.0   6.0   \n",
       "15                   6.0                   1.0                  10.0  17.0   \n",
       "16                   6.0                   1.0                  10.0   6.0   \n",
       "17                   4.0                   2.0                   9.0   2.0   \n",
       "18                   8.0                   2.0                  11.0   3.0   \n",
       "19                   8.0                   2.0                  10.0   5.0   \n",
       "20                   7.0                   2.0                   6.0   7.0   \n",
       "21                  10.0                   2.0                  11.0   5.0   \n",
       "22                   6.0                   3.0                  10.0  11.0   \n",
       "23                   4.0                   2.0                   4.0  11.0   \n",
       "24                   8.0                   2.0                   5.0   7.0   \n",
       "25                   6.0                   1.0                   8.0   2.0   \n",
       "26                   5.0                   1.0                   7.0  21.0   \n",
       "27                  10.0                   3.0                  14.0   6.0   \n",
       "28                   7.0                   2.0                   7.0   2.0   \n",
       "29                   8.0                   1.0                   9.0   6.0   \n",
       "\n",
       "    province  juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0        1.0             1.0              1.0            0.464637   \n",
       "1        2.0             2.0              2.0            0.372340   \n",
       "2        3.0             1.0              3.0            0.270000   \n",
       "3        4.0             1.0              1.0            0.419929   \n",
       "4        5.0             1.0              1.0            0.526316   \n",
       "5        6.0             1.0              4.0            0.673177   \n",
       "6        7.0             2.0              1.0            1.666667   \n",
       "7        8.0             1.0              5.0            0.307391   \n",
       "8        9.0             1.0              2.0            0.457291   \n",
       "9       10.0             3.0              6.0            0.221461   \n",
       "10      11.0             1.0              1.0            0.464637   \n",
       "11      12.0             3.0              1.0            0.084112   \n",
       "12      13.0             4.0              4.0            0.502591   \n",
       "13       5.0             1.0              1.0            0.356986   \n",
       "14       4.0             1.0              1.0            0.187500   \n",
       "15      14.0             1.0              7.0            0.361522   \n",
       "16      15.0             1.0              8.0            0.501767   \n",
       "17      16.0             1.0              2.0            0.335260   \n",
       "18      17.0             1.0              1.0            0.060606   \n",
       "19      18.0             1.0              1.0           -0.045024   \n",
       "20       8.0             1.0              2.0            0.255639   \n",
       "21       6.0             1.0              1.0            0.464637   \n",
       "22       4.0             1.0              2.0            0.325444   \n",
       "23      19.0             1.0              1.0            0.486056   \n",
       "24       4.0             1.0              3.0            0.229962   \n",
       "25      20.0             1.0              9.0            0.478309   \n",
       "26       6.0             3.0              2.0            0.408955   \n",
       "27      21.0             4.0              1.0            0.464637   \n",
       "28       8.0             1.0              4.0            0.463576   \n",
       "29       6.0             1.0             10.0            0.420786   \n",
       "\n",
       "    core_income_ratio  cash_asset_ratio  consolidated_liabilities_ratio  \\\n",
       "0            0.012593          0.000000                        0.416002   \n",
       "1            0.115385          0.235955                        0.484043   \n",
       "2            0.006369          0.359375                        0.125000   \n",
       "3            0.152174          0.136150                        0.765125   \n",
       "4            0.083333          0.233333                        0.197368   \n",
       "5            0.026609          0.192248                        0.252604   \n",
       "6            0.017544          0.615385                        0.277778   \n",
       "7            0.010648          0.080271                        0.157611   \n",
       "8            0.068892          0.000000                        0.369089   \n",
       "9           -0.045290          0.051724                        0.081050   \n",
       "10           0.012593          0.000000                        0.416002   \n",
       "11           0.015926          0.153680                        0.132710   \n",
       "12           0.058766          0.154930                        0.465026   \n",
       "13           0.034757          0.216390                        0.423127   \n",
       "14          -0.095941          0.092308                        0.122159   \n",
       "15           0.007576          0.107092                        0.284884   \n",
       "16           0.030769          0.323009                        0.084806   \n",
       "17           0.066454          0.406977                        0.554913   \n",
       "18           0.021978          0.306452                        0.045455   \n",
       "19          -0.447154          0.188889                        0.146919   \n",
       "20           0.019715          0.210938                        0.413534   \n",
       "21           0.012593          0.000000                        0.416002   \n",
       "22           0.046025          0.116788                        0.544379   \n",
       "23           0.057692          0.027473                        0.422311   \n",
       "24           0.029637          0.000000                        0.370582   \n",
       "25          -0.066730          0.061611                        0.389321   \n",
       "26           0.013657          0.129181                        0.419901   \n",
       "27           0.012593          0.000000                        0.416002   \n",
       "28           0.097458          0.065217                        0.218543   \n",
       "29           0.012346          0.092803                        0.430292   \n",
       "\n",
       "    tangible_assets_ratio  revenues  cr_available  region  geo_area  \\\n",
       "0                1.000000     410.0           1.0     1.0       1.0   \n",
       "1                1.000000     208.0           1.0     2.0       1.0   \n",
       "2                0.375000     471.0           0.0     3.0       2.0   \n",
       "3                0.058824     598.0           1.0     4.0       3.0   \n",
       "4                0.750000     108.0           0.0     5.0       4.0   \n",
       "5                0.504065    2073.0           1.0     6.0       5.0   \n",
       "6                0.000000      57.0           0.0     7.0       2.0   \n",
       "7                0.843066   12209.0           1.0     8.0       5.0   \n",
       "8                1.000000     584.0           1.0     9.0       2.0   \n",
       "9                0.715017     552.0           0.0    10.0       2.0   \n",
       "10               1.000000     410.0           0.0     6.0       5.0   \n",
       "11               1.000000    1507.0           1.0     2.0       1.0   \n",
       "12               0.676364    1100.0           1.0     4.0       3.0   \n",
       "13               0.038462    1752.0           1.0     5.0       4.0   \n",
       "14               0.740741     277.0           1.0     4.0       3.0   \n",
       "15               0.072614    1768.0           1.0    11.0       4.0   \n",
       "16               1.000000     208.0           1.0    12.0       3.0   \n",
       "17               0.500000    1565.0           1.0    11.0       4.0   \n",
       "18               0.500000     182.0           0.0     5.0       4.0   \n",
       "19               0.060241     182.0           1.0     5.0       4.0   \n",
       "20               0.200000     913.0           1.0     8.0       5.0   \n",
       "21               1.000000     410.0           1.0     6.0       5.0   \n",
       "22               0.531250     239.0           1.0     4.0       3.0   \n",
       "23               0.007246     988.0           1.0     3.0       2.0   \n",
       "24               1.000000     946.0           1.0     4.0       3.0   \n",
       "25               0.109012     990.0           1.0    13.0       3.0   \n",
       "26               0.768116    1337.0           1.0     6.0       5.0   \n",
       "27               1.000000     410.0           1.0     1.0       1.0   \n",
       "28               0.983051     236.0           0.0     8.0       5.0   \n",
       "29               0.093870    1134.0           1.0     6.0       5.0   \n",
       "\n",
       "    last_statement_age  overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                  2.0                              0.000000   \n",
       "1                  3.0                              0.000000   \n",
       "2                  2.0                              0.000000   \n",
       "3                  3.0                              0.000000   \n",
       "4                  2.0                              0.000000   \n",
       "5                  1.0                              0.000000   \n",
       "6                  2.0                              0.000000   \n",
       "7                  3.0                              0.000000   \n",
       "8                  2.0                              0.083333   \n",
       "9                  3.0                              0.000000   \n",
       "10                 2.0                              0.000000   \n",
       "11                 2.0                              0.000000   \n",
       "12                 2.0                              0.000000   \n",
       "13                 2.0                              0.000000   \n",
       "14                 1.0                              0.000000   \n",
       "15                 1.0                              0.000000   \n",
       "16                 2.0                              0.000000   \n",
       "17                 2.0                              0.000000   \n",
       "18                 2.0                              0.000000   \n",
       "19                 1.0                              0.000000   \n",
       "20                 2.0                              0.000000   \n",
       "21                 2.0                              0.416667   \n",
       "22                 2.0                              0.000000   \n",
       "23                 2.0                              0.000000   \n",
       "24                 2.0                              0.000000   \n",
       "25                 2.0                              0.000000   \n",
       "26                 1.0                              0.000000   \n",
       "27                 2.0                              0.833333   \n",
       "28                 2.0                              0.000000   \n",
       "29                 2.0                              0.416667   \n",
       "\n",
       "    avg_tension_a_revoca_autoliquidanti  std_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0.000000                             0.000000   \n",
       "1                              0.000000                             0.000000   \n",
       "2                              0.000000                             0.000000   \n",
       "3                              0.000000                             0.000000   \n",
       "4                              0.000000                             0.000000   \n",
       "5                              0.000000                             0.000000   \n",
       "6                              0.000000                             0.000000   \n",
       "7                              0.458545                             0.248584   \n",
       "8                          12637.000000                         43775.539062   \n",
       "9                              0.000000                             0.000000   \n",
       "10                             0.000000                             0.000000   \n",
       "11                             0.701977                             0.145203   \n",
       "12                             0.000000                             0.000000   \n",
       "13                             0.642653                             0.159023   \n",
       "14                             0.010555                             0.036563   \n",
       "15                             0.396210                             0.120278   \n",
       "16                             0.000000                             0.000000   \n",
       "17                             0.169214                             0.255193   \n",
       "18                             0.000000                             0.000000   \n",
       "19                             0.332279                             0.171461   \n",
       "20                             0.000000                             0.000000   \n",
       "21                             0.961410                             0.166273   \n",
       "22                             0.177833                             0.330063   \n",
       "23                             0.051943                             0.053098   \n",
       "24                             0.000000                             0.000000   \n",
       "25                             0.028333                             0.061643   \n",
       "26                             0.071703                             0.085131   \n",
       "27                             1.046128                             0.040009   \n",
       "28                             0.000000                             0.000000   \n",
       "29                             0.867331                             0.073822   \n",
       "\n",
       "    max_tension_a_revoca_autoliquidanti  last_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0.000000                              0.000000   \n",
       "1                              0.000000                              0.000000   \n",
       "2                              0.000000                              0.000000   \n",
       "3                              0.000000                              0.000000   \n",
       "4                              0.000000                              0.000000   \n",
       "5                              0.000000                              0.000000   \n",
       "6                              0.000000                              0.000000   \n",
       "7                              0.790275                              0.202147   \n",
       "8                         151643.000000                              1.000000   \n",
       "9                              0.000000                              0.000000   \n",
       "10                             0.000000                              0.000000   \n",
       "11                             0.999676                              0.670731   \n",
       "12                             0.000000                              0.000000   \n",
       "13                             0.858100                              0.615092   \n",
       "14                             0.126657                              0.000000   \n",
       "15                             0.609917                              0.294906   \n",
       "16                             0.000000                              0.000000   \n",
       "17                             0.632867                              0.000000   \n",
       "18                             0.000000                              0.000000   \n",
       "19                             0.658733                              0.000000   \n",
       "20                             0.000000                              0.000000   \n",
       "21                             1.179400                              1.172486   \n",
       "22                             0.909000                              0.000000   \n",
       "23                             0.154785                              0.037854   \n",
       "24                             0.000000                              0.000000   \n",
       "25                             0.184000                              0.000000   \n",
       "26                             0.240817                              0.114286   \n",
       "27                             1.114067                              1.006933   \n",
       "28                             0.000000                              0.000000   \n",
       "29                             0.967480                              0.936377   \n",
       "\n",
       "    avg_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.027610   \n",
       "8                               0.002856   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.069734   \n",
       "12                              0.000000   \n",
       "13                              0.194926   \n",
       "14                              0.001334   \n",
       "15                              0.130983   \n",
       "16                              0.000000   \n",
       "17                              0.003244   \n",
       "18                              0.000000   \n",
       "19                              0.052502   \n",
       "20                              0.000000   \n",
       "21                              0.074173   \n",
       "22                              0.003720   \n",
       "23                              0.008719   \n",
       "24                              0.000000   \n",
       "25                              0.000014   \n",
       "26                              0.009411   \n",
       "27                              0.038273   \n",
       "28                              0.000000   \n",
       "29                              0.290532   \n",
       "\n",
       "    std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.013843   \n",
       "8                               0.009886   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.014225   \n",
       "12                              0.000000   \n",
       "13                              0.047999   \n",
       "14                              0.004620   \n",
       "15                              0.039988   \n",
       "16                              0.000000   \n",
       "17                              0.004892   \n",
       "18                              0.000000   \n",
       "19                              0.027683   \n",
       "20                              0.000000   \n",
       "21                              0.017088   \n",
       "22                              0.006905   \n",
       "23                              0.008911   \n",
       "24                              0.000000   \n",
       "25                              0.000031   \n",
       "26                              0.011168   \n",
       "27                              0.001464   \n",
       "28                              0.000000   \n",
       "29                              0.025495   \n",
       "\n",
       "    max_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.045343   \n",
       "8                               0.034247   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.096186   \n",
       "12                              0.000000   \n",
       "13                              0.259955   \n",
       "14                              0.016004   \n",
       "15                              0.201627   \n",
       "16                              0.000000   \n",
       "17                              0.012132   \n",
       "18                              0.000000   \n",
       "19                              0.082725   \n",
       "20                              0.000000   \n",
       "21                              0.100090   \n",
       "22                              0.019017   \n",
       "23                              0.025983   \n",
       "24                              0.000000   \n",
       "25                              0.000093   \n",
       "26                              0.031521   \n",
       "27                              0.040759   \n",
       "28                              0.000000   \n",
       "29                              0.332647   \n",
       "\n",
       "    last_rel_used_a_revoca_autoliquidanti  overrun_freq_a_scadenza  \\\n",
       "0                                0.000000                 0.250000   \n",
       "1                                0.000000                 0.000000   \n",
       "2                                0.000000                 0.000000   \n",
       "3                                0.000000                 0.000000   \n",
       "4                                0.000000                 0.000000   \n",
       "5                                0.000000                 0.250000   \n",
       "6                                0.000000                 0.000000   \n",
       "7                                0.012444                 0.000000   \n",
       "8                                0.034247                 0.000000   \n",
       "9                                0.000000                 0.000000   \n",
       "10                               0.000000                 0.000000   \n",
       "11                               0.064536                 0.000000   \n",
       "12                               0.000000                 0.000000   \n",
       "13                               0.187009                 0.000000   \n",
       "14                               0.000000                 0.000000   \n",
       "15                               0.097028                 0.000000   \n",
       "16                               0.000000                 0.000000   \n",
       "17                               0.000000                 0.000000   \n",
       "18                               0.000000                 0.000000   \n",
       "19                               0.000000                 0.000000   \n",
       "20                               0.000000                 0.000000   \n",
       "21                               0.100090                 0.000000   \n",
       "22                               0.000000                 0.000000   \n",
       "23                               0.006371                 0.000000   \n",
       "24                               0.000000                 0.000000   \n",
       "25                               0.000000                 0.083333   \n",
       "26                               0.014959                 0.000000   \n",
       "27                               0.036839                 0.000000   \n",
       "28                               0.000000                 0.000000   \n",
       "29                               0.294638                 0.000000   \n",
       "\n",
       "    avg_rel_used_a_scadenza  std_rel_used_a_scadenza  max_rel_used_a_scadenza  \\\n",
       "0                  0.176975             2.111932e-03                 0.179073   \n",
       "1                  0.151754             6.806286e-03                 0.164755   \n",
       "2                  0.000000             0.000000e+00                 0.000000   \n",
       "3                  0.025084             2.619898e-02                 0.050167   \n",
       "4                  0.000000             0.000000e+00                 0.000000   \n",
       "5                  0.060680             3.722236e-02                 0.146051   \n",
       "6                  0.000000             0.000000e+00                 0.000000   \n",
       "7                  0.020232             2.002530e-02                 0.040953   \n",
       "8                  0.094279             4.360371e-04                 0.095017   \n",
       "9                  0.000000             0.000000e+00                 0.000000   \n",
       "10                 0.000000             0.000000e+00                 0.000000   \n",
       "11                 0.041406             1.724269e-02                 0.059721   \n",
       "12                 0.171200             5.174890e-02                 0.229672   \n",
       "13                 0.234372             5.594047e-02                 0.285388   \n",
       "14                 0.349027             6.285652e-03                 0.358538   \n",
       "15                 0.182228             1.410236e-02                 0.210419   \n",
       "16                 0.126764             2.898975e-17                 0.126764   \n",
       "17                 0.081779             1.744957e-02                 0.095847   \n",
       "18                 0.000000             0.000000e+00                 0.000000   \n",
       "19                 0.634728             7.677177e-02                 0.746165   \n",
       "20                 0.016453             2.430452e-02                 0.049733   \n",
       "21                 0.072884             1.291411e-02                 0.092295   \n",
       "22                 0.266932             6.039229e-03                 0.286109   \n",
       "23                 0.019821             1.210318e-02                 0.030364   \n",
       "24                 0.162474             2.898975e-17                 0.162474   \n",
       "25                 0.027778             8.747864e-03                 0.030308   \n",
       "26                 0.134426             1.642027e-03                 0.135087   \n",
       "27                 0.180244             3.767771e-02                 0.222927   \n",
       "28                 0.000000             0.000000e+00                 0.000000   \n",
       "29                 0.252414             4.928930e-02                 0.393825   \n",
       "\n",
       "    last_rel_used_a_scadenza  avg_count_enti_affidanti  \\\n",
       "0                   0.172032                  1.000000   \n",
       "1                   0.146385                  1.000000   \n",
       "2                   0.000000                  1.000000   \n",
       "3                   0.050167                  1.000000   \n",
       "4                   0.000000                  0.000000   \n",
       "5                   0.146051                  2.250000   \n",
       "6                   0.000000                  0.000000   \n",
       "7                   0.037795                  6.000000   \n",
       "8                   0.095017                  1.000000   \n",
       "9                   0.000000                  0.000000   \n",
       "10                  0.000000                  0.000000   \n",
       "11                  0.055987                  1.000000   \n",
       "12                  0.214628                  3.083333   \n",
       "13                  0.265908                  3.000000   \n",
       "14                  0.339361                  2.000000   \n",
       "15                  0.176218                  5.666667   \n",
       "16                  0.126764                  1.000000   \n",
       "17                  0.095847                  1.000000   \n",
       "18                  0.000000                  0.000000   \n",
       "19                  0.746165                  1.916667   \n",
       "20                  0.048723                  1.000000   \n",
       "21                  0.083193                  1.000000   \n",
       "22                  0.286109                  2.000000   \n",
       "23                  0.030364                  3.000000   \n",
       "24                  0.162474                  1.083333   \n",
       "25                  0.030303                  1.000000   \n",
       "26                  0.129804                  2.000000   \n",
       "27                  0.222927                  1.416667   \n",
       "28                  0.000000                  0.000000   \n",
       "29                  0.393825                  7.083333   \n",
       "\n",
       "    std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0                   0.000000                       1.0   \n",
       "1                   0.000000                       1.0   \n",
       "2                   0.000000                       1.0   \n",
       "3                   0.000000                       1.0   \n",
       "4                   0.000000                       0.0   \n",
       "5                   0.452267                       3.0   \n",
       "6                   0.000000                       0.0   \n",
       "7                   0.000000                       6.0   \n",
       "8                   0.000000                       1.0   \n",
       "9                   0.000000                       0.0   \n",
       "10                  0.000000                       0.0   \n",
       "11                  0.000000                       1.0   \n",
       "12                  1.083625                       4.0   \n",
       "13                  0.000000                       3.0   \n",
       "14                  0.000000                       2.0   \n",
       "15                  0.492366                       6.0   \n",
       "16                  0.000000                       1.0   \n",
       "17                  0.000000                       1.0   \n",
       "18                  0.000000                       0.0   \n",
       "19                  0.288675                       2.0   \n",
       "20                  0.000000                       1.0   \n",
       "21                  0.000000                       1.0   \n",
       "22                  0.000000                       2.0   \n",
       "23                  0.000000                       3.0   \n",
       "24                  0.288675                       2.0   \n",
       "25                  0.000000                       1.0   \n",
       "26                  0.000000                       2.0   \n",
       "27                  0.514929                       2.0   \n",
       "28                  0.000000                       0.0   \n",
       "29                  1.240112                       8.0   \n",
       "\n",
       "    last_count_enti_affidanti  avg_count_numero_prima_info  \\\n",
       "0                         1.0                     0.000000   \n",
       "1                         1.0                     2.000000   \n",
       "2                         1.0                     1.000000   \n",
       "3                         1.0                     0.500000   \n",
       "4                         0.0                     0.000000   \n",
       "5                         3.0                     2.916667   \n",
       "6                         0.0                     0.000000   \n",
       "7                         6.0                     0.250000   \n",
       "8                         1.0                     1.000000   \n",
       "9                         0.0                     0.000000   \n",
       "10                        0.0                     0.000000   \n",
       "11                        1.0                     1.083333   \n",
       "12                        0.0                     1.416667   \n",
       "13                        3.0                     0.166667   \n",
       "14                        2.0                     0.000000   \n",
       "15                        6.0                     0.000000   \n",
       "16                        1.0                     0.000000   \n",
       "17                        1.0                     1.000000   \n",
       "18                        0.0                     0.000000   \n",
       "19                        2.0                     1.000000   \n",
       "20                        1.0                     0.000000   \n",
       "21                        1.0                     1.000000   \n",
       "22                        2.0                     0.000000   \n",
       "23                        3.0                     0.000000   \n",
       "24                        2.0                     4.500000   \n",
       "25                        1.0                     1.000000   \n",
       "26                        2.0                     0.000000   \n",
       "27                        2.0                     0.000000   \n",
       "28                        0.0                     0.000000   \n",
       "29                        8.0                     2.833333   \n",
       "\n",
       "    std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0                      0.000000                          0.0   \n",
       "1                      0.000000                          2.0   \n",
       "2                      0.000000                          1.0   \n",
       "3                      0.522233                          1.0   \n",
       "4                      0.000000                          0.0   \n",
       "5                      0.668558                          4.0   \n",
       "6                      0.000000                          0.0   \n",
       "7                      0.621582                          2.0   \n",
       "8                      0.000000                          1.0   \n",
       "9                      0.000000                          0.0   \n",
       "10                     0.000000                          0.0   \n",
       "11                     0.288675                          2.0   \n",
       "12                     0.996205                          3.0   \n",
       "13                     0.389249                          1.0   \n",
       "14                     0.000000                          0.0   \n",
       "15                     0.000000                          0.0   \n",
       "16                     0.000000                          0.0   \n",
       "17                     0.000000                          1.0   \n",
       "18                     0.000000                          0.0   \n",
       "19                     0.000000                          1.0   \n",
       "20                     0.000000                          0.0   \n",
       "21                     0.000000                          1.0   \n",
       "22                     0.000000                          0.0   \n",
       "23                     0.000000                          0.0   \n",
       "24                     1.167748                          7.0   \n",
       "25                     0.000000                          1.0   \n",
       "26                     0.000000                          0.0   \n",
       "27                     0.000000                          0.0   \n",
       "28                     0.000000                          0.0   \n",
       "29                     1.029857                          4.0   \n",
       "\n",
       "    last_count_numero_prima_info  target  \n",
       "0                            0.0     1.0  \n",
       "1                            2.0     0.0  \n",
       "2                            1.0     1.0  \n",
       "3                            0.0     0.0  \n",
       "4                            0.0     0.0  \n",
       "5                            1.0     0.0  \n",
       "6                            0.0     0.0  \n",
       "7                            2.0     1.0  \n",
       "8                            1.0     1.0  \n",
       "9                            0.0     0.0  \n",
       "10                           0.0     0.0  \n",
       "11                           2.0     0.0  \n",
       "12                           0.0     0.0  \n",
       "13                           0.0     0.0  \n",
       "14                           0.0     0.0  \n",
       "15                           0.0     1.0  \n",
       "16                           0.0     0.0  \n",
       "17                           1.0     0.0  \n",
       "18                           0.0     1.0  \n",
       "19                           1.0     1.0  \n",
       "20                           0.0     1.0  \n",
       "21                           1.0     0.0  \n",
       "22                           0.0     0.0  \n",
       "23                           0.0     0.0  \n",
       "24                           7.0     1.0  \n",
       "25                           1.0     0.0  \n",
       "26                           0.0     0.0  \n",
       "27                           0.0     1.0  \n",
       "28                           0.0     0.0  \n",
       "29                           4.0     0.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Build a Balanced Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13788, 40)\n"
     ]
    }
   ],
   "source": [
    "def split_dataframe_by_label(df, label_column, label_value_1, label_value_2, sample_size):\n",
    "    # Separate the DataFrame based on the labels\n",
    "    subset_1 = df[df[label_column] == label_value_1]\n",
    "    subset_2 = df[df[label_column] == label_value_2]\n",
    "    \n",
    "    # Take a random sample of rows from each subset\n",
    "    subset_1_sampled = subset_1.sample(n=sample_size, random_state=42)\n",
    "    subset_2_sampled = subset_2.sample(n=sample_size, random_state=42)\n",
    "    \n",
    "    # Concatenate the sampled subsets to form the final split\n",
    "    final_split = pd.concat([subset_1_sampled, subset_2_sampled], ignore_index=True)\n",
    "\n",
    "    return final_split\n",
    "\n",
    "train_dataset = split_dataframe_by_label(train_dataset, 'target', 0, 1, 6894)\n",
    "print(train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> SVM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12409, 33) (1379, 33)\n",
      "[LibSVM]............................*...*...............*..*\n",
      "optimization finished, #iter = 47843\n",
      "obj = -893.871395, rho = -0.003811\n",
      "nSV = 8958, nBSV = 5905\n",
      "Total nSV = 8958\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"â–¸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"â–¾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=0.1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;SVC<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.4/modules/generated/sklearn.svm.SVC.html\">?<span>Documentation for SVC</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>SVC(C=0.1, class_weight=&#x27;balanced&#x27;, kernel=&#x27;linear&#x27;, verbose=True)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=0.1, class_weight='balanced', kernel='linear', verbose=True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "Y = train_dataset['target']\n",
    "\n",
    "# Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_dataset.drop(columns='target'))\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=33)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca,Y, test_size=0.1, stratify=Y, random_state=2)\n",
    "\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "# classifier = svm.SVC(C=0.1 ,kernel='linear', gamma=0.001, class_weight=\"balanced\")\n",
    "classifier = svm.SVC(C=0.1, kernel='linear', gamma='scale', class_weight='balanced', verbose=True)\n",
    "\n",
    "classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6874546773023931\n"
     ]
    }
   ],
   "source": [
    "X_test_prediction = classifier.predict(X_test)\n",
    "test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(test_data_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 Score: 0.6879073135409124\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# Assuming classifier is your trained SVM model and X_test, y_test are your test data\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(Y_test, y_pred)\n",
    "\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.780638143582306\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Step 1: Split the dataset into features (X) and target variable (y)\n",
    "X = train_dataset.drop(columns=['target'])  # Assuming 'target_column' is your target variable\n",
    "y = train_dataset['target']\n",
    "\n",
    "# Step 2: Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 3: Create a Random Forest classifier\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Step 4: Train the classifier on the training data\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Evaluate the classifier on the testing data\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### F1 Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7795992714025501\n"
     ]
    }
   ],
   "source": [
    "# Step 6: Compute the F1 score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quello che funziona "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [40/40], Loss: 2.5873, Fold:0\n",
      "Accuracy on test set: 49.20%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [40/40], Loss: 1.5723, Fold:1\n",
      "Accuracy on test set: 50.69%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [40/40], Loss: 1.2062, Fold:2\n",
      "Accuracy on test set: 49.60%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [40/40], Loss: 1.2893, Fold:3\n",
      "Accuracy on test set: 51.00%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [40/40], Loss: 1.7291, Fold:4\n",
      "Accuracy on test set: 49.51%\n",
      "Averagea ccuracy on test set: 50.00%\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)  \n",
    "        self.fc2 = nn.Linear(16,8)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.dropout = nn.Dropout(p=0.2)\n",
    "        self.fc4 = nn.Linear(8, 1)  # Output layer with 1 neuron for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.relu(x)\n",
    "        #x = self.fc4(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_values = []\n",
    "loss_values = []\n",
    "X = train_dataset.iloc[:, :-1].to_numpy()\n",
    "y = train_dataset.iloc[:, -1].to_numpy()\n",
    "\n",
    "num_folds = 5\n",
    "input_size = 39\n",
    "num_epochs = 40\n",
    "num_models = 1\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "l1_lambda = 0.01\n",
    "l2_lambda = 0.01\n",
    "fold_params = []\n",
    "\n",
    "for model_index in range(num_models):\n",
    "\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(X)):\n",
    "        print(f'Fold {fold+1}/{num_folds}')\n",
    "\n",
    "        #X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "        \n",
    "        model = NeuralNetwork(input_size)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "            loss_values.append(loss.item())\n",
    "\n",
    "            l1_reg = torch.tensor(0., requires_grad=True)\n",
    "            for param in model.parameters():\n",
    "                l1_reg = l1_reg + torch.norm(param, p=1)\n",
    "            loss = loss + l1_lambda * l1_reg\n",
    "\n",
    "            # L2 regularization\n",
    "            l2_reg = torch.tensor(0., requires_grad=True)\n",
    "            for param in model.parameters():\n",
    "                l2_reg = l2_reg + torch.norm(param, p=2)\n",
    "            loss = loss + l2_lambda * l2_reg\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        fold_params.append(model.state_dict())\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Fold:{fold}')\n",
    "\n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():\n",
    "            # Predict probabilities on the test set\n",
    "            outputs = model(X_val_tensor)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (predicted == y_val_tensor.view(-1, 1)).float().mean()\n",
    "            accuracy_values.append(accuracy)\n",
    "            print(f'Accuracy on test set: {accuracy.item()*100:.2f}%')\n",
    "    torch.save(model.state_dict(), f'model_{model_index}.pth')\n",
    "\n",
    "avg_params = {}\n",
    "\n",
    "for key in fold_params[0].keys():\n",
    "    avg_params[key] = torch.stack([params[key] for params in fold_params]).mean(dim=0)\n",
    "\n",
    "# Create a new model with the average parameters\n",
    "average_model = NeuralNetwork(input_size)\n",
    "average_model.load_state_dict(avg_params)\n",
    "print(f'Averagea ccuracy on test set: {np.array(accuracy_values).mean()*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Loss Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss values\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test set: 0.0000\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "true_labels = y_val_tensor.numpy().astype(int)\n",
    "predicted_labels = 1-(predicted.numpy())\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(f'F1 score on test set: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"/Users/danielguarnizo/Desktop/HACK4SDS/Dataset_DAY1/Data/test_set.csv\", delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ZWFXwUAP</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>1321219660</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>PD</td>\n",
       "      <td>SR</td>\n",
       "      <td>Distribuzione</td>\n",
       "      <td>0,0698090692124105</td>\n",
       "      <td>-0,0133630289532294</td>\n",
       "      <td>0,0454201362604088</td>\n",
       "      <td>0,39200477326969</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>True</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>Nord-est</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,554859166666667</td>\n",
       "      <td>0,146890245697462</td>\n",
       "      <td>0,83594</td>\n",
       "      <td>0,60264</td>\n",
       "      <td>0,123576651818857</td>\n",
       "      <td>0,032714976770036</td>\n",
       "      <td>0,186178173719376</td>\n",
       "      <td>0,134218262806236</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>1,27369933184855</td>\n",
       "      <td>0,028642038445761</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q7R00000ZWJX2UAP</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>1420617490</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>IS</td>\n",
       "      <td>SR</td>\n",
       "      <td>Altri beni di consumo</td>\n",
       "      <td>0,169093471113199</td>\n",
       "      <td>0,00206611570247934</td>\n",
       "      <td>0,155359917141378</td>\n",
       "      <td>0,54062940347581</td>\n",
       "      <td>0,95959595959596</td>\n",
       "      <td>1402</td>\n",
       "      <td>False</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q7R00000a3E9nUAE</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>51</td>\n",
       "      <td>CB</td>\n",
       "      <td>SR</td>\n",
       "      <td>Chimica di base e intermedi</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,941108491613086</td>\n",
       "      <td>0,0992007690627971</td>\n",
       "      <td>1,0864</td>\n",
       "      <td>1</td>\n",
       "      <td>0,137654704944179</td>\n",
       "      <td>0,115573259414523</td>\n",
       "      <td>0,267955342902711</td>\n",
       "      <td>0,0119617224880383</td>\n",
       "      <td>0</td>\n",
       "      <td>0,212708532695375</td>\n",
       "      <td>0,100377623990215</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ZWRR6UAP</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>CB</td>\n",
       "      <td>SR</td>\n",
       "      <td>Chimica di base e intermedi</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,878429123495436</td>\n",
       "      <td>0,0566505328975202</td>\n",
       "      <td>0,972473824531666</td>\n",
       "      <td>0,903049655802421</td>\n",
       "      <td>0,252491959064328</td>\n",
       "      <td>0,0249197649236005</td>\n",
       "      <td>0,269318979266348</td>\n",
       "      <td>0,17658293460925</td>\n",
       "      <td>0</td>\n",
       "      <td>0,14559735513025</td>\n",
       "      <td>0,0113414597444539</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000g6DWvUAM</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2412739090</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "      <td>SS</td>\n",
       "      <td>SR</td>\n",
       "      <td>Alimentare</td>\n",
       "      <td>0,135170603674541</td>\n",
       "      <td>-0,0755467196819085</td>\n",
       "      <td>0,0169851380042463</td>\n",
       "      <td>0,492125984251969</td>\n",
       "      <td>0,769345238095238</td>\n",
       "      <td>1463</td>\n",
       "      <td>True</td>\n",
       "      <td>Sardegna</td>\n",
       "      <td>Isole</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,722863999082564</td>\n",
       "      <td>0,0605656113993484</td>\n",
       "      <td>0,816631566033492</td>\n",
       "      <td>0,761046273164548</td>\n",
       "      <td>0,284641717931192</td>\n",
       "      <td>0,0245101240633782</td>\n",
       "      <td>0,315383458646616</td>\n",
       "      <td>0,306924812030075</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38485640236956</td>\n",
       "      <td>0,0307032798267901</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ZWFXwUAP    2020-10-12  1321219660                     5   \n",
       "1  a1Q7R00000ZWJX2UAP    2020-11-12  1420617490                     8   \n",
       "2  a1Q7R00000a3E9nUAE    2021-07-05   137667970                     8   \n",
       "3  a1Q7R00000ZWRR6UAP    2021-01-19   137667970                     8   \n",
       "4  a1Q7R00000g6DWvUAM    2022-05-09  2412739090                     6   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     1                 8.0   \n",
       "1                     1                 NaN   \n",
       "2                     1                 NaN   \n",
       "3                     1                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     5.0                      6.0   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  age province juridical_form  \\\n",
       "0                     7.0                    D    6       PD             SR   \n",
       "1                     NaN                    F   46       IS             SR   \n",
       "2                     NaN                    I   51       CB             SR   \n",
       "3                     NaN                    F   51       CB             SR   \n",
       "4                     NaN                    F   72       SS             SR   \n",
       "\n",
       "               industry_sector  gross_margin_ratio    core_income_ratio  \\\n",
       "0                Distribuzione  0,0698090692124105  -0,0133630289532294   \n",
       "1        Altri beni di consumo   0,169093471113199  0,00206611570247934   \n",
       "2  Chimica di base e intermedi  0,0589433072553853   0,0306451612903226   \n",
       "3  Chimica di base e intermedi  0,0589433072553853   0,0306451612903226   \n",
       "4                   Alimentare   0,135170603674541  -0,0755467196819085   \n",
       "\n",
       "     cash_asset_ratio consolidated_liabilities_ratio tangible_assets_ratio  \\\n",
       "0  0,0454201362604088               0,39200477326969                     1   \n",
       "1   0,155359917141378               0,54062940347581      0,95959595959596   \n",
       "2  0,0043021855102392              0,640767334690816     0,980113636363636   \n",
       "3  0,0043021855102392              0,640767334690816     0,980113636363636   \n",
       "4  0,0169851380042463              0,492125984251969     0,769345238095238   \n",
       "\n",
       "  revenues  cr_available    region  geo_area  last_statement_age  \\\n",
       "0      449          True    Veneto  Nord-est                   1   \n",
       "1     1402         False    Molise       Sud                   1   \n",
       "2     1254          True    Molise       Sud                   2   \n",
       "3     1254          True    Molise       Sud                   2   \n",
       "4     1463          True  Sardegna     Isole                   2   \n",
       "\n",
       "  overrun_freq_a_revoca_autoliquidanti avg_tension_a_revoca_autoliquidanti  \\\n",
       "0                    0,166666666666667                   0,554859166666667   \n",
       "1                                    0                                   0   \n",
       "2                    0,833333333333333                   0,941108491613086   \n",
       "3                    0,833333333333333                   0,878429123495436   \n",
       "4                                    0                   0,722863999082564   \n",
       "\n",
       "  std_tension_a_revoca_autoliquidanti max_tension_a_revoca_autoliquidanti  \\\n",
       "0                   0,146890245697462                             0,83594   \n",
       "1                                   0                                   0   \n",
       "2                  0,0992007690627971                              1,0864   \n",
       "3                  0,0566505328975202                   0,972473824531666   \n",
       "4                  0,0605656113993484                   0,816631566033492   \n",
       "\n",
       "  last_tension_a_revoca_autoliquidanti avg_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                              0,60264                    0,123576651818857   \n",
       "1                                    0                                    0   \n",
       "2                                    1                    0,137654704944179   \n",
       "3                    0,903049655802421                    0,252491959064328   \n",
       "4                    0,761046273164548                    0,284641717931192   \n",
       "\n",
       "  std_rel_used_a_revoca_autoliquidanti max_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                    0,032714976770036                    0,186178173719376   \n",
       "1                                    0                                    0   \n",
       "2                    0,115573259414523                    0,267955342902711   \n",
       "3                   0,0249197649236005                    0,269318979266348   \n",
       "4                   0,0245101240633782                    0,315383458646616   \n",
       "\n",
       "  last_rel_used_a_revoca_autoliquidanti overrun_freq_a_scadenza  \\\n",
       "0                     0,134218262806236       0,333333333333333   \n",
       "1                                     0                       0   \n",
       "2                    0,0119617224880383                       0   \n",
       "3                      0,17658293460925                       0   \n",
       "4                     0,306924812030075                       0   \n",
       "\n",
       "  avg_rel_used_a_scadenza std_rel_used_a_scadenza max_rel_used_a_scadenza  \\\n",
       "0        1,27369933184855       0,028642038445761        1,32464142538975   \n",
       "1                       0                       0                       0   \n",
       "2       0,212708532695375       0,100377623990215        0,33222009569378   \n",
       "3        0,14559735513025      0,0113414597444539       0,162240829346092   \n",
       "4        0,38485640236956      0,0307032798267901       0,478388926862611   \n",
       "\n",
       "  last_rel_used_a_scadenza avg_count_enti_affidanti std_count_enti_affidanti  \\\n",
       "0         1,32464142538975         1,16666666666667        0,389249472080761   \n",
       "1                        0                        1                        0   \n",
       "2        0,320196172248804                        3                        0   \n",
       "3        0,126861244019139                        3                        0   \n",
       "4        0,356901572112098                        3                        0   \n",
       "\n",
       "   max_count_enti_affidanti  last_count_enti_affidanti  \\\n",
       "0                         2                          2   \n",
       "1                         1                          1   \n",
       "2                         3                          3   \n",
       "3                         3                          3   \n",
       "4                         3                          3   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0            1,08333333333333           0,288675134594813   \n",
       "1                           1                           0   \n",
       "2            1,91666666666667           0,288675134594813   \n",
       "3            1,91666666666667           0,288675134594813   \n",
       "4            2,08333333333333           0,288675134594813   \n",
       "\n",
       "   max_count_numero_prima_info  last_count_numero_prima_info  \n",
       "0                            2                             1  \n",
       "1                            1                             1  \n",
       "2                            2                             2  \n",
       "3                            2                             2  \n",
       "4                            3                             3  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns \n",
    "test_dataset = Drop_unneed_columns(True,test_dataset)\n",
    "\n",
    "test_dataset = test_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "category_dics[\"juridical_form\"][\"SS\"] = 15\n",
    "category_dics[\"juridical_form\"][\"OS\"] = 16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_5651/3066482160.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_dataset.replace({k:v}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "#print(category_dics[\"juridical_form\"])\n",
    "for k,v in category_dics.items():\n",
    "    test_dataset.replace({k:v}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MISSING' in the column: external_score_ver03\n",
      "'MISSING' in the column: province\n",
      "'MISSING' in the column: region\n",
      "'MISSING' in the column: geo_area\n"
     ]
    }
   ],
   "source": [
    "# find columns with MISSING values \n",
    "columns = []\n",
    "for column in list(test_dataset.columns):\n",
    "    # Check if there is a value \"MISSING\" in the 'column_name' column\n",
    "    missing_values = test_dataset[column] == 'MISSING'\n",
    "\n",
    "    # Check if any row contains the value \"MISSING\" in the specified column\n",
    "    if missing_values.any():\n",
    "        print(f\"'MISSING' in the column: {column}\")\n",
    "        columns.append(column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'external_score_ver03': 6, 'province': 31, 'region': 7, 'geo_area': 3}\n"
     ]
    }
   ],
   "source": [
    "# Sum values in the specified columns\n",
    "dic = {}\n",
    "for column in columns:\n",
    "    column_name = column\n",
    "\n",
    "    count = 0\n",
    "    sum_values = 0\n",
    "    # Iterate over the DataFrame\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        # Access the value of the specified column for each row\n",
    "        count +=1\n",
    "        if isinstance(row[column_name], str):\n",
    "            continue\n",
    "        elif isinstance(row[column_name], int):\n",
    "            sum_values += row[column_name]\n",
    "    \n",
    "    dic[column] = int(sum_values/count)\n",
    "\n",
    "print(dic)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing_test(dataset,val, column):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset[column] == 'MISSING'), column] = val\n",
    "\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dic.items():\n",
    "    test_dataset = Replace_missing_test(test_dataset,v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver03\n",
      "6     3186\n",
      "10    1415\n",
      "7     1135\n",
      "11    1113\n",
      "9      804\n",
      "12     689\n",
      "8      667\n",
      "4      385\n",
      "5      297\n",
      "3      240\n",
      "13     225\n",
      "14     215\n",
      "2      168\n",
      "1      139\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "# print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = Replace_bool_toNumbers(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0698090692124105</td>\n",
       "      <td>-0,0133630289532294</td>\n",
       "      <td>0,0454201362604088</td>\n",
       "      <td>0,39200477326969</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,554859166666667</td>\n",
       "      <td>0,146890245697462</td>\n",
       "      <td>0,83594</td>\n",
       "      <td>0,60264</td>\n",
       "      <td>0,123576651818857</td>\n",
       "      <td>0,032714976770036</td>\n",
       "      <td>0,186178173719376</td>\n",
       "      <td>0,134218262806236</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>1,27369933184855</td>\n",
       "      <td>0,028642038445761</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,169093471113199</td>\n",
       "      <td>0,00206611570247934</td>\n",
       "      <td>0,155359917141378</td>\n",
       "      <td>0,54062940347581</td>\n",
       "      <td>0,95959595959596</td>\n",
       "      <td>1402</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,941108491613086</td>\n",
       "      <td>0,0992007690627971</td>\n",
       "      <td>1,0864</td>\n",
       "      <td>1</td>\n",
       "      <td>0,137654704944179</td>\n",
       "      <td>0,115573259414523</td>\n",
       "      <td>0,267955342902711</td>\n",
       "      <td>0,0119617224880383</td>\n",
       "      <td>0</td>\n",
       "      <td>0,212708532695375</td>\n",
       "      <td>0,100377623990215</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,878429123495436</td>\n",
       "      <td>0,0566505328975202</td>\n",
       "      <td>0,972473824531666</td>\n",
       "      <td>0,903049655802421</td>\n",
       "      <td>0,252491959064328</td>\n",
       "      <td>0,0249197649236005</td>\n",
       "      <td>0,269318979266348</td>\n",
       "      <td>0,17658293460925</td>\n",
       "      <td>0</td>\n",
       "      <td>0,14559735513025</td>\n",
       "      <td>0,0113414597444539</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,135170603674541</td>\n",
       "      <td>-0,0755467196819085</td>\n",
       "      <td>0,0169851380042463</td>\n",
       "      <td>0,492125984251969</td>\n",
       "      <td>0,769345238095238</td>\n",
       "      <td>1463</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,722863999082564</td>\n",
       "      <td>0,0605656113993484</td>\n",
       "      <td>0,816631566033492</td>\n",
       "      <td>0,761046273164548</td>\n",
       "      <td>0,284641717931192</td>\n",
       "      <td>0,0245101240633782</td>\n",
       "      <td>0,315383458646616</td>\n",
       "      <td>0,306924812030075</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38485640236956</td>\n",
       "      <td>0,0307032798267901</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   external_score_ver01  external_score_ver02 external_score_ver03  age  \\\n",
       "0                     5                     1                   11    6   \n",
       "1                     8                     1                    9   46   \n",
       "2                     8                     1                    6   51   \n",
       "3                     8                     1                    9   51   \n",
       "4                     6                     1                    9   72   \n",
       "\n",
       "  province  juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0        5               1                3  0,0698090692124105   \n",
       "1      101               1                8   0,169093471113199   \n",
       "2       69               1               12  0,0589433072553853   \n",
       "3       69               1               12  0,0589433072553853   \n",
       "4       51               1               15   0,135170603674541   \n",
       "\n",
       "     core_income_ratio    cash_asset_ratio consolidated_liabilities_ratio  \\\n",
       "0  -0,0133630289532294  0,0454201362604088               0,39200477326969   \n",
       "1  0,00206611570247934   0,155359917141378               0,54062940347581   \n",
       "2   0,0306451612903226  0,0043021855102392              0,640767334690816   \n",
       "3   0,0306451612903226  0,0043021855102392              0,640767334690816   \n",
       "4  -0,0755467196819085  0,0169851380042463              0,492125984251969   \n",
       "\n",
       "  tangible_assets_ratio revenues  cr_available region geo_area  \\\n",
       "0                     1      449             1      5        4   \n",
       "1      0,95959595959596     1402             0     18        2   \n",
       "2     0,980113636363636     1254             1     18        2   \n",
       "3     0,980113636363636     1254             1     18        2   \n",
       "4     0,769345238095238     1463             1      2        1   \n",
       "\n",
       "   last_statement_age overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                   1                    0,166666666666667   \n",
       "1                   1                                    0   \n",
       "2                   2                    0,833333333333333   \n",
       "3                   2                    0,833333333333333   \n",
       "4                   2                                    0   \n",
       "\n",
       "  avg_tension_a_revoca_autoliquidanti std_tension_a_revoca_autoliquidanti  \\\n",
       "0                   0,554859166666667                   0,146890245697462   \n",
       "1                                   0                                   0   \n",
       "2                   0,941108491613086                  0,0992007690627971   \n",
       "3                   0,878429123495436                  0,0566505328975202   \n",
       "4                   0,722863999082564                  0,0605656113993484   \n",
       "\n",
       "  max_tension_a_revoca_autoliquidanti last_tension_a_revoca_autoliquidanti  \\\n",
       "0                             0,83594                              0,60264   \n",
       "1                                   0                                    0   \n",
       "2                              1,0864                                    1   \n",
       "3                   0,972473824531666                    0,903049655802421   \n",
       "4                   0,816631566033492                    0,761046273164548   \n",
       "\n",
       "  avg_rel_used_a_revoca_autoliquidanti std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                    0,123576651818857                    0,032714976770036   \n",
       "1                                    0                                    0   \n",
       "2                    0,137654704944179                    0,115573259414523   \n",
       "3                    0,252491959064328                   0,0249197649236005   \n",
       "4                    0,284641717931192                   0,0245101240633782   \n",
       "\n",
       "  max_rel_used_a_revoca_autoliquidanti last_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                    0,186178173719376                     0,134218262806236   \n",
       "1                                    0                                     0   \n",
       "2                    0,267955342902711                    0,0119617224880383   \n",
       "3                    0,269318979266348                      0,17658293460925   \n",
       "4                    0,315383458646616                     0,306924812030075   \n",
       "\n",
       "  overrun_freq_a_scadenza avg_rel_used_a_scadenza std_rel_used_a_scadenza  \\\n",
       "0       0,333333333333333        1,27369933184855       0,028642038445761   \n",
       "1                       0                       0                       0   \n",
       "2                       0       0,212708532695375       0,100377623990215   \n",
       "3                       0        0,14559735513025      0,0113414597444539   \n",
       "4                       0        0,38485640236956      0,0307032798267901   \n",
       "\n",
       "  max_rel_used_a_scadenza last_rel_used_a_scadenza avg_count_enti_affidanti  \\\n",
       "0        1,32464142538975         1,32464142538975         1,16666666666667   \n",
       "1                       0                        0                        1   \n",
       "2        0,33222009569378        0,320196172248804                        3   \n",
       "3       0,162240829346092        0,126861244019139                        3   \n",
       "4       0,478388926862611        0,356901572112098                        3   \n",
       "\n",
       "  std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0        0,389249472080761                         2   \n",
       "1                        0                         1   \n",
       "2                        0                         3   \n",
       "3                        0                         3   \n",
       "4                        0                         3   \n",
       "\n",
       "   last_count_enti_affidanti avg_count_numero_prima_info  \\\n",
       "0                          2            1,08333333333333   \n",
       "1                          1                           1   \n",
       "2                          3            1,91666666666667   \n",
       "3                          3            1,91666666666667   \n",
       "4                          3            2,08333333333333   \n",
       "\n",
       "  std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0           0,288675134594813                            2   \n",
       "1                           0                            1   \n",
       "2           0,288675134594813                            2   \n",
       "3           0,288675134594813                            2   \n",
       "4           0,288675134594813                            3   \n",
       "\n",
       "   last_count_numero_prima_info  \n",
       "0                             1  \n",
       "1                             1  \n",
       "2                             2  \n",
       "3                             2  \n",
       "4                             3  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_5651/203960612.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset = dataset.replace(',', '.', regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrame does not contain any NaN values.\n"
     ]
    }
   ],
   "source": [
    "## normalise test dataset \n",
    "def normalized_tdata(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    # print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset\n",
    "test_dataset = normalized_tdata(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.069809</td>\n",
       "      <td>-0.013363</td>\n",
       "      <td>0.045420</td>\n",
       "      <td>0.392005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>449.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.554859</td>\n",
       "      <td>0.146890</td>\n",
       "      <td>0.835940</td>\n",
       "      <td>0.602640</td>\n",
       "      <td>0.123577</td>\n",
       "      <td>0.032715</td>\n",
       "      <td>0.186178</td>\n",
       "      <td>0.134218</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.273699</td>\n",
       "      <td>0.028642</td>\n",
       "      <td>1.324641</td>\n",
       "      <td>1.324641</td>\n",
       "      <td>1.166667</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>101.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.169093</td>\n",
       "      <td>0.002066</td>\n",
       "      <td>0.155360</td>\n",
       "      <td>0.540629</td>\n",
       "      <td>0.959596</td>\n",
       "      <td>1402.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.058943</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.640767</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.941108</td>\n",
       "      <td>0.099201</td>\n",
       "      <td>1.086400</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.137655</td>\n",
       "      <td>0.115573</td>\n",
       "      <td>0.267955</td>\n",
       "      <td>0.011962</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.212709</td>\n",
       "      <td>0.100378</td>\n",
       "      <td>0.332220</td>\n",
       "      <td>0.320196</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.058943</td>\n",
       "      <td>0.030645</td>\n",
       "      <td>0.004302</td>\n",
       "      <td>0.640767</td>\n",
       "      <td>0.980114</td>\n",
       "      <td>1254.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.878429</td>\n",
       "      <td>0.056651</td>\n",
       "      <td>0.972474</td>\n",
       "      <td>0.903050</td>\n",
       "      <td>0.252492</td>\n",
       "      <td>0.024920</td>\n",
       "      <td>0.269319</td>\n",
       "      <td>0.176583</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.145597</td>\n",
       "      <td>0.011341</td>\n",
       "      <td>0.162241</td>\n",
       "      <td>0.126861</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.135171</td>\n",
       "      <td>-0.075547</td>\n",
       "      <td>0.016985</td>\n",
       "      <td>0.492126</td>\n",
       "      <td>0.769345</td>\n",
       "      <td>1463.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.722864</td>\n",
       "      <td>0.060566</td>\n",
       "      <td>0.816632</td>\n",
       "      <td>0.761046</td>\n",
       "      <td>0.284642</td>\n",
       "      <td>0.024510</td>\n",
       "      <td>0.315383</td>\n",
       "      <td>0.306925</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.384856</td>\n",
       "      <td>0.030703</td>\n",
       "      <td>0.478389</td>\n",
       "      <td>0.356902</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   external_score_ver01  external_score_ver02  external_score_ver03   age  \\\n",
       "0                   5.0                   1.0                  11.0   6.0   \n",
       "1                   8.0                   1.0                   9.0  46.0   \n",
       "2                   8.0                   1.0                   6.0  51.0   \n",
       "3                   8.0                   1.0                   9.0  51.0   \n",
       "4                   6.0                   1.0                   9.0  72.0   \n",
       "\n",
       "   province  juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0       5.0             1.0              3.0            0.069809   \n",
       "1     101.0             1.0              8.0            0.169093   \n",
       "2      69.0             1.0             12.0            0.058943   \n",
       "3      69.0             1.0             12.0            0.058943   \n",
       "4      51.0             1.0             15.0            0.135171   \n",
       "\n",
       "   core_income_ratio  cash_asset_ratio  consolidated_liabilities_ratio  \\\n",
       "0          -0.013363          0.045420                        0.392005   \n",
       "1           0.002066          0.155360                        0.540629   \n",
       "2           0.030645          0.004302                        0.640767   \n",
       "3           0.030645          0.004302                        0.640767   \n",
       "4          -0.075547          0.016985                        0.492126   \n",
       "\n",
       "   tangible_assets_ratio  revenues  cr_available  region  geo_area  \\\n",
       "0               1.000000     449.0           1.0     5.0       4.0   \n",
       "1               0.959596    1402.0           0.0    18.0       2.0   \n",
       "2               0.980114    1254.0           1.0    18.0       2.0   \n",
       "3               0.980114    1254.0           1.0    18.0       2.0   \n",
       "4               0.769345    1463.0           1.0     2.0       1.0   \n",
       "\n",
       "   last_statement_age  overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                 1.0                              0.166667   \n",
       "1                 1.0                              0.000000   \n",
       "2                 2.0                              0.833333   \n",
       "3                 2.0                              0.833333   \n",
       "4                 2.0                              0.000000   \n",
       "\n",
       "   avg_tension_a_revoca_autoliquidanti  std_tension_a_revoca_autoliquidanti  \\\n",
       "0                             0.554859                             0.146890   \n",
       "1                             0.000000                             0.000000   \n",
       "2                             0.941108                             0.099201   \n",
       "3                             0.878429                             0.056651   \n",
       "4                             0.722864                             0.060566   \n",
       "\n",
       "   max_tension_a_revoca_autoliquidanti  last_tension_a_revoca_autoliquidanti  \\\n",
       "0                             0.835940                              0.602640   \n",
       "1                             0.000000                              0.000000   \n",
       "2                             1.086400                              1.000000   \n",
       "3                             0.972474                              0.903050   \n",
       "4                             0.816632                              0.761046   \n",
       "\n",
       "   avg_rel_used_a_revoca_autoliquidanti  std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                              0.123577                              0.032715   \n",
       "1                              0.000000                              0.000000   \n",
       "2                              0.137655                              0.115573   \n",
       "3                              0.252492                              0.024920   \n",
       "4                              0.284642                              0.024510   \n",
       "\n",
       "   max_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                              0.186178   \n",
       "1                              0.000000   \n",
       "2                              0.267955   \n",
       "3                              0.269319   \n",
       "4                              0.315383   \n",
       "\n",
       "   last_rel_used_a_revoca_autoliquidanti  overrun_freq_a_scadenza  \\\n",
       "0                               0.134218                 0.333333   \n",
       "1                               0.000000                 0.000000   \n",
       "2                               0.011962                 0.000000   \n",
       "3                               0.176583                 0.000000   \n",
       "4                               0.306925                 0.000000   \n",
       "\n",
       "   avg_rel_used_a_scadenza  std_rel_used_a_scadenza  max_rel_used_a_scadenza  \\\n",
       "0                 1.273699                 0.028642                 1.324641   \n",
       "1                 0.000000                 0.000000                 0.000000   \n",
       "2                 0.212709                 0.100378                 0.332220   \n",
       "3                 0.145597                 0.011341                 0.162241   \n",
       "4                 0.384856                 0.030703                 0.478389   \n",
       "\n",
       "   last_rel_used_a_scadenza  avg_count_enti_affidanti  \\\n",
       "0                  1.324641                  1.166667   \n",
       "1                  0.000000                  1.000000   \n",
       "2                  0.320196                  3.000000   \n",
       "3                  0.126861                  3.000000   \n",
       "4                  0.356902                  3.000000   \n",
       "\n",
       "   std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0                  0.389249                       2.0   \n",
       "1                  0.000000                       1.0   \n",
       "2                  0.000000                       3.0   \n",
       "3                  0.000000                       3.0   \n",
       "4                  0.000000                       3.0   \n",
       "\n",
       "   last_count_enti_affidanti  avg_count_numero_prima_info  \\\n",
       "0                        2.0                     1.083333   \n",
       "1                        1.0                     1.000000   \n",
       "2                        3.0                     1.916667   \n",
       "3                        3.0                     1.916667   \n",
       "4                        3.0                     2.083333   \n",
       "\n",
       "   std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0                     0.288675                          2.0   \n",
       "1                     0.000000                          1.0   \n",
       "2                     0.288675                          2.0   \n",
       "3                     0.288675                          2.0   \n",
       "4                     0.288675                          3.0   \n",
       "\n",
       "   last_count_numero_prima_info  \n",
       "0                           1.0  \n",
       "1                           1.0  \n",
       "2                           2.0  \n",
       "3                           2.0  \n",
       "4                           3.0  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10678, 39)\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\">SVM Predictions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 1. 1. ... 0. 0. 1.]\n"
     ]
    }
   ],
   "source": [
    "#Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=33)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# X_train, X_test, Y_train, Y_test = train_test_split(X_pca,Y, test_size=0.1, stratify=Y, random_state=2)\n",
    "\n",
    "# print(X_train.shape, X_test.shape)\n",
    "\n",
    "# classifier = svm.SVC(C=0.1 ,kernel='linear', gamma=0.001, class_weight=\"balanced\")\n",
    "# classifier = svm.SVC(C=0.1, kernel='linear', gamma='scale', class_weight='balanced', verbose=True)\n",
    "\n",
    "\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = classifier.predict(X_pca)\n",
    "# test_data_accuracy = accuracy_score(X_test_prediction,Y_test)\n",
    "print(X_test_prediction_final)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_df = pd.DataFrame(X_test_prediction_final_int, columns=['label'])\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_df.to_csv('predictions_culo.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Compute The Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_models' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m results \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[43mnum_models\u001b[49m):\n\u001b[1;32m      3\u001b[0m     model_dict \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m     model \u001b[38;5;241m=\u001b[39m NeuralNetwork(input_size) \u001b[38;5;66;03m# Instantiate your model class here\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_models' is not defined"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "for model_index in range(num_models):\n",
    "    model_dict = torch.load(f'model_{model_index}.pth')\n",
    "    model = NeuralNetwork(input_size) # Instantiate your model class here\n",
    "    model.load_state_dict(model_dict)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        X_test_tensor = torch.tensor(test_dataset.values, dtype=torch.float32)\n",
    "        outputs = model(X_test_tensor)\n",
    "        predicted = (outputs >= 0.5).float().reshape(-1, 1)  # Reshape to (10678, 1)\n",
    "        results.append(predicted)\n",
    "\n",
    "results = np.concatenate(results, axis=1)  # Concatenate along axis 1 to get shape (10678, 5)\n",
    "\n",
    "# Calculate mean along axis 1 to get shape (10678, 1)\n",
    "results_mean = np.mean(results, axis=1).reshape(-1, 1)\n",
    "\n",
    "print(results.shape)\n",
    "print(results_mean.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Export The CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10678,)\n"
     ]
    }
   ],
   "source": [
    "predicted_np = results_mean.flatten()\n",
    "print(predicted_np.shape)\n",
    "# Export the array to a CSV file with column name 'label' and each number on a different row\n",
    "np.savetxt('prediction.csv', predicted_np, fmt='%d', delimiter=',', header='label', comments='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
