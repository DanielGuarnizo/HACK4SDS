{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"/Users/danielguarnizo/Desktop/HACK4SDS/Dataset_DAY1/Data/train_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ej2yjUAA</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>7256587870</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q2X00000ZWC5LUAX</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>6178307100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q2X00000XcCCQUA3</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>7692855390</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ejSs3UAE</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>5752241730</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000eiRidUAE</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>7533506540</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ej2yjUAA    2021-11-30  7256587870                    10   \n",
       "1  a1Q2X00000ZWC5LUAX    2020-10-06  6178307100                     7   \n",
       "2  a1Q2X00000XcCCQUA3    2020-02-11  7692855390                     7   \n",
       "3  a1Q7R00000ejSs3UAE    2022-01-18  5752241730                     8   \n",
       "4  a1Q7R00000eiRidUAE    2021-09-16  7533506540                     4   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     3                 NaN   \n",
       "1                     3                 NaN   \n",
       "2                     3                 NaN   \n",
       "3                     2                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     NaN                      NaN   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  ...  avg_count_enti_affidanti  \\\n",
       "0                     NaN              MISSING  ...                         1   \n",
       "1                     NaN                    H  ...                         1   \n",
       "2                     NaN              MISSING  ...                         1   \n",
       "3                     NaN              MISSING  ...                         1   \n",
       "4                     NaN              MISSING  ...                         0   \n",
       "\n",
       "  std_count_enti_affidanti max_count_enti_affidanti last_count_enti_affidanti  \\\n",
       "0                        0                        1                         1   \n",
       "1                        0                        1                         1   \n",
       "2                        0                        1                         1   \n",
       "3                        0                        1                         1   \n",
       "4                        0                        0                         0   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0                           0                           0   \n",
       "1                           2                           0   \n",
       "2                           1                           0   \n",
       "3                         0,5           0,522232967867094   \n",
       "4                           0                           0   \n",
       "\n",
       "  max_count_numero_prima_info last_count_numero_prima_info days_to_default  \\\n",
       "0                           0                            0             522   \n",
       "1                           2                            2            1498   \n",
       "2                           1                            1             779   \n",
       "3                           1                            0            1498   \n",
       "4                           0                            0            1498   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>age</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>4544.000000</td>\n",
       "      <td>4824.000000</td>\n",
       "      <td>4824.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "      <td>32032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>6.772040</td>\n",
       "      <td>1.942433</td>\n",
       "      <td>9.286532</td>\n",
       "      <td>5.891505</td>\n",
       "      <td>6.039594</td>\n",
       "      <td>6.168947</td>\n",
       "      <td>8.972715</td>\n",
       "      <td>1.824894</td>\n",
       "      <td>2.928571</td>\n",
       "      <td>2.691964</td>\n",
       "      <td>1.146354</td>\n",
       "      <td>0.976773</td>\n",
       "      <td>1281.800356</td>\n",
       "      <td>0.215222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.764166</td>\n",
       "      <td>0.786342</td>\n",
       "      <td>2.760645</td>\n",
       "      <td>1.244978</td>\n",
       "      <td>1.302913</td>\n",
       "      <td>1.343487</td>\n",
       "      <td>9.003956</td>\n",
       "      <td>0.621009</td>\n",
       "      <td>3.321439</td>\n",
       "      <td>3.105271</td>\n",
       "      <td>1.494643</td>\n",
       "      <td>1.314287</td>\n",
       "      <td>426.997217</td>\n",
       "      <td>0.410983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>8.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>106.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1498.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       external_score_ver01  external_score_ver02  late_payment_score  \\\n",
       "count          32032.000000          32032.000000         4544.000000   \n",
       "mean               6.772040              1.942433            9.286532   \n",
       "std                1.764166              0.786342            2.760645   \n",
       "min                2.000000              1.000000            1.000000   \n",
       "25%                6.000000              1.000000            7.000000   \n",
       "50%                6.000000              2.000000            9.000000   \n",
       "75%                8.000000              3.000000           10.000000   \n",
       "max               10.000000              3.000000           20.000000   \n",
       "\n",
       "       external_score_late_payment_integrated  external_score_moderate  \\\n",
       "count                             4544.000000              4824.000000   \n",
       "mean                                 5.891505                 6.039594   \n",
       "std                                  1.244978                 1.302913   \n",
       "min                                  2.000000                 2.000000   \n",
       "25%                                  5.000000                 5.000000   \n",
       "50%                                  6.000000                 6.000000   \n",
       "75%                                  7.000000                 7.000000   \n",
       "max                                 10.000000                10.000000   \n",
       "\n",
       "       external_score_adverse           age  last_statement_age  \\\n",
       "count             4824.000000  32032.000000        32032.000000   \n",
       "mean                 6.168947      8.972715            1.824894   \n",
       "std                  1.343487      9.003956            0.621009   \n",
       "min                  2.000000      0.000000            0.000000   \n",
       "25%                  5.000000      3.000000            1.000000   \n",
       "50%                  6.000000      6.000000            2.000000   \n",
       "75%                  7.000000     11.000000            2.000000   \n",
       "max                 10.000000    106.000000            7.000000   \n",
       "\n",
       "       max_count_enti_affidanti  last_count_enti_affidanti  \\\n",
       "count              32032.000000               32032.000000   \n",
       "mean                   2.928571                   2.691964   \n",
       "std                    3.321439                   3.105271   \n",
       "min                    0.000000                   0.000000   \n",
       "25%                    1.000000                   1.000000   \n",
       "50%                    2.000000                   2.000000   \n",
       "75%                    4.000000                   4.000000   \n",
       "max                   50.000000                  45.000000   \n",
       "\n",
       "       max_count_numero_prima_info  last_count_numero_prima_info  \\\n",
       "count                 32032.000000                  32032.000000   \n",
       "mean                      1.146354                      0.976773   \n",
       "std                       1.494643                      1.314287   \n",
       "min                       0.000000                      0.000000   \n",
       "25%                       0.000000                      0.000000   \n",
       "50%                       1.000000                      1.000000   \n",
       "75%                       2.000000                      1.000000   \n",
       "max                      12.000000                     12.000000   \n",
       "\n",
       "       days_to_default        target  \n",
       "count     32032.000000  32032.000000  \n",
       "mean       1281.800356      0.215222  \n",
       "std         426.997217      0.410983  \n",
       "min           1.000000      0.000000  \n",
       "25%        1498.000000      0.000000  \n",
       "50%        1498.000000      0.000000  \n",
       "75%        1498.000000      0.000000  \n",
       "max        1498.000000      1.000000  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_dataset.values.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: xlabel='external_score_ver03', ylabel='count'>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='external_score_ver03', hue= 'juridical_form', data= train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# df = pd.read_csv(\"your_dataset.csv\")\n",
    "\n",
    "# Plot the distribution using Seaborn\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.countplot(data=train_dataset, x='external_score_ver03')\n",
    "plt.xlabel('Category Value')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Distribution of external_score_ver03')\n",
    "plt.xticks(rotation=45)  # Rotate x-axis labels for better readability\n",
    "plt.tight_layout()  # Adjust layout to prevent overlapping labels\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Clean and encode Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop unneeded columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features\n",
    "def Drop_unneed_columns(test, dataset):\n",
    "    cols= ['days_to_default', 'application_ID', 'decision_date', 'company_ID']\n",
    "    if test:\n",
    "        cols.remove('days_to_default')\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    else:\n",
    "        dataset= dataset.drop(columns=cols)\n",
    "    return dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Find columns with to many Nan's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_values(dataset):\n",
    "    column_names = dataset.columns.tolist()\n",
    "    drop_columns = []\n",
    "    for name in column_names:\n",
    "        nan_count = dataset[name].isna().sum()\n",
    "        print(f\"column {name}: {nan_count}\")\n",
    "        if (nan_count/28000) > 0.5:\n",
    "            print(f\"Number of NaN values in column '{name}': {nan_count}\")\n",
    "            drop_columns.append(name)\n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Label enconding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_cate_to_value(column_name, dataset):\n",
    "    # Extract categories\n",
    "\n",
    "    # Extract unique category names from the column\n",
    "    unique_categories = dataset[column_name].unique()\n",
    "\n",
    "    # convert 'numpy.ndarray' in to a python list\n",
    "    l = unique_categories.tolist()\n",
    "    \n",
    "    if 'MISSING' in l:\n",
    "        l.remove('MISSING')\n",
    "        l.sort(reverse=True)\n",
    "    # print(unique_categories)\n",
    "\n",
    "    # print(f\"remove{l}\")\n",
    "    dic = { l[i]:i+1 for i in range(0, len(l))}\n",
    "\n",
    "    # dic = {}\n",
    "\n",
    "    # for name in unique_categories:\n",
    "    #     if name != \"MISSING\":\n",
    "    #         dic{}\n",
    "    # print(dic)\n",
    "\n",
    "    # Replace values in the column based on the dictionary mapping\n",
    "    dataset[column_name] = dataset[column_name].replace(dic)\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Category_values(dataset):\n",
    "    column_names = ['industry_sector', 'region', 'geo_area','external_score_ver03', 'province','juridical_form']\n",
    "    dic = {}\n",
    "    for column_name in column_names:\n",
    "        category_dic, dataset = Replace_cate_to_value(column_name, dataset)\n",
    "        dic[column_name] = category_dic\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace True and False values to numerical values in Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_bool_toNumbers(dataset):\n",
    "    dataset['cr_available'] = [int(dataset['cr_available'][i]) for i in range(len(dataset['cr_available']))]\n",
    "    dataset['cr_available']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mean of external score var 03 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var03(dataset):\n",
    "    s0, s1, c0, c1 = 0,0,0,0\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row['external_score_ver03'] != 'MISSING':\n",
    "            if row['target'] == 0:\n",
    "                s0 += row['external_score_ver03']\n",
    "                c0 +=1\n",
    "            elif row['target'] == 1:\n",
    "                s1 +=  row['external_score_ver03']\n",
    "                c1 += 1\n",
    "\n",
    "    m0 = round(s0/c0)\n",
    "    m1 = round(s1/c1)\n",
    "    print(m0)\n",
    "    print(m1)\n",
    "    return m0,m1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace MISSING values to Mean finded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing(dataset, m0, m1):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset['target'] == 1) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m1\n",
    "    dataset.loc[(dataset['target'] == 0) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m0\n",
    "    dataset['external_score_ver03']\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Main code for train dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column external_score_ver01: 0\n",
      "column external_score_ver02: 0\n",
      "column late_payment_score: 27488\n",
      "Number of NaN values in column 'late_payment_score': 27488\n",
      "column external_score_late_payment_integrated: 27488\n",
      "Number of NaN values in column 'external_score_late_payment_integrated': 27488\n",
      "column external_score_moderate: 27208\n",
      "Number of NaN values in column 'external_score_moderate': 27208\n",
      "column external_score_adverse: 27208\n",
      "Number of NaN values in column 'external_score_adverse': 27208\n",
      "column external_score_ver03: 0\n",
      "column age: 0\n",
      "column province: 2654\n",
      "column juridical_form: 0\n",
      "column industry_sector: 0\n",
      "column gross_margin_ratio: 0\n",
      "column core_income_ratio: 0\n",
      "column cash_asset_ratio: 0\n",
      "column consolidated_liabilities_ratio: 0\n",
      "column tangible_assets_ratio: 0\n",
      "column revenues: 0\n",
      "column cr_available: 0\n",
      "column region: 0\n",
      "column geo_area: 0\n",
      "column last_statement_age: 0\n",
      "column overrun_freq_a_revoca_autoliquidanti: 0\n",
      "column avg_tension_a_revoca_autoliquidanti: 0\n",
      "column std_tension_a_revoca_autoliquidanti: 0\n",
      "column max_tension_a_revoca_autoliquidanti: 0\n",
      "column last_tension_a_revoca_autoliquidanti: 0\n",
      "column avg_rel_used_a_revoca_autoliquidanti: 0\n",
      "column std_rel_used_a_revoca_autoliquidanti: 0\n",
      "column max_rel_used_a_revoca_autoliquidanti: 0\n",
      "column last_rel_used_a_revoca_autoliquidanti: 0\n",
      "column overrun_freq_a_scadenza: 0\n",
      "column avg_rel_used_a_scadenza: 0\n",
      "column std_rel_used_a_scadenza: 0\n",
      "column max_rel_used_a_scadenza: 0\n",
      "column last_rel_used_a_scadenza: 0\n",
      "column avg_count_enti_affidanti: 0\n",
      "column std_count_enti_affidanti: 0\n",
      "column max_count_enti_affidanti: 0\n",
      "column last_count_enti_affidanti: 0\n",
      "column avg_count_numero_prima_info: 0\n",
      "column std_count_numero_prima_info: 0\n",
      "column max_count_numero_prima_info: 0\n",
      "column last_count_numero_prima_info: 0\n",
      "column target: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop columns \n",
    "train_dataset = Drop_unneed_columns(False,train_dataset)\n",
    "drop_columns = Nan_values(train_dataset)\n",
    "train_dataset = train_dataset.drop(columns=drop_columns)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_1212/238755991.py:26: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset[column_name] = dataset[column_name].replace(dic)\n"
     ]
    }
   ],
   "source": [
    "# replace bool values to numerical ones \n",
    "category_dics, train_dataset = Category_values(train_dataset)\n",
    "train_dataset = Replace_bool_toNumbers(train_dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# v03 column with missing values \n",
    "m0, m1= mean_var03(train_dataset)\n",
    "train_dataset = Replace_missing(train_dataset, m0, m1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Normalise Datase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replace the \",\" to \".\", in such a way to pass from object to number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalise Columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"green\"> Main code Normalise Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                  int64\n",
      "juridical_form                            int64\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                    int64\n",
      "geo_area                                  int64\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "target                                    int64\n",
      "dtype: object\n",
      "DataFrame does not contain any NaN values.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_1212/2113528616.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset = dataset.replace(',', '.', regex=True)\n"
     ]
    }
   ],
   "source": [
    "train_dataset = normalized_data(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.176975</td>\n",
       "      <td>2.111932e-03</td>\n",
       "      <td>0.179073</td>\n",
       "      <td>0.172032</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>0.484043</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.151754</td>\n",
       "      <td>6.806286e-03</td>\n",
       "      <td>0.164755</td>\n",
       "      <td>0.146385</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.375000</td>\n",
       "      <td>471.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.136150</td>\n",
       "      <td>0.765125</td>\n",
       "      <td>0.058824</td>\n",
       "      <td>598.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.025084</td>\n",
       "      <td>2.619898e-02</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>0.050167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>0.197368</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>108.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.673177</td>\n",
       "      <td>0.026609</td>\n",
       "      <td>0.192248</td>\n",
       "      <td>0.252604</td>\n",
       "      <td>0.504065</td>\n",
       "      <td>2073.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.060680</td>\n",
       "      <td>3.722236e-02</td>\n",
       "      <td>0.146051</td>\n",
       "      <td>0.146051</td>\n",
       "      <td>2.250000</td>\n",
       "      <td>0.452267</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.916667</td>\n",
       "      <td>0.668558</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.666667</td>\n",
       "      <td>0.017544</td>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.277778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.307391</td>\n",
       "      <td>0.010648</td>\n",
       "      <td>0.080271</td>\n",
       "      <td>0.157611</td>\n",
       "      <td>0.843066</td>\n",
       "      <td>12209.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.458545</td>\n",
       "      <td>0.248584</td>\n",
       "      <td>0.790275</td>\n",
       "      <td>0.202147</td>\n",
       "      <td>0.027610</td>\n",
       "      <td>0.013843</td>\n",
       "      <td>0.045343</td>\n",
       "      <td>0.012444</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.020232</td>\n",
       "      <td>2.002530e-02</td>\n",
       "      <td>0.040953</td>\n",
       "      <td>0.037795</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.621582</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.457291</td>\n",
       "      <td>0.068892</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.369089</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>584.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>12637.000000</td>\n",
       "      <td>43775.539062</td>\n",
       "      <td>151643.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.002856</td>\n",
       "      <td>0.009886</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.034247</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.094279</td>\n",
       "      <td>4.360371e-04</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>0.095017</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.221461</td>\n",
       "      <td>-0.045290</td>\n",
       "      <td>0.051724</td>\n",
       "      <td>0.081050</td>\n",
       "      <td>0.715017</td>\n",
       "      <td>552.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.084112</td>\n",
       "      <td>0.015926</td>\n",
       "      <td>0.153680</td>\n",
       "      <td>0.132710</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1507.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.701977</td>\n",
       "      <td>0.145203</td>\n",
       "      <td>0.999676</td>\n",
       "      <td>0.670731</td>\n",
       "      <td>0.069734</td>\n",
       "      <td>0.014225</td>\n",
       "      <td>0.096186</td>\n",
       "      <td>0.064536</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.041406</td>\n",
       "      <td>1.724269e-02</td>\n",
       "      <td>0.059721</td>\n",
       "      <td>0.055987</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.502591</td>\n",
       "      <td>0.058766</td>\n",
       "      <td>0.154930</td>\n",
       "      <td>0.465026</td>\n",
       "      <td>0.676364</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.171200</td>\n",
       "      <td>5.174890e-02</td>\n",
       "      <td>0.229672</td>\n",
       "      <td>0.214628</td>\n",
       "      <td>3.083333</td>\n",
       "      <td>1.083625</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.996205</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.356986</td>\n",
       "      <td>0.034757</td>\n",
       "      <td>0.216390</td>\n",
       "      <td>0.423127</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>1752.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.642653</td>\n",
       "      <td>0.159023</td>\n",
       "      <td>0.858100</td>\n",
       "      <td>0.615092</td>\n",
       "      <td>0.194926</td>\n",
       "      <td>0.047999</td>\n",
       "      <td>0.259955</td>\n",
       "      <td>0.187009</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.234372</td>\n",
       "      <td>5.594047e-02</td>\n",
       "      <td>0.285388</td>\n",
       "      <td>0.265908</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.389249</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.187500</td>\n",
       "      <td>-0.095941</td>\n",
       "      <td>0.092308</td>\n",
       "      <td>0.122159</td>\n",
       "      <td>0.740741</td>\n",
       "      <td>277.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010555</td>\n",
       "      <td>0.036563</td>\n",
       "      <td>0.126657</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.001334</td>\n",
       "      <td>0.004620</td>\n",
       "      <td>0.016004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.349027</td>\n",
       "      <td>6.285652e-03</td>\n",
       "      <td>0.358538</td>\n",
       "      <td>0.339361</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.361522</td>\n",
       "      <td>0.007576</td>\n",
       "      <td>0.107092</td>\n",
       "      <td>0.284884</td>\n",
       "      <td>0.072614</td>\n",
       "      <td>1768.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.396210</td>\n",
       "      <td>0.120278</td>\n",
       "      <td>0.609917</td>\n",
       "      <td>0.294906</td>\n",
       "      <td>0.130983</td>\n",
       "      <td>0.039988</td>\n",
       "      <td>0.201627</td>\n",
       "      <td>0.097028</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.182228</td>\n",
       "      <td>1.410236e-02</td>\n",
       "      <td>0.210419</td>\n",
       "      <td>0.176218</td>\n",
       "      <td>5.666667</td>\n",
       "      <td>0.492366</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.501767</td>\n",
       "      <td>0.030769</td>\n",
       "      <td>0.323009</td>\n",
       "      <td>0.084806</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>208.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>2.898975e-17</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>0.126764</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.335260</td>\n",
       "      <td>0.066454</td>\n",
       "      <td>0.406977</td>\n",
       "      <td>0.554913</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1565.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.169214</td>\n",
       "      <td>0.255193</td>\n",
       "      <td>0.632867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003244</td>\n",
       "      <td>0.004892</td>\n",
       "      <td>0.012132</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.081779</td>\n",
       "      <td>1.744957e-02</td>\n",
       "      <td>0.095847</td>\n",
       "      <td>0.095847</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.060606</td>\n",
       "      <td>0.021978</td>\n",
       "      <td>0.306452</td>\n",
       "      <td>0.045455</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>182.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.045024</td>\n",
       "      <td>-0.447154</td>\n",
       "      <td>0.188889</td>\n",
       "      <td>0.146919</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>182.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.332279</td>\n",
       "      <td>0.171461</td>\n",
       "      <td>0.658733</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.052502</td>\n",
       "      <td>0.027683</td>\n",
       "      <td>0.082725</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.634728</td>\n",
       "      <td>7.677177e-02</td>\n",
       "      <td>0.746165</td>\n",
       "      <td>0.746165</td>\n",
       "      <td>1.916667</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.255639</td>\n",
       "      <td>0.019715</td>\n",
       "      <td>0.210938</td>\n",
       "      <td>0.413534</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>913.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016453</td>\n",
       "      <td>2.430452e-02</td>\n",
       "      <td>0.049733</td>\n",
       "      <td>0.048723</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>10.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.961410</td>\n",
       "      <td>0.166273</td>\n",
       "      <td>1.179400</td>\n",
       "      <td>1.172486</td>\n",
       "      <td>0.074173</td>\n",
       "      <td>0.017088</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.100090</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072884</td>\n",
       "      <td>1.291411e-02</td>\n",
       "      <td>0.092295</td>\n",
       "      <td>0.083193</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.325444</td>\n",
       "      <td>0.046025</td>\n",
       "      <td>0.116788</td>\n",
       "      <td>0.544379</td>\n",
       "      <td>0.531250</td>\n",
       "      <td>239.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.177833</td>\n",
       "      <td>0.330063</td>\n",
       "      <td>0.909000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003720</td>\n",
       "      <td>0.006905</td>\n",
       "      <td>0.019017</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.266932</td>\n",
       "      <td>6.039229e-03</td>\n",
       "      <td>0.286109</td>\n",
       "      <td>0.286109</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.486056</td>\n",
       "      <td>0.057692</td>\n",
       "      <td>0.027473</td>\n",
       "      <td>0.422311</td>\n",
       "      <td>0.007246</td>\n",
       "      <td>988.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.051943</td>\n",
       "      <td>0.053098</td>\n",
       "      <td>0.154785</td>\n",
       "      <td>0.037854</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.008911</td>\n",
       "      <td>0.025983</td>\n",
       "      <td>0.006371</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.019821</td>\n",
       "      <td>1.210318e-02</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>0.030364</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.229962</td>\n",
       "      <td>0.029637</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.370582</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>946.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>2.898975e-17</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>0.162474</td>\n",
       "      <td>1.083333</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>1.167748</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.478309</td>\n",
       "      <td>-0.066730</td>\n",
       "      <td>0.061611</td>\n",
       "      <td>0.389321</td>\n",
       "      <td>0.109012</td>\n",
       "      <td>990.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.028333</td>\n",
       "      <td>0.061643</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000093</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.027778</td>\n",
       "      <td>8.747864e-03</td>\n",
       "      <td>0.030308</td>\n",
       "      <td>0.030303</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.408955</td>\n",
       "      <td>0.013657</td>\n",
       "      <td>0.129181</td>\n",
       "      <td>0.419901</td>\n",
       "      <td>0.768116</td>\n",
       "      <td>1337.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071703</td>\n",
       "      <td>0.085131</td>\n",
       "      <td>0.240817</td>\n",
       "      <td>0.114286</td>\n",
       "      <td>0.009411</td>\n",
       "      <td>0.011168</td>\n",
       "      <td>0.031521</td>\n",
       "      <td>0.014959</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.134426</td>\n",
       "      <td>1.642027e-03</td>\n",
       "      <td>0.135087</td>\n",
       "      <td>0.129804</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.416002</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>410.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>1.046128</td>\n",
       "      <td>0.040009</td>\n",
       "      <td>1.114067</td>\n",
       "      <td>1.006933</td>\n",
       "      <td>0.038273</td>\n",
       "      <td>0.001464</td>\n",
       "      <td>0.040759</td>\n",
       "      <td>0.036839</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.180244</td>\n",
       "      <td>3.767771e-02</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>0.222927</td>\n",
       "      <td>1.416667</td>\n",
       "      <td>0.514929</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.463576</td>\n",
       "      <td>0.097458</td>\n",
       "      <td>0.065217</td>\n",
       "      <td>0.218543</td>\n",
       "      <td>0.983051</td>\n",
       "      <td>236.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.420786</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.092803</td>\n",
       "      <td>0.430292</td>\n",
       "      <td>0.093870</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.867331</td>\n",
       "      <td>0.073822</td>\n",
       "      <td>0.967480</td>\n",
       "      <td>0.936377</td>\n",
       "      <td>0.290532</td>\n",
       "      <td>0.025495</td>\n",
       "      <td>0.332647</td>\n",
       "      <td>0.294638</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.252414</td>\n",
       "      <td>4.928930e-02</td>\n",
       "      <td>0.393825</td>\n",
       "      <td>0.393825</td>\n",
       "      <td>7.083333</td>\n",
       "      <td>1.240112</td>\n",
       "      <td>8.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>2.833333</td>\n",
       "      <td>1.029857</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    external_score_ver01  external_score_ver02  external_score_ver03   age  \\\n",
       "0                   10.0                   3.0                  10.0  15.0   \n",
       "1                    7.0                   3.0                   7.0   5.0   \n",
       "2                    7.0                   3.0                  10.0   5.0   \n",
       "3                    8.0                   2.0                   8.0   6.0   \n",
       "4                    4.0                   1.0                   8.0   5.0   \n",
       "5                    6.0                   1.0                  12.0   2.0   \n",
       "6                    7.0                   3.0                  10.0   3.0   \n",
       "7                    6.0                   1.0                  10.0   9.0   \n",
       "8                   10.0                   3.0                  10.0   2.0   \n",
       "9                    7.0                   2.0                   8.0  12.0   \n",
       "10                  10.0                   2.0                   7.0   0.0   \n",
       "11                   5.0                   2.0                   9.0   6.0   \n",
       "12                   6.0                   2.0                   8.0   8.0   \n",
       "13                   6.0                   1.0                   8.0  14.0   \n",
       "14                   5.0                   3.0                   8.0   6.0   \n",
       "15                   6.0                   1.0                  10.0  17.0   \n",
       "16                   6.0                   1.0                  10.0   6.0   \n",
       "17                   4.0                   2.0                   9.0   2.0   \n",
       "18                   8.0                   2.0                  11.0   3.0   \n",
       "19                   8.0                   2.0                  10.0   5.0   \n",
       "20                   7.0                   2.0                   6.0   7.0   \n",
       "21                  10.0                   2.0                  11.0   5.0   \n",
       "22                   6.0                   3.0                  10.0  11.0   \n",
       "23                   4.0                   2.0                   4.0  11.0   \n",
       "24                   8.0                   2.0                   5.0   7.0   \n",
       "25                   6.0                   1.0                   8.0   2.0   \n",
       "26                   5.0                   1.0                   7.0  21.0   \n",
       "27                  10.0                   3.0                  14.0   6.0   \n",
       "28                   7.0                   2.0                   7.0   2.0   \n",
       "29                   8.0                   1.0                   9.0   6.0   \n",
       "\n",
       "    province  juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0        1.0             1.0              1.0            0.464637   \n",
       "1        2.0             2.0              2.0            0.372340   \n",
       "2        3.0             1.0              3.0            0.270000   \n",
       "3        4.0             1.0              1.0            0.419929   \n",
       "4        5.0             1.0              1.0            0.526316   \n",
       "5        6.0             1.0              4.0            0.673177   \n",
       "6        7.0             2.0              1.0            1.666667   \n",
       "7        8.0             1.0              5.0            0.307391   \n",
       "8        9.0             1.0              2.0            0.457291   \n",
       "9       10.0             3.0              6.0            0.221461   \n",
       "10      11.0             1.0              1.0            0.464637   \n",
       "11      12.0             3.0              1.0            0.084112   \n",
       "12      13.0             4.0              4.0            0.502591   \n",
       "13       5.0             1.0              1.0            0.356986   \n",
       "14       4.0             1.0              1.0            0.187500   \n",
       "15      14.0             1.0              7.0            0.361522   \n",
       "16      15.0             1.0              8.0            0.501767   \n",
       "17      16.0             1.0              2.0            0.335260   \n",
       "18      17.0             1.0              1.0            0.060606   \n",
       "19      18.0             1.0              1.0           -0.045024   \n",
       "20       8.0             1.0              2.0            0.255639   \n",
       "21       6.0             1.0              1.0            0.464637   \n",
       "22       4.0             1.0              2.0            0.325444   \n",
       "23      19.0             1.0              1.0            0.486056   \n",
       "24       4.0             1.0              3.0            0.229962   \n",
       "25      20.0             1.0              9.0            0.478309   \n",
       "26       6.0             3.0              2.0            0.408955   \n",
       "27      21.0             4.0              1.0            0.464637   \n",
       "28       8.0             1.0              4.0            0.463576   \n",
       "29       6.0             1.0             10.0            0.420786   \n",
       "\n",
       "    core_income_ratio  cash_asset_ratio  consolidated_liabilities_ratio  \\\n",
       "0            0.012593          0.000000                        0.416002   \n",
       "1            0.115385          0.235955                        0.484043   \n",
       "2            0.006369          0.359375                        0.125000   \n",
       "3            0.152174          0.136150                        0.765125   \n",
       "4            0.083333          0.233333                        0.197368   \n",
       "5            0.026609          0.192248                        0.252604   \n",
       "6            0.017544          0.615385                        0.277778   \n",
       "7            0.010648          0.080271                        0.157611   \n",
       "8            0.068892          0.000000                        0.369089   \n",
       "9           -0.045290          0.051724                        0.081050   \n",
       "10           0.012593          0.000000                        0.416002   \n",
       "11           0.015926          0.153680                        0.132710   \n",
       "12           0.058766          0.154930                        0.465026   \n",
       "13           0.034757          0.216390                        0.423127   \n",
       "14          -0.095941          0.092308                        0.122159   \n",
       "15           0.007576          0.107092                        0.284884   \n",
       "16           0.030769          0.323009                        0.084806   \n",
       "17           0.066454          0.406977                        0.554913   \n",
       "18           0.021978          0.306452                        0.045455   \n",
       "19          -0.447154          0.188889                        0.146919   \n",
       "20           0.019715          0.210938                        0.413534   \n",
       "21           0.012593          0.000000                        0.416002   \n",
       "22           0.046025          0.116788                        0.544379   \n",
       "23           0.057692          0.027473                        0.422311   \n",
       "24           0.029637          0.000000                        0.370582   \n",
       "25          -0.066730          0.061611                        0.389321   \n",
       "26           0.013657          0.129181                        0.419901   \n",
       "27           0.012593          0.000000                        0.416002   \n",
       "28           0.097458          0.065217                        0.218543   \n",
       "29           0.012346          0.092803                        0.430292   \n",
       "\n",
       "    tangible_assets_ratio  revenues  cr_available  region  geo_area  \\\n",
       "0                1.000000     410.0           1.0     1.0       1.0   \n",
       "1                1.000000     208.0           1.0     2.0       1.0   \n",
       "2                0.375000     471.0           0.0     3.0       2.0   \n",
       "3                0.058824     598.0           1.0     4.0       3.0   \n",
       "4                0.750000     108.0           0.0     5.0       4.0   \n",
       "5                0.504065    2073.0           1.0     6.0       5.0   \n",
       "6                0.000000      57.0           0.0     7.0       2.0   \n",
       "7                0.843066   12209.0           1.0     8.0       5.0   \n",
       "8                1.000000     584.0           1.0     9.0       2.0   \n",
       "9                0.715017     552.0           0.0    10.0       2.0   \n",
       "10               1.000000     410.0           0.0     6.0       5.0   \n",
       "11               1.000000    1507.0           1.0     2.0       1.0   \n",
       "12               0.676364    1100.0           1.0     4.0       3.0   \n",
       "13               0.038462    1752.0           1.0     5.0       4.0   \n",
       "14               0.740741     277.0           1.0     4.0       3.0   \n",
       "15               0.072614    1768.0           1.0    11.0       4.0   \n",
       "16               1.000000     208.0           1.0    12.0       3.0   \n",
       "17               0.500000    1565.0           1.0    11.0       4.0   \n",
       "18               0.500000     182.0           0.0     5.0       4.0   \n",
       "19               0.060241     182.0           1.0     5.0       4.0   \n",
       "20               0.200000     913.0           1.0     8.0       5.0   \n",
       "21               1.000000     410.0           1.0     6.0       5.0   \n",
       "22               0.531250     239.0           1.0     4.0       3.0   \n",
       "23               0.007246     988.0           1.0     3.0       2.0   \n",
       "24               1.000000     946.0           1.0     4.0       3.0   \n",
       "25               0.109012     990.0           1.0    13.0       3.0   \n",
       "26               0.768116    1337.0           1.0     6.0       5.0   \n",
       "27               1.000000     410.0           1.0     1.0       1.0   \n",
       "28               0.983051     236.0           0.0     8.0       5.0   \n",
       "29               0.093870    1134.0           1.0     6.0       5.0   \n",
       "\n",
       "    last_statement_age  overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                  2.0                              0.000000   \n",
       "1                  3.0                              0.000000   \n",
       "2                  2.0                              0.000000   \n",
       "3                  3.0                              0.000000   \n",
       "4                  2.0                              0.000000   \n",
       "5                  1.0                              0.000000   \n",
       "6                  2.0                              0.000000   \n",
       "7                  3.0                              0.000000   \n",
       "8                  2.0                              0.083333   \n",
       "9                  3.0                              0.000000   \n",
       "10                 2.0                              0.000000   \n",
       "11                 2.0                              0.000000   \n",
       "12                 2.0                              0.000000   \n",
       "13                 2.0                              0.000000   \n",
       "14                 1.0                              0.000000   \n",
       "15                 1.0                              0.000000   \n",
       "16                 2.0                              0.000000   \n",
       "17                 2.0                              0.000000   \n",
       "18                 2.0                              0.000000   \n",
       "19                 1.0                              0.000000   \n",
       "20                 2.0                              0.000000   \n",
       "21                 2.0                              0.416667   \n",
       "22                 2.0                              0.000000   \n",
       "23                 2.0                              0.000000   \n",
       "24                 2.0                              0.000000   \n",
       "25                 2.0                              0.000000   \n",
       "26                 1.0                              0.000000   \n",
       "27                 2.0                              0.833333   \n",
       "28                 2.0                              0.000000   \n",
       "29                 2.0                              0.416667   \n",
       "\n",
       "    avg_tension_a_revoca_autoliquidanti  std_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0.000000                             0.000000   \n",
       "1                              0.000000                             0.000000   \n",
       "2                              0.000000                             0.000000   \n",
       "3                              0.000000                             0.000000   \n",
       "4                              0.000000                             0.000000   \n",
       "5                              0.000000                             0.000000   \n",
       "6                              0.000000                             0.000000   \n",
       "7                              0.458545                             0.248584   \n",
       "8                          12637.000000                         43775.539062   \n",
       "9                              0.000000                             0.000000   \n",
       "10                             0.000000                             0.000000   \n",
       "11                             0.701977                             0.145203   \n",
       "12                             0.000000                             0.000000   \n",
       "13                             0.642653                             0.159023   \n",
       "14                             0.010555                             0.036563   \n",
       "15                             0.396210                             0.120278   \n",
       "16                             0.000000                             0.000000   \n",
       "17                             0.169214                             0.255193   \n",
       "18                             0.000000                             0.000000   \n",
       "19                             0.332279                             0.171461   \n",
       "20                             0.000000                             0.000000   \n",
       "21                             0.961410                             0.166273   \n",
       "22                             0.177833                             0.330063   \n",
       "23                             0.051943                             0.053098   \n",
       "24                             0.000000                             0.000000   \n",
       "25                             0.028333                             0.061643   \n",
       "26                             0.071703                             0.085131   \n",
       "27                             1.046128                             0.040009   \n",
       "28                             0.000000                             0.000000   \n",
       "29                             0.867331                             0.073822   \n",
       "\n",
       "    max_tension_a_revoca_autoliquidanti  last_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0.000000                              0.000000   \n",
       "1                              0.000000                              0.000000   \n",
       "2                              0.000000                              0.000000   \n",
       "3                              0.000000                              0.000000   \n",
       "4                              0.000000                              0.000000   \n",
       "5                              0.000000                              0.000000   \n",
       "6                              0.000000                              0.000000   \n",
       "7                              0.790275                              0.202147   \n",
       "8                         151643.000000                              1.000000   \n",
       "9                              0.000000                              0.000000   \n",
       "10                             0.000000                              0.000000   \n",
       "11                             0.999676                              0.670731   \n",
       "12                             0.000000                              0.000000   \n",
       "13                             0.858100                              0.615092   \n",
       "14                             0.126657                              0.000000   \n",
       "15                             0.609917                              0.294906   \n",
       "16                             0.000000                              0.000000   \n",
       "17                             0.632867                              0.000000   \n",
       "18                             0.000000                              0.000000   \n",
       "19                             0.658733                              0.000000   \n",
       "20                             0.000000                              0.000000   \n",
       "21                             1.179400                              1.172486   \n",
       "22                             0.909000                              0.000000   \n",
       "23                             0.154785                              0.037854   \n",
       "24                             0.000000                              0.000000   \n",
       "25                             0.184000                              0.000000   \n",
       "26                             0.240817                              0.114286   \n",
       "27                             1.114067                              1.006933   \n",
       "28                             0.000000                              0.000000   \n",
       "29                             0.967480                              0.936377   \n",
       "\n",
       "    avg_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.027610   \n",
       "8                               0.002856   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.069734   \n",
       "12                              0.000000   \n",
       "13                              0.194926   \n",
       "14                              0.001334   \n",
       "15                              0.130983   \n",
       "16                              0.000000   \n",
       "17                              0.003244   \n",
       "18                              0.000000   \n",
       "19                              0.052502   \n",
       "20                              0.000000   \n",
       "21                              0.074173   \n",
       "22                              0.003720   \n",
       "23                              0.008719   \n",
       "24                              0.000000   \n",
       "25                              0.000014   \n",
       "26                              0.009411   \n",
       "27                              0.038273   \n",
       "28                              0.000000   \n",
       "29                              0.290532   \n",
       "\n",
       "    std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.013843   \n",
       "8                               0.009886   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.014225   \n",
       "12                              0.000000   \n",
       "13                              0.047999   \n",
       "14                              0.004620   \n",
       "15                              0.039988   \n",
       "16                              0.000000   \n",
       "17                              0.004892   \n",
       "18                              0.000000   \n",
       "19                              0.027683   \n",
       "20                              0.000000   \n",
       "21                              0.017088   \n",
       "22                              0.006905   \n",
       "23                              0.008911   \n",
       "24                              0.000000   \n",
       "25                              0.000031   \n",
       "26                              0.011168   \n",
       "27                              0.001464   \n",
       "28                              0.000000   \n",
       "29                              0.025495   \n",
       "\n",
       "    max_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                               0.000000   \n",
       "1                               0.000000   \n",
       "2                               0.000000   \n",
       "3                               0.000000   \n",
       "4                               0.000000   \n",
       "5                               0.000000   \n",
       "6                               0.000000   \n",
       "7                               0.045343   \n",
       "8                               0.034247   \n",
       "9                               0.000000   \n",
       "10                              0.000000   \n",
       "11                              0.096186   \n",
       "12                              0.000000   \n",
       "13                              0.259955   \n",
       "14                              0.016004   \n",
       "15                              0.201627   \n",
       "16                              0.000000   \n",
       "17                              0.012132   \n",
       "18                              0.000000   \n",
       "19                              0.082725   \n",
       "20                              0.000000   \n",
       "21                              0.100090   \n",
       "22                              0.019017   \n",
       "23                              0.025983   \n",
       "24                              0.000000   \n",
       "25                              0.000093   \n",
       "26                              0.031521   \n",
       "27                              0.040759   \n",
       "28                              0.000000   \n",
       "29                              0.332647   \n",
       "\n",
       "    last_rel_used_a_revoca_autoliquidanti  overrun_freq_a_scadenza  \\\n",
       "0                                0.000000                 0.250000   \n",
       "1                                0.000000                 0.000000   \n",
       "2                                0.000000                 0.000000   \n",
       "3                                0.000000                 0.000000   \n",
       "4                                0.000000                 0.000000   \n",
       "5                                0.000000                 0.250000   \n",
       "6                                0.000000                 0.000000   \n",
       "7                                0.012444                 0.000000   \n",
       "8                                0.034247                 0.000000   \n",
       "9                                0.000000                 0.000000   \n",
       "10                               0.000000                 0.000000   \n",
       "11                               0.064536                 0.000000   \n",
       "12                               0.000000                 0.000000   \n",
       "13                               0.187009                 0.000000   \n",
       "14                               0.000000                 0.000000   \n",
       "15                               0.097028                 0.000000   \n",
       "16                               0.000000                 0.000000   \n",
       "17                               0.000000                 0.000000   \n",
       "18                               0.000000                 0.000000   \n",
       "19                               0.000000                 0.000000   \n",
       "20                               0.000000                 0.000000   \n",
       "21                               0.100090                 0.000000   \n",
       "22                               0.000000                 0.000000   \n",
       "23                               0.006371                 0.000000   \n",
       "24                               0.000000                 0.000000   \n",
       "25                               0.000000                 0.083333   \n",
       "26                               0.014959                 0.000000   \n",
       "27                               0.036839                 0.000000   \n",
       "28                               0.000000                 0.000000   \n",
       "29                               0.294638                 0.000000   \n",
       "\n",
       "    avg_rel_used_a_scadenza  std_rel_used_a_scadenza  max_rel_used_a_scadenza  \\\n",
       "0                  0.176975             2.111932e-03                 0.179073   \n",
       "1                  0.151754             6.806286e-03                 0.164755   \n",
       "2                  0.000000             0.000000e+00                 0.000000   \n",
       "3                  0.025084             2.619898e-02                 0.050167   \n",
       "4                  0.000000             0.000000e+00                 0.000000   \n",
       "5                  0.060680             3.722236e-02                 0.146051   \n",
       "6                  0.000000             0.000000e+00                 0.000000   \n",
       "7                  0.020232             2.002530e-02                 0.040953   \n",
       "8                  0.094279             4.360371e-04                 0.095017   \n",
       "9                  0.000000             0.000000e+00                 0.000000   \n",
       "10                 0.000000             0.000000e+00                 0.000000   \n",
       "11                 0.041406             1.724269e-02                 0.059721   \n",
       "12                 0.171200             5.174890e-02                 0.229672   \n",
       "13                 0.234372             5.594047e-02                 0.285388   \n",
       "14                 0.349027             6.285652e-03                 0.358538   \n",
       "15                 0.182228             1.410236e-02                 0.210419   \n",
       "16                 0.126764             2.898975e-17                 0.126764   \n",
       "17                 0.081779             1.744957e-02                 0.095847   \n",
       "18                 0.000000             0.000000e+00                 0.000000   \n",
       "19                 0.634728             7.677177e-02                 0.746165   \n",
       "20                 0.016453             2.430452e-02                 0.049733   \n",
       "21                 0.072884             1.291411e-02                 0.092295   \n",
       "22                 0.266932             6.039229e-03                 0.286109   \n",
       "23                 0.019821             1.210318e-02                 0.030364   \n",
       "24                 0.162474             2.898975e-17                 0.162474   \n",
       "25                 0.027778             8.747864e-03                 0.030308   \n",
       "26                 0.134426             1.642027e-03                 0.135087   \n",
       "27                 0.180244             3.767771e-02                 0.222927   \n",
       "28                 0.000000             0.000000e+00                 0.000000   \n",
       "29                 0.252414             4.928930e-02                 0.393825   \n",
       "\n",
       "    last_rel_used_a_scadenza  avg_count_enti_affidanti  \\\n",
       "0                   0.172032                  1.000000   \n",
       "1                   0.146385                  1.000000   \n",
       "2                   0.000000                  1.000000   \n",
       "3                   0.050167                  1.000000   \n",
       "4                   0.000000                  0.000000   \n",
       "5                   0.146051                  2.250000   \n",
       "6                   0.000000                  0.000000   \n",
       "7                   0.037795                  6.000000   \n",
       "8                   0.095017                  1.000000   \n",
       "9                   0.000000                  0.000000   \n",
       "10                  0.000000                  0.000000   \n",
       "11                  0.055987                  1.000000   \n",
       "12                  0.214628                  3.083333   \n",
       "13                  0.265908                  3.000000   \n",
       "14                  0.339361                  2.000000   \n",
       "15                  0.176218                  5.666667   \n",
       "16                  0.126764                  1.000000   \n",
       "17                  0.095847                  1.000000   \n",
       "18                  0.000000                  0.000000   \n",
       "19                  0.746165                  1.916667   \n",
       "20                  0.048723                  1.000000   \n",
       "21                  0.083193                  1.000000   \n",
       "22                  0.286109                  2.000000   \n",
       "23                  0.030364                  3.000000   \n",
       "24                  0.162474                  1.083333   \n",
       "25                  0.030303                  1.000000   \n",
       "26                  0.129804                  2.000000   \n",
       "27                  0.222927                  1.416667   \n",
       "28                  0.000000                  0.000000   \n",
       "29                  0.393825                  7.083333   \n",
       "\n",
       "    std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0                   0.000000                       1.0   \n",
       "1                   0.000000                       1.0   \n",
       "2                   0.000000                       1.0   \n",
       "3                   0.000000                       1.0   \n",
       "4                   0.000000                       0.0   \n",
       "5                   0.452267                       3.0   \n",
       "6                   0.000000                       0.0   \n",
       "7                   0.000000                       6.0   \n",
       "8                   0.000000                       1.0   \n",
       "9                   0.000000                       0.0   \n",
       "10                  0.000000                       0.0   \n",
       "11                  0.000000                       1.0   \n",
       "12                  1.083625                       4.0   \n",
       "13                  0.000000                       3.0   \n",
       "14                  0.000000                       2.0   \n",
       "15                  0.492366                       6.0   \n",
       "16                  0.000000                       1.0   \n",
       "17                  0.000000                       1.0   \n",
       "18                  0.000000                       0.0   \n",
       "19                  0.288675                       2.0   \n",
       "20                  0.000000                       1.0   \n",
       "21                  0.000000                       1.0   \n",
       "22                  0.000000                       2.0   \n",
       "23                  0.000000                       3.0   \n",
       "24                  0.288675                       2.0   \n",
       "25                  0.000000                       1.0   \n",
       "26                  0.000000                       2.0   \n",
       "27                  0.514929                       2.0   \n",
       "28                  0.000000                       0.0   \n",
       "29                  1.240112                       8.0   \n",
       "\n",
       "    last_count_enti_affidanti  avg_count_numero_prima_info  \\\n",
       "0                         1.0                     0.000000   \n",
       "1                         1.0                     2.000000   \n",
       "2                         1.0                     1.000000   \n",
       "3                         1.0                     0.500000   \n",
       "4                         0.0                     0.000000   \n",
       "5                         3.0                     2.916667   \n",
       "6                         0.0                     0.000000   \n",
       "7                         6.0                     0.250000   \n",
       "8                         1.0                     1.000000   \n",
       "9                         0.0                     0.000000   \n",
       "10                        0.0                     0.000000   \n",
       "11                        1.0                     1.083333   \n",
       "12                        0.0                     1.416667   \n",
       "13                        3.0                     0.166667   \n",
       "14                        2.0                     0.000000   \n",
       "15                        6.0                     0.000000   \n",
       "16                        1.0                     0.000000   \n",
       "17                        1.0                     1.000000   \n",
       "18                        0.0                     0.000000   \n",
       "19                        2.0                     1.000000   \n",
       "20                        1.0                     0.000000   \n",
       "21                        1.0                     1.000000   \n",
       "22                        2.0                     0.000000   \n",
       "23                        3.0                     0.000000   \n",
       "24                        2.0                     4.500000   \n",
       "25                        1.0                     1.000000   \n",
       "26                        2.0                     0.000000   \n",
       "27                        2.0                     0.000000   \n",
       "28                        0.0                     0.000000   \n",
       "29                        8.0                     2.833333   \n",
       "\n",
       "    std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0                      0.000000                          0.0   \n",
       "1                      0.000000                          2.0   \n",
       "2                      0.000000                          1.0   \n",
       "3                      0.522233                          1.0   \n",
       "4                      0.000000                          0.0   \n",
       "5                      0.668558                          4.0   \n",
       "6                      0.000000                          0.0   \n",
       "7                      0.621582                          2.0   \n",
       "8                      0.000000                          1.0   \n",
       "9                      0.000000                          0.0   \n",
       "10                     0.000000                          0.0   \n",
       "11                     0.288675                          2.0   \n",
       "12                     0.996205                          3.0   \n",
       "13                     0.389249                          1.0   \n",
       "14                     0.000000                          0.0   \n",
       "15                     0.000000                          0.0   \n",
       "16                     0.000000                          0.0   \n",
       "17                     0.000000                          1.0   \n",
       "18                     0.000000                          0.0   \n",
       "19                     0.000000                          1.0   \n",
       "20                     0.000000                          0.0   \n",
       "21                     0.000000                          1.0   \n",
       "22                     0.000000                          0.0   \n",
       "23                     0.000000                          0.0   \n",
       "24                     1.167748                          7.0   \n",
       "25                     0.000000                          1.0   \n",
       "26                     0.000000                          0.0   \n",
       "27                     0.000000                          0.0   \n",
       "28                     0.000000                          0.0   \n",
       "29                     1.029857                          4.0   \n",
       "\n",
       "    last_count_numero_prima_info  target  \n",
       "0                            0.0     1.0  \n",
       "1                            2.0     0.0  \n",
       "2                            1.0     1.0  \n",
       "3                            0.0     0.0  \n",
       "4                            0.0     0.0  \n",
       "5                            1.0     0.0  \n",
       "6                            0.0     0.0  \n",
       "7                            2.0     1.0  \n",
       "8                            1.0     1.0  \n",
       "9                            0.0     0.0  \n",
       "10                           0.0     0.0  \n",
       "11                           2.0     0.0  \n",
       "12                           0.0     0.0  \n",
       "13                           0.0     0.0  \n",
       "14                           0.0     0.0  \n",
       "15                           0.0     1.0  \n",
       "16                           0.0     0.0  \n",
       "17                           1.0     0.0  \n",
       "18                           0.0     1.0  \n",
       "19                           1.0     1.0  \n",
       "20                           0.0     1.0  \n",
       "21                           1.0     0.0  \n",
       "22                           0.0     0.0  \n",
       "23                           0.0     0.0  \n",
       "24                           7.0     1.0  \n",
       "25                           1.0     0.0  \n",
       "26                           0.0     0.0  \n",
       "27                           0.0     1.0  \n",
       "28                           0.0     0.0  \n",
       "29                           4.0     0.0  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "train_dataset.head(30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Quello che funziona "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 11.4413, Fold:0\n",
      "Accuracy on test set: 40.24%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 5.8067, Fold:1\n",
      "Accuracy on test set: 73.67%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 6.5492, Fold:2\n",
      "Accuracy on test set: 66.16%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 3.1426, Fold:3\n",
      "Accuracy on test set: 40.56%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 11.1091, Fold:4\n",
      "Accuracy on test set: 65.81%\n",
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 7.4382, Fold:0\n",
      "Accuracy on test set: 57.84%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 9.5645, Fold:1\n",
      "Accuracy on test set: 50.29%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 2.3002, Fold:2\n",
      "Accuracy on test set: 76.15%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 10.5275, Fold:3\n",
      "Accuracy on test set: 55.00%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 4.1176, Fold:4\n",
      "Accuracy on test set: 79.13%\n",
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 2.5908, Fold:0\n",
      "Accuracy on test set: 29.86%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 10.2164, Fold:1\n",
      "Accuracy on test set: 67.77%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 2.2532, Fold:2\n",
      "Accuracy on test set: 78.19%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 7.3622, Fold:3\n",
      "Accuracy on test set: 45.85%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 2.6162, Fold:4\n",
      "Accuracy on test set: 34.39%\n",
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 11.0345, Fold:0\n",
      "Accuracy on test set: 64.73%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 13.9644, Fold:1\n",
      "Accuracy on test set: 61.40%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 10.2519, Fold:2\n",
      "Accuracy on test set: 58.05%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 3.6128, Fold:3\n",
      "Accuracy on test set: 31.17%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 2.1803, Fold:4\n",
      "Accuracy on test set: 30.42%\n",
      "Fold 1/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 4.8626, Fold:0\n",
      "Accuracy on test set: 53.07%\n",
      "Fold 2/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 5.1258, Fold:1\n",
      "Accuracy on test set: 78.54%\n",
      "Fold 3/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 13.6254, Fold:2\n",
      "Accuracy on test set: 59.88%\n",
      "Fold 4/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 23.2926, Fold:3\n",
      "Accuracy on test set: 31.47%\n",
      "Fold 5/5\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Epoch [20/20], Loss: 1.4236, Fold:4\n",
      "Accuracy on test set: 44.38%\n",
      "Averagea ccuracy on test set: 54.96%\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 8)  \n",
    "        self.fc2 = nn.Linear(8,4)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        self.fc4 = nn.Linear(4, 1)  # Output layer with 1 neuron for binary classification\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return torch.sigmoid(x)\n",
    "\n",
    "\n",
    "\n",
    "accuracy_values = []\n",
    "loss_values = []\n",
    "X = train_dataset.iloc[:, :-1].to_numpy()\n",
    "y = train_dataset.iloc[:, -1].to_numpy()\n",
    "\n",
    "num_folds = 5\n",
    "input_size = 39\n",
    "num_epochs = 20\n",
    "num_models = 5\n",
    "\n",
    "kf = KFold(n_splits=num_folds, shuffle=True)\n",
    "\n",
    "criterion = nn.BCELoss() \n",
    "l1_lambda = 0.001\n",
    "l2_lambda = 0.001\n",
    "fold_params = []\n",
    "\n",
    "for model_index in range(num_models):\n",
    "\n",
    "    for fold, (train_indices, val_indices) in enumerate(kf.split(X)):\n",
    "        print(f'Fold {fold+1}/{num_folds}')\n",
    "\n",
    "        # Split the data into training and validation sets\n",
    "        X_train, X_val = X[train_indices], X[val_indices]\n",
    "        y_train, y_val = y[train_indices], y[val_indices]\n",
    "\n",
    "        # Convert data to PyTorch tensors\n",
    "        X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "        y_train_tensor = torch.tensor(y_train, dtype=torch.float32)\n",
    "        X_val_tensor = torch.tensor(X_val, dtype=torch.float32)\n",
    "        y_val_tensor = torch.tensor(y_val, dtype=torch.float32)\n",
    "        \n",
    "        model = NeuralNetwork(input_size)\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        # Train the neural network\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            # Forward pass\n",
    "            outputs = model(X_train_tensor)\n",
    "            loss = criterion(outputs, y_train_tensor.view(-1, 1))\n",
    "            loss_values.append(loss.item())\n",
    "\n",
    "            l1_reg = torch.tensor(0., requires_grad=True)\n",
    "            for param in model.parameters():\n",
    "                l1_reg = l1_reg + torch.norm(param, p=1)\n",
    "            loss = loss + l1_lambda * l1_reg\n",
    "\n",
    "            # L2 regularization\n",
    "            l2_reg = torch.tensor(0., requires_grad=True)\n",
    "            for param in model.parameters():\n",
    "                l2_reg = l2_reg + torch.norm(param, p=2)\n",
    "            loss = loss + l2_lambda * l2_reg\n",
    "            \n",
    "            # Backward pass and optimization\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "        fold_params.append(model.state_dict())\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {loss.item():.4f}, Fold:{fold}')\n",
    "\n",
    "        # Evaluate the model\n",
    "        with torch.no_grad():\n",
    "            # Predict probabilities on the test set\n",
    "            outputs = model(X_val_tensor)\n",
    "            predicted = (outputs >= 0.5).float()\n",
    "            \n",
    "            # Calculate accuracy\n",
    "            accuracy = (predicted == y_val_tensor.view(-1, 1)).float().mean()\n",
    "            accuracy_values.append(accuracy)\n",
    "            print(f'Accuracy on test set: {accuracy.item()*100:.2f}%')\n",
    "    torch.save(model.state_dict(), f'model_{model_index}.pth')\n",
    "\n",
    "avg_params = {}\n",
    "\n",
    "for key in fold_params[0].keys():\n",
    "    avg_params[key] = torch.stack([params[key] for params in fold_params]).mean(dim=0)\n",
    "\n",
    "# Create a new model with the average parameters\n",
    "average_model = NeuralNetwork(input_size)\n",
    "average_model.load_state_dict(avg_params)\n",
    "print(f'Averagea ccuracy on test set: {np.array(accuracy_values).mean()*100:.2f}%')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Loss Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot the loss values\n",
    "plt.plot(loss_values, label='Training Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss Over Epochs')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Calculated F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score on test set: 0.2779\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "true_labels = y_val_tensor.numpy().astype(int)\n",
    "predicted_labels = 1-(predicted.numpy())\n",
    "# Calculate F1 score\n",
    "f1 = f1_score(true_labels, predicted_labels)\n",
    "print(f'F1 score on test set: {f1:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"/Users/danielguarnizo/Desktop/HACK4SDS/Dataset_DAY1/Data/test_set.csv\", delimiter=';')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ZWFXwUAP</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>1321219660</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>D</td>\n",
       "      <td>6</td>\n",
       "      <td>PD</td>\n",
       "      <td>SR</td>\n",
       "      <td>Distribuzione</td>\n",
       "      <td>0,0698090692124105</td>\n",
       "      <td>-0,0133630289532294</td>\n",
       "      <td>0,0454201362604088</td>\n",
       "      <td>0,39200477326969</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>True</td>\n",
       "      <td>Veneto</td>\n",
       "      <td>Nord-est</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,554859166666667</td>\n",
       "      <td>0,146890245697462</td>\n",
       "      <td>0,83594</td>\n",
       "      <td>0,60264</td>\n",
       "      <td>0,123576651818857</td>\n",
       "      <td>0,032714976770036</td>\n",
       "      <td>0,186178173719376</td>\n",
       "      <td>0,134218262806236</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>1,27369933184855</td>\n",
       "      <td>0,028642038445761</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q7R00000ZWJX2UAP</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>1420617490</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>46</td>\n",
       "      <td>IS</td>\n",
       "      <td>SR</td>\n",
       "      <td>Altri beni di consumo</td>\n",
       "      <td>0,169093471113199</td>\n",
       "      <td>0,00206611570247934</td>\n",
       "      <td>0,155359917141378</td>\n",
       "      <td>0,54062940347581</td>\n",
       "      <td>0,95959595959596</td>\n",
       "      <td>1402</td>\n",
       "      <td>False</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q7R00000a3E9nUAE</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>51</td>\n",
       "      <td>CB</td>\n",
       "      <td>SR</td>\n",
       "      <td>Chimica di base e intermedi</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,941108491613086</td>\n",
       "      <td>0,0992007690627971</td>\n",
       "      <td>1,0864</td>\n",
       "      <td>1</td>\n",
       "      <td>0,137654704944179</td>\n",
       "      <td>0,115573259414523</td>\n",
       "      <td>0,267955342902711</td>\n",
       "      <td>0,0119617224880383</td>\n",
       "      <td>0</td>\n",
       "      <td>0,212708532695375</td>\n",
       "      <td>0,100377623990215</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ZWRR6UAP</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>51</td>\n",
       "      <td>CB</td>\n",
       "      <td>SR</td>\n",
       "      <td>Chimica di base e intermedi</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>Molise</td>\n",
       "      <td>Sud</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,878429123495436</td>\n",
       "      <td>0,0566505328975202</td>\n",
       "      <td>0,972473824531666</td>\n",
       "      <td>0,903049655802421</td>\n",
       "      <td>0,252491959064328</td>\n",
       "      <td>0,0249197649236005</td>\n",
       "      <td>0,269318979266348</td>\n",
       "      <td>0,17658293460925</td>\n",
       "      <td>0</td>\n",
       "      <td>0,14559735513025</td>\n",
       "      <td>0,0113414597444539</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000g6DWvUAM</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2412739090</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>72</td>\n",
       "      <td>SS</td>\n",
       "      <td>SR</td>\n",
       "      <td>Alimentare</td>\n",
       "      <td>0,135170603674541</td>\n",
       "      <td>-0,0755467196819085</td>\n",
       "      <td>0,0169851380042463</td>\n",
       "      <td>0,492125984251969</td>\n",
       "      <td>0,769345238095238</td>\n",
       "      <td>1463</td>\n",
       "      <td>True</td>\n",
       "      <td>Sardegna</td>\n",
       "      <td>Isole</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,722863999082564</td>\n",
       "      <td>0,0605656113993484</td>\n",
       "      <td>0,816631566033492</td>\n",
       "      <td>0,761046273164548</td>\n",
       "      <td>0,284641717931192</td>\n",
       "      <td>0,0245101240633782</td>\n",
       "      <td>0,315383458646616</td>\n",
       "      <td>0,306924812030075</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38485640236956</td>\n",
       "      <td>0,0307032798267901</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ZWFXwUAP    2020-10-12  1321219660                     5   \n",
       "1  a1Q7R00000ZWJX2UAP    2020-11-12  1420617490                     8   \n",
       "2  a1Q7R00000a3E9nUAE    2021-07-05   137667970                     8   \n",
       "3  a1Q7R00000ZWRR6UAP    2021-01-19   137667970                     8   \n",
       "4  a1Q7R00000g6DWvUAM    2022-05-09  2412739090                     6   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     1                 8.0   \n",
       "1                     1                 NaN   \n",
       "2                     1                 NaN   \n",
       "3                     1                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     5.0                      6.0   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  age province juridical_form  \\\n",
       "0                     7.0                    D    6       PD             SR   \n",
       "1                     NaN                    F   46       IS             SR   \n",
       "2                     NaN                    I   51       CB             SR   \n",
       "3                     NaN                    F   51       CB             SR   \n",
       "4                     NaN                    F   72       SS             SR   \n",
       "\n",
       "               industry_sector  gross_margin_ratio    core_income_ratio  \\\n",
       "0                Distribuzione  0,0698090692124105  -0,0133630289532294   \n",
       "1        Altri beni di consumo   0,169093471113199  0,00206611570247934   \n",
       "2  Chimica di base e intermedi  0,0589433072553853   0,0306451612903226   \n",
       "3  Chimica di base e intermedi  0,0589433072553853   0,0306451612903226   \n",
       "4                   Alimentare   0,135170603674541  -0,0755467196819085   \n",
       "\n",
       "     cash_asset_ratio consolidated_liabilities_ratio tangible_assets_ratio  \\\n",
       "0  0,0454201362604088               0,39200477326969                     1   \n",
       "1   0,155359917141378               0,54062940347581      0,95959595959596   \n",
       "2  0,0043021855102392              0,640767334690816     0,980113636363636   \n",
       "3  0,0043021855102392              0,640767334690816     0,980113636363636   \n",
       "4  0,0169851380042463              0,492125984251969     0,769345238095238   \n",
       "\n",
       "  revenues  cr_available    region  geo_area  last_statement_age  \\\n",
       "0      449          True    Veneto  Nord-est                   1   \n",
       "1     1402         False    Molise       Sud                   1   \n",
       "2     1254          True    Molise       Sud                   2   \n",
       "3     1254          True    Molise       Sud                   2   \n",
       "4     1463          True  Sardegna     Isole                   2   \n",
       "\n",
       "  overrun_freq_a_revoca_autoliquidanti avg_tension_a_revoca_autoliquidanti  \\\n",
       "0                    0,166666666666667                   0,554859166666667   \n",
       "1                                    0                                   0   \n",
       "2                    0,833333333333333                   0,941108491613086   \n",
       "3                    0,833333333333333                   0,878429123495436   \n",
       "4                                    0                   0,722863999082564   \n",
       "\n",
       "  std_tension_a_revoca_autoliquidanti max_tension_a_revoca_autoliquidanti  \\\n",
       "0                   0,146890245697462                             0,83594   \n",
       "1                                   0                                   0   \n",
       "2                  0,0992007690627971                              1,0864   \n",
       "3                  0,0566505328975202                   0,972473824531666   \n",
       "4                  0,0605656113993484                   0,816631566033492   \n",
       "\n",
       "  last_tension_a_revoca_autoliquidanti avg_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                              0,60264                    0,123576651818857   \n",
       "1                                    0                                    0   \n",
       "2                                    1                    0,137654704944179   \n",
       "3                    0,903049655802421                    0,252491959064328   \n",
       "4                    0,761046273164548                    0,284641717931192   \n",
       "\n",
       "  std_rel_used_a_revoca_autoliquidanti max_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                    0,032714976770036                    0,186178173719376   \n",
       "1                                    0                                    0   \n",
       "2                    0,115573259414523                    0,267955342902711   \n",
       "3                   0,0249197649236005                    0,269318979266348   \n",
       "4                   0,0245101240633782                    0,315383458646616   \n",
       "\n",
       "  last_rel_used_a_revoca_autoliquidanti overrun_freq_a_scadenza  \\\n",
       "0                     0,134218262806236       0,333333333333333   \n",
       "1                                     0                       0   \n",
       "2                    0,0119617224880383                       0   \n",
       "3                      0,17658293460925                       0   \n",
       "4                     0,306924812030075                       0   \n",
       "\n",
       "  avg_rel_used_a_scadenza std_rel_used_a_scadenza max_rel_used_a_scadenza  \\\n",
       "0        1,27369933184855       0,028642038445761        1,32464142538975   \n",
       "1                       0                       0                       0   \n",
       "2       0,212708532695375       0,100377623990215        0,33222009569378   \n",
       "3        0,14559735513025      0,0113414597444539       0,162240829346092   \n",
       "4        0,38485640236956      0,0307032798267901       0,478388926862611   \n",
       "\n",
       "  last_rel_used_a_scadenza avg_count_enti_affidanti std_count_enti_affidanti  \\\n",
       "0         1,32464142538975         1,16666666666667        0,389249472080761   \n",
       "1                        0                        1                        0   \n",
       "2        0,320196172248804                        3                        0   \n",
       "3        0,126861244019139                        3                        0   \n",
       "4        0,356901572112098                        3                        0   \n",
       "\n",
       "   max_count_enti_affidanti  last_count_enti_affidanti  \\\n",
       "0                         2                          2   \n",
       "1                         1                          1   \n",
       "2                         3                          3   \n",
       "3                         3                          3   \n",
       "4                         3                          3   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0            1,08333333333333           0,288675134594813   \n",
       "1                           1                           0   \n",
       "2            1,91666666666667           0,288675134594813   \n",
       "3            1,91666666666667           0,288675134594813   \n",
       "4            2,08333333333333           0,288675134594813   \n",
       "\n",
       "   max_count_numero_prima_info  last_count_numero_prima_info  \n",
       "0                            2                             1  \n",
       "1                            1                             1  \n",
       "2                            2                             2  \n",
       "3                            2                             2  \n",
       "4                            3                             3  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['late_payment_score', 'external_score_late_payment_integrated', 'external_score_moderate', 'external_score_adverse']\n"
     ]
    }
   ],
   "source": [
    "# Drop columns \n",
    "test_dataset = Drop_unneed_columns(True,test_dataset)\n",
    "print(drop_columns)\n",
    "test_dataset = test_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'SR': 1, 'RS': 2, 'SU': 3, 'SC': 4, 'SP': 5, 'CO': 6, 'CL': 7, 'AU': 8, 'OO': 9, 'SL': 10, 'OC': 11, 'CC': 12, 'SO': 13, 'PS': 14}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_1212/3755637750.py:3: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  test_dataset.replace({k:v}, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "print(category_dics[\"juridical_form\"])\n",
    "for k,v in category_dics.items():\n",
    "    test_dataset.replace({k:v}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver03\n",
      "MISSING    2434\n",
      "10         1415\n",
      "7          1135\n",
      "11         1113\n",
      "9           804\n",
      "6           752\n",
      "12          689\n",
      "8           667\n",
      "4           385\n",
      "5           297\n",
      "3           240\n",
      "13          225\n",
      "14          215\n",
      "2           168\n",
      "1           139\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['external_score_ver01', 'external_score_ver02', 'external_score_ver03', 'age', 'province', 'juridical_form', 'industry_sector', 'gross_margin_ratio', 'core_income_ratio', 'cash_asset_ratio', 'consolidated_liabilities_ratio', 'tangible_assets_ratio', 'revenues', 'cr_available', 'region', 'geo_area', 'last_statement_age', 'overrun_freq_a_revoca_autoliquidanti', 'avg_tension_a_revoca_autoliquidanti', 'std_tension_a_revoca_autoliquidanti', 'max_tension_a_revoca_autoliquidanti', 'last_tension_a_revoca_autoliquidanti', 'avg_rel_used_a_revoca_autoliquidanti', 'std_rel_used_a_revoca_autoliquidanti', 'max_rel_used_a_revoca_autoliquidanti', 'last_rel_used_a_revoca_autoliquidanti', 'overrun_freq_a_scadenza', 'avg_rel_used_a_scadenza', 'std_rel_used_a_scadenza', 'max_rel_used_a_scadenza', 'last_rel_used_a_scadenza', 'avg_count_enti_affidanti', 'std_count_enti_affidanti', 'max_count_enti_affidanti', 'last_count_enti_affidanti', 'avg_count_numero_prima_info', 'std_count_numero_prima_info', 'max_count_numero_prima_info', 'last_count_numero_prima_info']\n"
     ]
    }
   ],
   "source": [
    "print(list(test_dataset.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MISSING' in the column: external_score_ver03\n",
      "'MISSING' in the column: province\n",
      "'MISSING' in the column: region\n",
      "'MISSING' in the column: geo_area\n"
     ]
    }
   ],
   "source": [
    "# find columns with MISSING values \n",
    "columns = []\n",
    "for column in list(test_dataset.columns):\n",
    "    # Check if there is a value \"MISSING\" in the 'column_name' column\n",
    "    missing_values = test_dataset[column] == 'MISSING'\n",
    "\n",
    "    # Check if any row contains the value \"MISSING\" in the specified column\n",
    "    if missing_values.any():\n",
    "        print(f\"'MISSING' in the column: {column}\")\n",
    "        columns.append(column)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'external_score_ver03': 6, 'province': 31, 'region': 7, 'geo_area': 3}\n"
     ]
    }
   ],
   "source": [
    "# Sum values in the specified columns\n",
    "dic = {}\n",
    "for column in columns:\n",
    "    column_name = column\n",
    "\n",
    "    count = 0\n",
    "    sum_values = 0\n",
    "    # Iterate over the DataFrame\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        # Access the value of the specified column for each row\n",
    "        count +=1\n",
    "        if isinstance(row[column_name], str):\n",
    "            continue\n",
    "        elif isinstance(row[column_name], int):\n",
    "            sum_values += row[column_name]\n",
    "    \n",
    "    dic[column] = int(sum_values/count)\n",
    "\n",
    "print(dic)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing_test(dataset,val, columun):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset[column] == 'MISSING'), column] = val\n",
    "\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dic.items():\n",
    "    test_dataset = Replace_missing_test(test_dataset,v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "province\n",
      "4.0      1157\n",
      "6.0      1044\n",
      "27.0      877\n",
      "39.0      316\n",
      "7.0       300\n",
      "         ... \n",
      "95.0       11\n",
      "60.0       10\n",
      "107.0       9\n",
      "12.0        7\n",
      "105.0       6\n",
      "Name: count, Length: 107, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(test_dataset[\"province\"].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_1212/2073560081.py:2: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset.replace('MISSING', np.nan, inplace=True)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'SS'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[46], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m(dataset)\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m---> 11\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mreplace_missing_values\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(test_dataset)\n",
      "Cell \u001b[0;32mIn[46], line 5\u001b[0m, in \u001b[0;36mreplace_missing_values\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      3\u001b[0m imp_mean \u001b[38;5;241m=\u001b[39m SimpleImputer(missing_values\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mnan, strategy\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmean\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# unique_labels = dataset['target'].unique()\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mimp_mean\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      6\u001b[0m SimpleImputer()\n\u001b[1;32m      7\u001b[0m dataset \u001b[38;5;241m=\u001b[39m imp_mean\u001b[38;5;241m.\u001b[39mtransform(dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/sklearn/base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[0;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[1;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[1;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[1;32m   1472\u001b[0m     )\n\u001b[1;32m   1473\u001b[0m ):\n\u001b[0;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/sklearn/impute/_base.py:410\u001b[0m, in \u001b[0;36mSimpleImputer.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    392\u001b[0m \u001b[38;5;129m@_fit_context\u001b[39m(prefer_skip_nested_validation\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    393\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfit\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, y\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    394\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Fit the imputer on `X`.\u001b[39;00m\n\u001b[1;32m    395\u001b[0m \n\u001b[1;32m    396\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;124;03m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m    409\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 410\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_input\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_fit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# default fill_value is 0 for numerical input and \"missing_value\"\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# otherwise\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfill_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/sklearn/impute/_base.py:337\u001b[0m, in \u001b[0;36mSimpleImputer._validate_input\u001b[0;34m(self, X, in_fit)\u001b[0m\n\u001b[1;32m    331\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcould not convert\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(ve):\n\u001b[1;32m    332\u001b[0m     new_ve \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    333\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m strategy with non-numeric data:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    334\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstrategy, ve\n\u001b[1;32m    335\u001b[0m         )\n\u001b[1;32m    336\u001b[0m     )\n\u001b[0;32m--> 337\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m new_ve \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    338\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    339\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ve\n",
      "\u001b[0;31mValueError\u001b[0m: Cannot use mean strategy with non-numeric data:\ncould not convert string to float: 'SS'"
     ]
    }
   ],
   "source": [
    "def replace_missing_values(dataset):\n",
    "    dataset.replace('MISSING', np.nan, inplace=True)\n",
    "    imp_mean = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    imp_mean.fit(dataset)\n",
    "    SimpleImputer()\n",
    "    dataset = imp_mean.transform(dataset)\n",
    "    print(dataset)\n",
    "    return dataset\n",
    "\n",
    "test_dataset = replace_missing_values(test_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[470], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m c \u001b[38;5;241m=\u001b[39m \u001b[43mtest_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mexternal_score_ver03\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(c)\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "c = test_dataset[\"external_score_ver03\"].value_counts()\n",
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_dataset = Replace_bool_toNumbers(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0698090692124105</td>\n",
       "      <td>-0,0133630289532294</td>\n",
       "      <td>0,0454201362604088</td>\n",
       "      <td>0,39200477326969</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,554859166666667</td>\n",
       "      <td>0,146890245697462</td>\n",
       "      <td>0,83594</td>\n",
       "      <td>0,60264</td>\n",
       "      <td>0,123576651818857</td>\n",
       "      <td>0,032714976770036</td>\n",
       "      <td>0,186178173719376</td>\n",
       "      <td>0,134218262806236</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>1,27369933184855</td>\n",
       "      <td>0,028642038445761</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,169093471113199</td>\n",
       "      <td>0,00206611570247934</td>\n",
       "      <td>0,155359917141378</td>\n",
       "      <td>0,54062940347581</td>\n",
       "      <td>0,95959595959596</td>\n",
       "      <td>1402</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,941108491613086</td>\n",
       "      <td>0,0992007690627971</td>\n",
       "      <td>1,0864</td>\n",
       "      <td>1</td>\n",
       "      <td>0,137654704944179</td>\n",
       "      <td>0,115573259414523</td>\n",
       "      <td>0,267955342902711</td>\n",
       "      <td>0,0119617224880383</td>\n",
       "      <td>0</td>\n",
       "      <td>0,212708532695375</td>\n",
       "      <td>0,100377623990215</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,878429123495436</td>\n",
       "      <td>0,0566505328975202</td>\n",
       "      <td>0,972473824531666</td>\n",
       "      <td>0,903049655802421</td>\n",
       "      <td>0,252491959064328</td>\n",
       "      <td>0,0249197649236005</td>\n",
       "      <td>0,269318979266348</td>\n",
       "      <td>0,17658293460925</td>\n",
       "      <td>0</td>\n",
       "      <td>0,14559735513025</td>\n",
       "      <td>0,0113414597444539</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,135170603674541</td>\n",
       "      <td>-0,0755467196819085</td>\n",
       "      <td>0,0169851380042463</td>\n",
       "      <td>0,492125984251969</td>\n",
       "      <td>0,769345238095238</td>\n",
       "      <td>1463</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,722863999082564</td>\n",
       "      <td>0,0605656113993484</td>\n",
       "      <td>0,816631566033492</td>\n",
       "      <td>0,761046273164548</td>\n",
       "      <td>0,284641717931192</td>\n",
       "      <td>0,0245101240633782</td>\n",
       "      <td>0,315383458646616</td>\n",
       "      <td>0,306924812030075</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38485640236956</td>\n",
       "      <td>0,0307032798267901</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0,212602739726027</td>\n",
       "      <td>0,0300330872995673</td>\n",
       "      <td>0,000325626831650928</td>\n",
       "      <td>0,550319634703196</td>\n",
       "      <td>0,965474209650582</td>\n",
       "      <td>3929</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>0,962571308834391</td>\n",
       "      <td>0,0263028736043071</td>\n",
       "      <td>0,985825788026107</td>\n",
       "      <td>0,927813888888889</td>\n",
       "      <td>0,65057540086536</td>\n",
       "      <td>0,05203209285494</td>\n",
       "      <td>0,75066327309748</td>\n",
       "      <td>0,595085517943497</td>\n",
       "      <td>0</td>\n",
       "      <td>0,409035293119539</td>\n",
       "      <td>0,0730965006549573</td>\n",
       "      <td>0,548144311529651</td>\n",
       "      <td>0,548144311529651</td>\n",
       "      <td>14,4166666666667</td>\n",
       "      <td>1,44337567297406</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>3,91666666666667</td>\n",
       "      <td>1,97522534195852</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0806451612903226</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0469314079422383</td>\n",
       "      <td>0,625448028673835</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,40953703703704</td>\n",
       "      <td>0,241564672078251</td>\n",
       "      <td>2,74656944444444</td>\n",
       "      <td>2,72804166666667</td>\n",
       "      <td>2,33333333333333</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0,181209150326797</td>\n",
       "      <td>0,132992097701149</td>\n",
       "      <td>0,0224453632604843</td>\n",
       "      <td>0,400326797385621</td>\n",
       "      <td>0,838453572661374</td>\n",
       "      <td>11604</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,801134920634921</td>\n",
       "      <td>0,162625295169213</td>\n",
       "      <td>0,997085714285714</td>\n",
       "      <td>0,989671428571429</td>\n",
       "      <td>0,0146629395036194</td>\n",
       "      <td>0,00938302515493416</td>\n",
       "      <td>0,02496035849707</td>\n",
       "      <td>0,00597009651844192</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,163601531081236</td>\n",
       "      <td>0,0316792029521103</td>\n",
       "      <td>0,195947948983109</td>\n",
       "      <td>0,131166494312306</td>\n",
       "      <td>4,58333333333333</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,456674473067916</td>\n",
       "      <td>0,0857664233576642</td>\n",
       "      <td>0,09</td>\n",
       "      <td>0,566744730679157</td>\n",
       "      <td>1</td>\n",
       "      <td>548</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,15715</td>\n",
       "      <td>0,171998635618267</td>\n",
       "      <td>0,48076</td>\n",
       "      <td>0,01578</td>\n",
       "      <td>0,014338503649635</td>\n",
       "      <td>0,0156933061695499</td>\n",
       "      <td>0,0438649635036496</td>\n",
       "      <td>0,00143978102189781</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0604969586374696</td>\n",
       "      <td>0,0183848321359603</td>\n",
       "      <td>0,0813248175182482</td>\n",
       "      <td>0,0813248175182482</td>\n",
       "      <td>1,41666666666667</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0144619044637826</td>\n",
       "      <td>-0,454376163873371</td>\n",
       "      <td>0,004375</td>\n",
       "      <td>0,68690915920616</td>\n",
       "      <td>0,990120364572462</td>\n",
       "      <td>1074</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,550165188172043</td>\n",
       "      <td>0,35657406042894</td>\n",
       "      <td>0,89842380952381</td>\n",
       "      <td>0</td>\n",
       "      <td>0,214047098075729</td>\n",
       "      <td>0,140905816352211</td>\n",
       "      <td>0,351338919925512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>4,63836052115501e-16</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0,31540847983454</td>\n",
       "      <td>0,0314009661835749</td>\n",
       "      <td>0,00859598853868195</td>\n",
       "      <td>0,641158221302999</td>\n",
       "      <td>0,294498381877023</td>\n",
       "      <td>414</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,432869884853596</td>\n",
       "      <td>0,252745760238384</td>\n",
       "      <td>0,817354668987479</td>\n",
       "      <td>0,0176624295172793</td>\n",
       "      <td>0,105709339774557</td>\n",
       "      <td>0,061668784045319</td>\n",
       "      <td>0,199628019323671</td>\n",
       "      <td>0,00434299516908213</td>\n",
       "      <td>0</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>0</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,141483516483516</td>\n",
       "      <td>-0,0277594183740912</td>\n",
       "      <td>0,10952380952381</td>\n",
       "      <td>0,68956043956044</td>\n",
       "      <td>0,980519480519481</td>\n",
       "      <td>1511</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,389512666666667</td>\n",
       "      <td>0,324676924728493</td>\n",
       "      <td>0,86928</td>\n",
       "      <td>0,038832</td>\n",
       "      <td>0,0644461725126848</td>\n",
       "      <td>0,053718882317752</td>\n",
       "      <td>0,143825281270682</td>\n",
       "      <td>0,00642488418266049</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0887348334436356</td>\n",
       "      <td>0,0193342937616968</td>\n",
       "      <td>0,114889477167439</td>\n",
       "      <td>0,0469675711449371</td>\n",
       "      <td>5,83333333333333</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0,443548387096774</td>\n",
       "      <td>-0,107561929595828</td>\n",
       "      <td>0,0156569094622192</td>\n",
       "      <td>0,485483870967742</td>\n",
       "      <td>0,920870425321464</td>\n",
       "      <td>1598</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,680249537037037</td>\n",
       "      <td>0,231309785776821</td>\n",
       "      <td>0,982183333333333</td>\n",
       "      <td>0,441591666666667</td>\n",
       "      <td>0,153247705465165</td>\n",
       "      <td>0,0521098390986579</td>\n",
       "      <td>0,221267834793492</td>\n",
       "      <td>0,099482478097622</td>\n",
       "      <td>0</td>\n",
       "      <td>0,131861284939508</td>\n",
       "      <td>0,00617420704782303</td>\n",
       "      <td>0,134433667083855</td>\n",
       "      <td>0,122338548185232</td>\n",
       "      <td>4,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0,0511390517698671</td>\n",
       "      <td>-0,202533995451803</td>\n",
       "      <td>0,00750618641737696</td>\n",
       "      <td>0,657252225774541</td>\n",
       "      <td>0,706839219915521</td>\n",
       "      <td>19058</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,583333333333333</td>\n",
       "      <td>0,798658440088396</td>\n",
       "      <td>0,0526465224978752</td>\n",
       "      <td>0,849462658254437</td>\n",
       "      <td>0,707507345829415</td>\n",
       "      <td>0,529653990450205</td>\n",
       "      <td>0,0881121454276001</td>\n",
       "      <td>0,696123675097072</td>\n",
       "      <td>0,477022405289117</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,735301321404834</td>\n",
       "      <td>0,0462155669116603</td>\n",
       "      <td>0,796762094658411</td>\n",
       "      <td>0,72403247979851</td>\n",
       "      <td>15,5</td>\n",
       "      <td>0,674199862463242</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0,383680555555556</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,120171673819742</td>\n",
       "      <td>0,58275462962963</td>\n",
       "      <td>0,996231155778894</td>\n",
       "      <td>1476</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,628923562838665</td>\n",
       "      <td>0,103512084354466</td>\n",
       "      <td>0,788404705882353</td>\n",
       "      <td>0,599674352174946</td>\n",
       "      <td>0,180249153116531</td>\n",
       "      <td>0,0288855083825645</td>\n",
       "      <td>0,227013550135501</td>\n",
       "      <td>0,172670054200542</td>\n",
       "      <td>0</td>\n",
       "      <td>0,502086720867209</td>\n",
       "      <td>0,0827169281291274</td>\n",
       "      <td>0,576208672086721</td>\n",
       "      <td>0,555310298102981</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,229961682960403</td>\n",
       "      <td>0,0296371270618898</td>\n",
       "      <td>0</td>\n",
       "      <td>0,370582043783666</td>\n",
       "      <td>1</td>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,407657248453215</td>\n",
       "      <td>0,0627932392858802</td>\n",
       "      <td>0,533127466391065</td>\n",
       "      <td>0,416367998645988</td>\n",
       "      <td>0,37710826286117</td>\n",
       "      <td>0,0585151705576629</td>\n",
       "      <td>0,49512156448203</td>\n",
       "      <td>0,384871035940803</td>\n",
       "      <td>0</td>\n",
       "      <td>1,9360563777308</td>\n",
       "      <td>0,181163318878327</td>\n",
       "      <td>2,27354334038055</td>\n",
       "      <td>2,02711522198731</td>\n",
       "      <td>8,16666666666667</td>\n",
       "      <td>0,834847109936722</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,229961682960403</td>\n",
       "      <td>0,0296371270618898</td>\n",
       "      <td>0</td>\n",
       "      <td>0,370582043783666</td>\n",
       "      <td>1</td>\n",
       "      <td>946</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38907167988079</td>\n",
       "      <td>0,110072083071302</td>\n",
       "      <td>0,6557280310228</td>\n",
       "      <td>0,38673728171286</td>\n",
       "      <td>0,359894908386187</td>\n",
       "      <td>0,102254172902609</td>\n",
       "      <td>0,608458773784355</td>\n",
       "      <td>0,361408033826638</td>\n",
       "      <td>0</td>\n",
       "      <td>1,95689622973925</td>\n",
       "      <td>0,164308117930946</td>\n",
       "      <td>2,27354334038055</td>\n",
       "      <td>2,12585517970402</td>\n",
       "      <td>8,16666666666667</td>\n",
       "      <td>0,834847109936722</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,17374616171955</td>\n",
       "      <td>0,0262008733624454</td>\n",
       "      <td>0</td>\n",
       "      <td>0,323439099283521</td>\n",
       "      <td>0,997134670487106</td>\n",
       "      <td>2748</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,25</td>\n",
       "      <td>0,788993056125199</td>\n",
       "      <td>0,121123110275902</td>\n",
       "      <td>0,98285856519349</td>\n",
       "      <td>0,681517647956877</td>\n",
       "      <td>0,220619905385735</td>\n",
       "      <td>0,0347397205985855</td>\n",
       "      <td>0,268704876273654</td>\n",
       "      <td>0,168943959243086</td>\n",
       "      <td>0,25</td>\n",
       "      <td>0,446912148229015</td>\n",
       "      <td>0,0268070705445783</td>\n",
       "      <td>0,500278748180495</td>\n",
       "      <td>0,500278748180495</td>\n",
       "      <td>8</td>\n",
       "      <td>1,04446593573419</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1,04446593573419</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,3963133640553</td>\n",
       "      <td>0,00866425992779783</td>\n",
       "      <td>0,0558002936857562</td>\n",
       "      <td>0,412771560236998</td>\n",
       "      <td>0,973747016706444</td>\n",
       "      <td>1385</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>0,956168637915266</td>\n",
       "      <td>0,0358738162380265</td>\n",
       "      <td>1,0169875</td>\n",
       "      <td>1,0169875</td>\n",
       "      <td>0,0552298435619735</td>\n",
       "      <td>0,0020721683250733</td>\n",
       "      <td>0,0587429602888087</td>\n",
       "      <td>0,0587429602888087</td>\n",
       "      <td>0</td>\n",
       "      <td>0,120986642599278</td>\n",
       "      <td>0,00767103565035951</td>\n",
       "      <td>0,124258483754513</td>\n",
       "      <td>0,124258483754513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,240783889489889</td>\n",
       "      <td>0,0178091397849462</td>\n",
       "      <td>0,306265984654731</td>\n",
       "      <td>0,42939169509861</td>\n",
       "      <td>0,793959382051727</td>\n",
       "      <td>10918</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0,916666666666667</td>\n",
       "      <td>0,669427384796735</td>\n",
       "      <td>0,0992854648085776</td>\n",
       "      <td>0,800954430164723</td>\n",
       "      <td>0,504998383855887</td>\n",
       "      <td>0,147342072723942</td>\n",
       "      <td>0,0218651229538172</td>\n",
       "      <td>0,176202051657813</td>\n",
       "      <td>0,111044880014655</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,317335142272699</td>\n",
       "      <td>0,0455557481627097</td>\n",
       "      <td>0,379084264517311</td>\n",
       "      <td>0,272506777798131</td>\n",
       "      <td>5,91666666666667</td>\n",
       "      <td>0,668557923421522</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0301587301587302</td>\n",
       "      <td>-0,0029130253849355</td>\n",
       "      <td>0,0754716981132075</td>\n",
       "      <td>0,307503607503608</td>\n",
       "      <td>0,866206589492431</td>\n",
       "      <td>4808</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,144379904014562</td>\n",
       "      <td>0,115279495811948</td>\n",
       "      <td>0,297076923076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00393472684414864</td>\n",
       "      <td>0,00309533028142784</td>\n",
       "      <td>0,0080324459234609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0,481517505546312</td>\n",
       "      <td>0,0267490915331625</td>\n",
       "      <td>0,522436772046589</td>\n",
       "      <td>0,522436772046589</td>\n",
       "      <td>7,66666666666667</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0,295138888888889</td>\n",
       "      <td>0,0121951219512195</td>\n",
       "      <td>0,00302114803625378</td>\n",
       "      <td>0,388888888888889</td>\n",
       "      <td>0,335834896810507</td>\n",
       "      <td>664</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,882571959792879</td>\n",
       "      <td>0,0627466955596793</td>\n",
       "      <td>0,959823809523809</td>\n",
       "      <td>0,887839900937936</td>\n",
       "      <td>0,292130647590362</td>\n",
       "      <td>0,028137245748139</td>\n",
       "      <td>0,347700301204819</td>\n",
       "      <td>0,347700301204819</td>\n",
       "      <td>0</td>\n",
       "      <td>0,172019076305221</td>\n",
       "      <td>0,0196131546324518</td>\n",
       "      <td>0,219200301204819</td>\n",
       "      <td>0,219200301204819</td>\n",
       "      <td>3,41666666666667</td>\n",
       "      <td>0,90033663737852</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,140170826988016</td>\n",
       "      <td>-0,00601684717208183</td>\n",
       "      <td>0,000402738622633911</td>\n",
       "      <td>0,413560219823876</td>\n",
       "      <td>0,587057314787412</td>\n",
       "      <td>7626</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0,75</td>\n",
       "      <td>0,86054493006993</td>\n",
       "      <td>0,0317146467326909</td>\n",
       "      <td>0,892214685314685</td>\n",
       "      <td>0,808557342657343</td>\n",
       "      <td>0,161366279832153</td>\n",
       "      <td>0,00594701610644478</td>\n",
       "      <td>0,16730487804878</td>\n",
       "      <td>0,151617755048518</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,379730822187254</td>\n",
       "      <td>0,006381729176409</td>\n",
       "      <td>0,389625753999475</td>\n",
       "      <td>0,371850642538683</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2,16666666666667</td>\n",
       "      <td>0,577350269189626</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,464636707194417</td>\n",
       "      <td>0,0125934084914631</td>\n",
       "      <td>0</td>\n",
       "      <td>0,416001808268284</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,61671781205978</td>\n",
       "      <td>0,343459428362498</td>\n",
       "      <td>0,9918</td>\n",
       "      <td>0,94058690744921</td>\n",
       "      <td>0,234048577235772</td>\n",
       "      <td>0,129814950290693</td>\n",
       "      <td>0,374948780487805</td>\n",
       "      <td>0,35570243902439</td>\n",
       "      <td>0</td>\n",
       "      <td>1,98546808943089</td>\n",
       "      <td>0,0420881814728821</td>\n",
       "      <td>2,04689756097561</td>\n",
       "      <td>2,02848536585366</td>\n",
       "      <td>6,66666666666667</td>\n",
       "      <td>0,778498944161523</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,363423212192263</td>\n",
       "      <td>0,0251382604323781</td>\n",
       "      <td>0,0212373037857802</td>\n",
       "      <td>0,78810082063306</td>\n",
       "      <td>0,855302705023615</td>\n",
       "      <td>1996</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,257538076245022</td>\n",
       "      <td>0,234986131346604</td>\n",
       "      <td>0,654829931972789</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0482941299265197</td>\n",
       "      <td>0,0500603081420705</td>\n",
       "      <td>0,144679358717435</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,951946601536406</td>\n",
       "      <td>0,107436450056201</td>\n",
       "      <td>1,06908667334669</td>\n",
       "      <td>1,0667745490982</td>\n",
       "      <td>4,83333333333333</td>\n",
       "      <td>0,717740562565273</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,110410094637224</td>\n",
       "      <td>0,000302114803625378</td>\n",
       "      <td>0,000453514739229025</td>\n",
       "      <td>0,572780531771068</td>\n",
       "      <td>0,913793103448276</td>\n",
       "      <td>3535</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,760519982603886</td>\n",
       "      <td>0,0484556156116301</td>\n",
       "      <td>0,863583577551971</td>\n",
       "      <td>0,809404775069472</td>\n",
       "      <td>0,252594813767091</td>\n",
       "      <td>0,0220811476943254</td>\n",
       "      <td>0,279845827439887</td>\n",
       "      <td>0,256748231966054</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,0863115040075436</td>\n",
       "      <td>0,00295801997721993</td>\n",
       "      <td>0,0907448373408769</td>\n",
       "      <td>0,0897807637906648</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0,16093023255814</td>\n",
       "      <td>0,0536082474226804</td>\n",
       "      <td>0,0098159509202454</td>\n",
       "      <td>0,562790697674419</td>\n",
       "      <td>0,334615384615385</td>\n",
       "      <td>514</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>50547,6666666667</td>\n",
       "      <td>74663,8518663158</td>\n",
       "      <td>151643</td>\n",
       "      <td>0</td>\n",
       "      <td>7,76588845654993e-05</td>\n",
       "      <td>0,000209091450918547</td>\n",
       "      <td>0,000729571984435798</td>\n",
       "      <td>0</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,242317282749676</td>\n",
       "      <td>0,00677395747478242</td>\n",
       "      <td>0,25593579766537</td>\n",
       "      <td>0,233945525291829</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,231349782293179</td>\n",
       "      <td>0,0194128787878788</td>\n",
       "      <td>0,0804071246819338</td>\n",
       "      <td>0,443251088534107</td>\n",
       "      <td>0,565540540540541</td>\n",
       "      <td>2148</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,733450051894817</td>\n",
       "      <td>0,0431962210755328</td>\n",
       "      <td>0,826521160104293</td>\n",
       "      <td>0,73129175245682</td>\n",
       "      <td>0,498746314400993</td>\n",
       "      <td>0,0334977524587498</td>\n",
       "      <td>0,533630819366853</td>\n",
       "      <td>0,530116387337058</td>\n",
       "      <td>0</td>\n",
       "      <td>0,55561351644941</td>\n",
       "      <td>0,0173859879616584</td>\n",
       "      <td>0,585378491620112</td>\n",
       "      <td>0,555938547486033</td>\n",
       "      <td>10,0833333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,123490455784963</td>\n",
       "      <td>0,00589101620029455</td>\n",
       "      <td>0,00174520069808028</td>\n",
       "      <td>0,773276197896377</td>\n",
       "      <td>0,988740323715693</td>\n",
       "      <td>1358</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,817854559348955</td>\n",
       "      <td>0,0755611328793689</td>\n",
       "      <td>0,969013067603609</td>\n",
       "      <td>0,745015394081212</td>\n",
       "      <td>0,194098735886107</td>\n",
       "      <td>0,0224413326185982</td>\n",
       "      <td>0,229287187039764</td>\n",
       "      <td>0,226478645066274</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,370288659793814</td>\n",
       "      <td>0,0413559763129373</td>\n",
       "      <td>0,437880706921944</td>\n",
       "      <td>0,310402798232695</td>\n",
       "      <td>5,33333333333333</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0,583333333333333</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,19488597097443</td>\n",
       "      <td>-0,0117508813160987</td>\n",
       "      <td>0,0157342657342657</td>\n",
       "      <td>0,387007601935038</td>\n",
       "      <td>0,970285714285714</td>\n",
       "      <td>1704</td>\n",
       "      <td>1</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,902962083333333</td>\n",
       "      <td>0,109107650603728</td>\n",
       "      <td>0,99917</td>\n",
       "      <td>0,87729</td>\n",
       "      <td>0,078669014084507</td>\n",
       "      <td>0,0277018301862738</td>\n",
       "      <td>0,114713615023474</td>\n",
       "      <td>0,0514841549295775</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,477285602503912</td>\n",
       "      <td>0,0236722918443658</td>\n",
       "      <td>0,506569248826291</td>\n",
       "      <td>0,502116197183099</td>\n",
       "      <td>4,75</td>\n",
       "      <td>0,452267016866645</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    external_score_ver01  external_score_ver02 external_score_ver03  age  \\\n",
       "0                      5                     1                   11    6   \n",
       "1                      8                     1                    9   46   \n",
       "2                      8                     1                    6   51   \n",
       "3                      8                     1                    9   51   \n",
       "4                      6                     1                    9   72   \n",
       "5                      6                     1                    7   25   \n",
       "6                      5                     1                    8   48   \n",
       "7                      6                     1                    7   60   \n",
       "8                      5                     1                    3   52   \n",
       "9                      6                     1                   10   47   \n",
       "10                     8                     1                   14   48   \n",
       "11                     7                     1                    5   53   \n",
       "12                     6                     1                    7   57   \n",
       "13                     9                     1                   14   50   \n",
       "14                     5                     1                    4   53   \n",
       "15                    10                     2                   11   24   \n",
       "16                    10                     2                   10   24   \n",
       "17                     6                     1                   11   46   \n",
       "18                     8                     1                   11    6   \n",
       "19                     9                     1                   14   10   \n",
       "20                     5                     1                    3   46   \n",
       "21                     7                     1                   10    6   \n",
       "22                     7                     1                   10   58   \n",
       "23                    10                     3                   14   55   \n",
       "24                     8                     1                   10   47   \n",
       "25                     8                     1                   14    6   \n",
       "26                     7                     1                    5   46   \n",
       "27                     7                     1                    9   20   \n",
       "28                     6                     1                   14   52   \n",
       "29                     4                     1                    7    6   \n",
       "\n",
       "   province juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0         5              1                3  0,0698090692124105   \n",
       "1       101              1                8   0,169093471113199   \n",
       "2        69              1               12  0,0589433072553853   \n",
       "3        69              1               12  0,0589433072553853   \n",
       "4        51              1               15   0,135170603674541   \n",
       "5         5              1                4   0,212602739726027   \n",
       "6        71              1                3  0,0806451612903226   \n",
       "7         1              5               16   0,181209150326797   \n",
       "8        22              1               15   0,456674473067916   \n",
       "9        68              1                1  0,0144619044637826   \n",
       "10       51              1               10    0,31540847983454   \n",
       "11       52              1               15   0,141483516483516   \n",
       "12       91              1                2   0,443548387096774   \n",
       "13        9              5               10  0,0511390517698671   \n",
       "14       74              1                6   0,383680555555556   \n",
       "15       96              1                3   0,229961682960403   \n",
       "16       96              1                3   0,229961682960403   \n",
       "17       21              1                3    0,17374616171955   \n",
       "18       76              1               15     0,3963133640553   \n",
       "19        9              1               12   0,240783889489889   \n",
       "20       10              4                3  0,0301587301587302   \n",
       "21       76              1               10   0,295138888888889   \n",
       "22       41              4                3   0,140170826988016   \n",
       "23       48              1                1   0,464636707194417   \n",
       "24        9              1                1   0,363423212192263   \n",
       "25       34              1                8   0,110410094637224   \n",
       "26       49              1               18    0,16093023255814   \n",
       "27       65              1                8   0,231349782293179   \n",
       "28       80              1                3   0,123490455784963   \n",
       "29       80              4                3    0,19488597097443   \n",
       "\n",
       "       core_income_ratio      cash_asset_ratio consolidated_liabilities_ratio  \\\n",
       "0    -0,0133630289532294    0,0454201362604088               0,39200477326969   \n",
       "1    0,00206611570247934     0,155359917141378               0,54062940347581   \n",
       "2     0,0306451612903226    0,0043021855102392              0,640767334690816   \n",
       "3     0,0306451612903226    0,0043021855102392              0,640767334690816   \n",
       "4    -0,0755467196819085    0,0169851380042463              0,492125984251969   \n",
       "5     0,0300330872995673  0,000325626831650928              0,550319634703196   \n",
       "6                      0    0,0469314079422383              0,625448028673835   \n",
       "7      0,132992097701149    0,0224453632604843              0,400326797385621   \n",
       "8     0,0857664233576642                  0,09              0,566744730679157   \n",
       "9     -0,454376163873371              0,004375               0,68690915920616   \n",
       "10    0,0314009661835749   0,00859598853868195              0,641158221302999   \n",
       "11   -0,0277594183740912      0,10952380952381               0,68956043956044   \n",
       "12    -0,107561929595828    0,0156569094622192              0,485483870967742   \n",
       "13    -0,202533995451803   0,00750618641737696              0,657252225774541   \n",
       "14    0,0833333333333333     0,120171673819742               0,58275462962963   \n",
       "15    0,0296371270618898                     0              0,370582043783666   \n",
       "16    0,0296371270618898                     0              0,370582043783666   \n",
       "17    0,0262008733624454                     0              0,323439099283521   \n",
       "18   0,00866425992779783    0,0558002936857562              0,412771560236998   \n",
       "19    0,0178091397849462     0,306265984654731               0,42939169509861   \n",
       "20   -0,0029130253849355    0,0754716981132075              0,307503607503608   \n",
       "21    0,0121951219512195   0,00302114803625378              0,388888888888889   \n",
       "22  -0,00601684717208183  0,000402738622633911              0,413560219823876   \n",
       "23    0,0125934084914631                     0              0,416001808268284   \n",
       "24    0,0251382604323781    0,0212373037857802               0,78810082063306   \n",
       "25  0,000302114803625378  0,000453514739229025              0,572780531771068   \n",
       "26    0,0536082474226804    0,0098159509202454              0,562790697674419   \n",
       "27    0,0194128787878788    0,0804071246819338              0,443251088534107   \n",
       "28   0,00589101620029455   0,00174520069808028              0,773276197896377   \n",
       "29   -0,0117508813160987    0,0157342657342657              0,387007601935038   \n",
       "\n",
       "   tangible_assets_ratio revenues  cr_available region geo_area  \\\n",
       "0                      1      449             1      5        4   \n",
       "1       0,95959595959596     1402             0     18        2   \n",
       "2      0,980113636363636     1254             1     18        2   \n",
       "3      0,980113636363636     1254             1     18        2   \n",
       "4      0,769345238095238     1463             1      2        1   \n",
       "5      0,965474209650582     3929             1      5        4   \n",
       "6                      1      144             1     19        4   \n",
       "7      0,838453572661374    11604             1      1        1   \n",
       "8                      1      548             1      7        2   \n",
       "9      0,990120364572462     1074             1     17        5   \n",
       "10     0,294498381877023      414             1      2        1   \n",
       "11     0,980519480519481     1511             1     16        3   \n",
       "12     0,920870425321464     1598             1     13        3   \n",
       "13     0,706839219915521    19058             1      9        2   \n",
       "14     0,996231155778894     1476             1     16        3   \n",
       "15                     1      946             1      3        2   \n",
       "16                     1      946             1      3        2   \n",
       "17     0,997134670487106     2748             1      1        1   \n",
       "18     0,973747016706444     1385             1     13        3   \n",
       "19     0,793959382051727    10918             1      9        2   \n",
       "20     0,866206589492431     4808             1     10        2   \n",
       "21     0,335834896810507      664             1     13        3   \n",
       "22     0,587057314787412     7626             1     15        2   \n",
       "23                     1      410             1     15        2   \n",
       "24     0,855302705023615     1996             1      9        2   \n",
       "25     0,913793103448276     3535             1      5        4   \n",
       "26     0,334615384615385      514             1     16        3   \n",
       "27     0,565540540540541     2148             1     16        3   \n",
       "28     0,988740323715693     1358             1     19        4   \n",
       "29     0,970285714285714     1704             1     19        4   \n",
       "\n",
       "    last_statement_age overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                    1                    0,166666666666667   \n",
       "1                    1                                    0   \n",
       "2                    2                    0,833333333333333   \n",
       "3                    2                    0,833333333333333   \n",
       "4                    2                                    0   \n",
       "5                    2                    0,333333333333333   \n",
       "6                    1                                    0   \n",
       "7                    2                                  0,5   \n",
       "8                    2                                    0   \n",
       "9                    1                                    0   \n",
       "10                   2                                    0   \n",
       "11                   1                    0,166666666666667   \n",
       "12                   2                   0,0833333333333333   \n",
       "13                   2                    0,583333333333333   \n",
       "14                   2                   0,0833333333333333   \n",
       "15                   2                                    0   \n",
       "16                   2                                    0   \n",
       "17                   1                                 0,25   \n",
       "18                   2                    0,333333333333333   \n",
       "19                   4                    0,916666666666667   \n",
       "20                   1                                    0   \n",
       "21                   2                   0,0833333333333333   \n",
       "22                   1                                 0,75   \n",
       "23                   2                   0,0833333333333333   \n",
       "24                   1                                    0   \n",
       "25                   3                                  0,5   \n",
       "26                   1                    0,333333333333333   \n",
       "27                   2                                    0   \n",
       "28                   2                                  0,5   \n",
       "29                   2                                    0   \n",
       "\n",
       "   avg_tension_a_revoca_autoliquidanti std_tension_a_revoca_autoliquidanti  \\\n",
       "0                    0,554859166666667                   0,146890245697462   \n",
       "1                                    0                                   0   \n",
       "2                    0,941108491613086                  0,0992007690627971   \n",
       "3                    0,878429123495436                  0,0566505328975202   \n",
       "4                    0,722863999082564                  0,0605656113993484   \n",
       "5                    0,962571308834391                  0,0263028736043071   \n",
       "6                                    0                                   0   \n",
       "7                    0,801134920634921                   0,162625295169213   \n",
       "8                              0,15715                   0,171998635618267   \n",
       "9                    0,550165188172043                    0,35657406042894   \n",
       "10                   0,432869884853596                   0,252745760238384   \n",
       "11                   0,389512666666667                   0,324676924728493   \n",
       "12                   0,680249537037037                   0,231309785776821   \n",
       "13                   0,798658440088396                  0,0526465224978752   \n",
       "14                   0,628923562838665                   0,103512084354466   \n",
       "15                   0,407657248453215                  0,0627932392858802   \n",
       "16                    0,38907167988079                   0,110072083071302   \n",
       "17                   0,788993056125199                   0,121123110275902   \n",
       "18                   0,956168637915266                  0,0358738162380265   \n",
       "19                   0,669427384796735                  0,0992854648085776   \n",
       "20                   0,144379904014562                   0,115279495811948   \n",
       "21                   0,882571959792879                  0,0627466955596793   \n",
       "22                    0,86054493006993                  0,0317146467326909   \n",
       "23                    0,61671781205978                   0,343459428362498   \n",
       "24                   0,257538076245022                   0,234986131346604   \n",
       "25                   0,760519982603886                  0,0484556156116301   \n",
       "26                    50547,6666666667                    74663,8518663158   \n",
       "27                   0,733450051894817                  0,0431962210755328   \n",
       "28                   0,817854559348955                  0,0755611328793689   \n",
       "29                   0,902962083333333                   0,109107650603728   \n",
       "\n",
       "   max_tension_a_revoca_autoliquidanti last_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0,83594                              0,60264   \n",
       "1                                    0                                    0   \n",
       "2                               1,0864                                    1   \n",
       "3                    0,972473824531666                    0,903049655802421   \n",
       "4                    0,816631566033492                    0,761046273164548   \n",
       "5                    0,985825788026107                    0,927813888888889   \n",
       "6                                    0                                    0   \n",
       "7                    0,997085714285714                    0,989671428571429   \n",
       "8                              0,48076                              0,01578   \n",
       "9                     0,89842380952381                                    0   \n",
       "10                   0,817354668987479                   0,0176624295172793   \n",
       "11                             0,86928                             0,038832   \n",
       "12                   0,982183333333333                    0,441591666666667   \n",
       "13                   0,849462658254437                    0,707507345829415   \n",
       "14                   0,788404705882353                    0,599674352174946   \n",
       "15                   0,533127466391065                    0,416367998645988   \n",
       "16                     0,6557280310228                     0,38673728171286   \n",
       "17                    0,98285856519349                    0,681517647956877   \n",
       "18                           1,0169875                            1,0169875   \n",
       "19                   0,800954430164723                    0,504998383855887   \n",
       "20                   0,297076923076923                                    0   \n",
       "21                   0,959823809523809                    0,887839900937936   \n",
       "22                   0,892214685314685                    0,808557342657343   \n",
       "23                              0,9918                     0,94058690744921   \n",
       "24                   0,654829931972789                                    0   \n",
       "25                   0,863583577551971                    0,809404775069472   \n",
       "26                              151643                                    0   \n",
       "27                   0,826521160104293                     0,73129175245682   \n",
       "28                   0,969013067603609                    0,745015394081212   \n",
       "29                             0,99917                              0,87729   \n",
       "\n",
       "   avg_rel_used_a_revoca_autoliquidanti std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                     0,123576651818857                    0,032714976770036   \n",
       "1                                     0                                    0   \n",
       "2                     0,137654704944179                    0,115573259414523   \n",
       "3                     0,252491959064328                   0,0249197649236005   \n",
       "4                     0,284641717931192                   0,0245101240633782   \n",
       "5                      0,65057540086536                     0,05203209285494   \n",
       "6                                     0                                    0   \n",
       "7                    0,0146629395036194                  0,00938302515493416   \n",
       "8                     0,014338503649635                   0,0156933061695499   \n",
       "9                     0,214047098075729                    0,140905816352211   \n",
       "10                    0,105709339774557                    0,061668784045319   \n",
       "11                   0,0644461725126848                    0,053718882317752   \n",
       "12                    0,153247705465165                   0,0521098390986579   \n",
       "13                    0,529653990450205                   0,0881121454276001   \n",
       "14                    0,180249153116531                   0,0288855083825645   \n",
       "15                     0,37710826286117                   0,0585151705576629   \n",
       "16                    0,359894908386187                    0,102254172902609   \n",
       "17                    0,220619905385735                   0,0347397205985855   \n",
       "18                   0,0552298435619735                   0,0020721683250733   \n",
       "19                    0,147342072723942                   0,0218651229538172   \n",
       "20                  0,00393472684414864                  0,00309533028142784   \n",
       "21                    0,292130647590362                    0,028137245748139   \n",
       "22                    0,161366279832153                  0,00594701610644478   \n",
       "23                    0,234048577235772                    0,129814950290693   \n",
       "24                   0,0482941299265197                   0,0500603081420705   \n",
       "25                    0,252594813767091                   0,0220811476943254   \n",
       "26                 7,76588845654993e-05                 0,000209091450918547   \n",
       "27                    0,498746314400993                   0,0334977524587498   \n",
       "28                    0,194098735886107                   0,0224413326185982   \n",
       "29                    0,078669014084507                   0,0277018301862738   \n",
       "\n",
       "   max_rel_used_a_revoca_autoliquidanti last_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                     0,186178173719376                     0,134218262806236   \n",
       "1                                     0                                     0   \n",
       "2                     0,267955342902711                    0,0119617224880383   \n",
       "3                     0,269318979266348                      0,17658293460925   \n",
       "4                     0,315383458646616                     0,306924812030075   \n",
       "5                      0,75066327309748                     0,595085517943497   \n",
       "6                                     0                                     0   \n",
       "7                      0,02496035849707                   0,00597009651844192   \n",
       "8                    0,0438649635036496                   0,00143978102189781   \n",
       "9                     0,351338919925512                                     0   \n",
       "10                    0,199628019323671                   0,00434299516908213   \n",
       "11                    0,143825281270682                   0,00642488418266049   \n",
       "12                    0,221267834793492                     0,099482478097622   \n",
       "13                    0,696123675097072                     0,477022405289117   \n",
       "14                    0,227013550135501                     0,172670054200542   \n",
       "15                     0,49512156448203                     0,384871035940803   \n",
       "16                    0,608458773784355                     0,361408033826638   \n",
       "17                    0,268704876273654                     0,168943959243086   \n",
       "18                   0,0587429602888087                    0,0587429602888087   \n",
       "19                    0,176202051657813                     0,111044880014655   \n",
       "20                   0,0080324459234609                                     0   \n",
       "21                    0,347700301204819                     0,347700301204819   \n",
       "22                     0,16730487804878                     0,151617755048518   \n",
       "23                    0,374948780487805                      0,35570243902439   \n",
       "24                    0,144679358717435                                     0   \n",
       "25                    0,279845827439887                     0,256748231966054   \n",
       "26                 0,000729571984435798                                     0   \n",
       "27                    0,533630819366853                     0,530116387337058   \n",
       "28                    0,229287187039764                     0,226478645066274   \n",
       "29                    0,114713615023474                    0,0514841549295775   \n",
       "\n",
       "   overrun_freq_a_scadenza avg_rel_used_a_scadenza std_rel_used_a_scadenza  \\\n",
       "0        0,333333333333333        1,27369933184855       0,028642038445761   \n",
       "1                        0                       0                       0   \n",
       "2                        0       0,212708532695375       0,100377623990215   \n",
       "3                        0        0,14559735513025      0,0113414597444539   \n",
       "4                        0        0,38485640236956      0,0307032798267901   \n",
       "5                        0       0,409035293119539      0,0730965006549573   \n",
       "6                        0        2,40953703703704       0,241564672078251   \n",
       "7                      0,5       0,163601531081236      0,0316792029521103   \n",
       "8                        0      0,0604969586374696      0,0183848321359603   \n",
       "9                        0        2,14089292364991    4,63836052115501e-16   \n",
       "10                       0       0,072463768115942                       0   \n",
       "11                       0      0,0887348334436356      0,0193342937616968   \n",
       "12                       0       0,131861284939508     0,00617420704782303   \n",
       "13      0,0833333333333333       0,735301321404834      0,0462155669116603   \n",
       "14                       0       0,502086720867209      0,0827169281291274   \n",
       "15                       0         1,9360563777308       0,181163318878327   \n",
       "16                       0        1,95689622973925       0,164308117930946   \n",
       "17                    0,25       0,446912148229015      0,0268070705445783   \n",
       "18                       0       0,120986642599278     0,00767103565035951   \n",
       "19                     0,5       0,317335142272699      0,0455557481627097   \n",
       "20                       0       0,481517505546312      0,0267490915331625   \n",
       "21                       0       0,172019076305221      0,0196131546324518   \n",
       "22       0,416666666666667       0,379730822187254       0,006381729176409   \n",
       "23                       0        1,98546808943089      0,0420881814728821   \n",
       "24      0,0833333333333333       0,951946601536406       0,107436450056201   \n",
       "25      0,0833333333333333      0,0863115040075436     0,00295801997721993   \n",
       "26       0,416666666666667       0,242317282749676     0,00677395747478242   \n",
       "27                       0        0,55561351644941      0,0173859879616584   \n",
       "28      0,0833333333333333       0,370288659793814      0,0413559763129373   \n",
       "29      0,0833333333333333       0,477285602503912      0,0236722918443658   \n",
       "\n",
       "   max_rel_used_a_scadenza last_rel_used_a_scadenza avg_count_enti_affidanti  \\\n",
       "0         1,32464142538975         1,32464142538975         1,16666666666667   \n",
       "1                        0                        0                        1   \n",
       "2         0,33222009569378        0,320196172248804                        3   \n",
       "3        0,162240829346092        0,126861244019139                        3   \n",
       "4        0,478388926862611        0,356901572112098                        3   \n",
       "5        0,548144311529651        0,548144311529651         14,4166666666667   \n",
       "6         2,74656944444444         2,72804166666667         2,33333333333333   \n",
       "7        0,195947948983109        0,131166494312306         4,58333333333333   \n",
       "8       0,0813248175182482       0,0813248175182482         1,41666666666667   \n",
       "9         2,14089292364991         2,14089292364991                        0   \n",
       "10       0,072463768115942        0,072463768115942                        2   \n",
       "11       0,114889477167439       0,0469675711449371         5,83333333333333   \n",
       "12       0,134433667083855        0,122338548185232         4,91666666666667   \n",
       "13       0,796762094658411         0,72403247979851                     15,5   \n",
       "14       0,576208672086721        0,555310298102981                        3   \n",
       "15        2,27354334038055         2,02711522198731         8,16666666666667   \n",
       "16        2,27354334038055         2,12585517970402         8,16666666666667   \n",
       "17       0,500278748180495        0,500278748180495                        8   \n",
       "18       0,124258483754513        0,124258483754513                        1   \n",
       "19       0,379084264517311        0,272506777798131         5,91666666666667   \n",
       "20       0,522436772046589        0,522436772046589         7,66666666666667   \n",
       "21       0,219200301204819        0,219200301204819         3,41666666666667   \n",
       "22       0,389625753999475        0,371850642538683                       14   \n",
       "23        2,04689756097561         2,02848536585366         6,66666666666667   \n",
       "24        1,06908667334669          1,0667745490982         4,83333333333333   \n",
       "25      0,0907448373408769       0,0897807637906648                        6   \n",
       "26        0,25593579766537        0,233945525291829         1,08333333333333   \n",
       "27       0,585378491620112        0,555938547486033         10,0833333333333   \n",
       "28       0,437880706921944        0,310402798232695         5,33333333333333   \n",
       "29       0,506569248826291        0,502116197183099                     4,75   \n",
       "\n",
       "   std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0         0,389249472080761                         2   \n",
       "1                         0                         1   \n",
       "2                         0                         3   \n",
       "3                         0                         3   \n",
       "4                         0                         3   \n",
       "5          1,44337567297406                        17   \n",
       "6         0,492365963917331                         3   \n",
       "7         0,514928650544437                         5   \n",
       "8         0,514928650544437                         2   \n",
       "9                         0                         0   \n",
       "10                        0                         2   \n",
       "11        0,389249472080761                         6   \n",
       "12        0,288675134594813                         5   \n",
       "13        0,674199862463242                        16   \n",
       "14                        0                         3   \n",
       "15        0,834847109936722                         9   \n",
       "16        0,834847109936722                         9   \n",
       "17         1,04446593573419                        10   \n",
       "18                        0                         1   \n",
       "19        0,668557923421522                         7   \n",
       "20        0,492365963917331                         8   \n",
       "21         0,90033663737852                         5   \n",
       "22                        0                        14   \n",
       "23        0,778498944161523                         7   \n",
       "24        0,717740562565273                         6   \n",
       "25                        0                         6   \n",
       "26        0,288675134594813                         2   \n",
       "27        0,288675134594813                        11   \n",
       "28        0,492365963917331                         6   \n",
       "29        0,452267016866645                         5   \n",
       "\n",
       "    last_count_enti_affidanti avg_count_numero_prima_info  \\\n",
       "0                           2            1,08333333333333   \n",
       "1                           1                           1   \n",
       "2                           3            1,91666666666667   \n",
       "3                           3            1,91666666666667   \n",
       "4                           3            2,08333333333333   \n",
       "5                          16            3,91666666666667   \n",
       "6                           3                           0   \n",
       "7                           5                           4   \n",
       "8                           2                           0   \n",
       "9                           0                           0   \n",
       "10                          2                           1   \n",
       "11                          5                           0   \n",
       "12                          4                           0   \n",
       "13                         16                         0,5   \n",
       "14                          3                           0   \n",
       "15                          9                           1   \n",
       "16                          9                           1   \n",
       "17                         10                           1   \n",
       "18                          1                           2   \n",
       "19                          6           0,416666666666667   \n",
       "20                          8                           0   \n",
       "21                          5                           0   \n",
       "22                         14            2,16666666666667   \n",
       "23                          7                           0   \n",
       "24                          4                           0   \n",
       "25                          6                           1   \n",
       "26                          2                           2   \n",
       "27                         11                           0   \n",
       "28                          6           0,583333333333333   \n",
       "29                          4            1,08333333333333   \n",
       "\n",
       "   std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0            0,288675134594813                            2   \n",
       "1                            0                            1   \n",
       "2            0,288675134594813                            2   \n",
       "3            0,288675134594813                            2   \n",
       "4            0,288675134594813                            3   \n",
       "5             1,97522534195852                            6   \n",
       "6                            0                            0   \n",
       "7                            0                            4   \n",
       "8                            0                            0   \n",
       "9                            0                            0   \n",
       "10                           0                            1   \n",
       "11                           0                            0   \n",
       "12                           0                            0   \n",
       "13           0,522232967867094                            1   \n",
       "14                           0                            0   \n",
       "15                           0                            1   \n",
       "16                           0                            1   \n",
       "17            1,04446593573419                            2   \n",
       "18                           0                            2   \n",
       "19           0,514928650544437                            1   \n",
       "20                           0                            0   \n",
       "21                           0                            0   \n",
       "22           0,577350269189626                            4   \n",
       "23                           0                            0   \n",
       "24                           0                            0   \n",
       "25                           0                            1   \n",
       "26                           0                            2   \n",
       "27                           0                            0   \n",
       "28           0,514928650544437                            1   \n",
       "29           0,288675134594813                            2   \n",
       "\n",
       "    last_count_numero_prima_info  \n",
       "0                              1  \n",
       "1                              1  \n",
       "2                              2  \n",
       "3                              2  \n",
       "4                              3  \n",
       "5                              6  \n",
       "6                              0  \n",
       "7                              4  \n",
       "8                              0  \n",
       "9                              0  \n",
       "10                             1  \n",
       "11                             0  \n",
       "12                             0  \n",
       "13                             1  \n",
       "14                             0  \n",
       "15                             1  \n",
       "16                             1  \n",
       "17                             0  \n",
       "18                             2  \n",
       "19                             1  \n",
       "20                             0  \n",
       "21                             0  \n",
       "22                             4  \n",
       "23                             0  \n",
       "24                             0  \n",
       "25                             1  \n",
       "26                             2  \n",
       "27                             0  \n",
       "28                             1  \n",
       "29                             2  "
      ]
     },
     "execution_count": 423,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "test_dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sq/lqj95by96lnccb74l6fsytf00000gn/T/ipykernel_7013/1089663070.py:4: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dataset = dataset.replace(',', '.', regex=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                 object\n",
      "juridical_form                           object\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                   object\n",
      "geo_area                                 object\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "dtype: object\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'MISSING'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[424], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame does not contain any NaN values.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n\u001b[0;32m---> 17\u001b[0m test_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mnormalized_tdata\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataset\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[424], line 6\u001b[0m, in \u001b[0;36mnormalized_tdata\u001b[0;34m(dataset)\u001b[0m\n\u001b[1;32m      4\u001b[0m dataset \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39mreplace(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m, regex\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset\u001b[38;5;241m.\u001b[39mdtypes)\n\u001b[0;32m----> 6\u001b[0m dataset \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfloat32\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# check if the dataset has any nan value\u001b[39;00m\n\u001b[1;32m      9\u001b[0m has_nan_values \u001b[38;5;241m=\u001b[39m dataset\u001b[38;5;241m.\u001b[39misna()\u001b[38;5;241m.\u001b[39many()\u001b[38;5;241m.\u001b[39many()\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/generic.py:6640\u001b[0m, in \u001b[0;36mNDFrame.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m   6634\u001b[0m     results \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m   6635\u001b[0m         ser\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy, errors\u001b[38;5;241m=\u001b[39merrors) \u001b[38;5;28;01mfor\u001b[39;00m _, ser \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   6636\u001b[0m     ]\n\u001b[1;32m   6638\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   6639\u001b[0m     \u001b[38;5;66;03m# else, only a single dtype is given\u001b[39;00m\n\u001b[0;32m-> 6640\u001b[0m     new_data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_mgr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   6641\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_constructor_from_mgr(new_data, axes\u001b[38;5;241m=\u001b[39mnew_data\u001b[38;5;241m.\u001b[39maxes)\n\u001b[1;32m   6642\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mastype\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/internals/managers.py:430\u001b[0m, in \u001b[0;36mBaseBlockManager.astype\u001b[0;34m(self, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m using_copy_on_write():\n\u001b[1;32m    428\u001b[0m     copy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 430\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    431\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mastype\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    432\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    433\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    434\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    435\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_cow\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43musing_copy_on_write\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    436\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/internals/managers.py:363\u001b[0m, in \u001b[0;36mBaseBlockManager.apply\u001b[0;34m(self, f, align_keys, **kwargs)\u001b[0m\n\u001b[1;32m    361\u001b[0m         applied \u001b[38;5;241m=\u001b[39m b\u001b[38;5;241m.\u001b[39mapply(f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    362\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 363\u001b[0m         applied \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     result_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(applied, result_blocks)\n\u001b[1;32m    366\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39mfrom_blocks(result_blocks, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes)\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/internals/blocks.py:758\u001b[0m, in \u001b[0;36mBlock.astype\u001b[0;34m(self, dtype, copy, errors, using_cow, squeeze)\u001b[0m\n\u001b[1;32m    755\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan not squeeze with more than one column.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    756\u001b[0m     values \u001b[38;5;241m=\u001b[39m values[\u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# type: ignore[call-overload]\u001b[39;00m\n\u001b[0;32m--> 758\u001b[0m new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array_safe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    760\u001b[0m new_values \u001b[38;5;241m=\u001b[39m maybe_coerce_values(new_values)\n\u001b[1;32m    762\u001b[0m refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:237\u001b[0m, in \u001b[0;36mastype_array_safe\u001b[0;34m(values, dtype, copy, errors)\u001b[0m\n\u001b[1;32m    234\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtype\u001b[38;5;241m.\u001b[39mnumpy_dtype\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 237\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m \u001b[43mastype_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mValueError\u001b[39;00m, \u001b[38;5;167;01mTypeError\u001b[39;00m):\n\u001b[1;32m    239\u001b[0m     \u001b[38;5;66;03m# e.g. _astype_nansafe can fail on object-dtype of strings\u001b[39;00m\n\u001b[1;32m    240\u001b[0m     \u001b[38;5;66;03m#  trying to convert to float\u001b[39;00m\n\u001b[1;32m    241\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:182\u001b[0m, in \u001b[0;36mastype_array\u001b[0;34m(values, dtype, copy)\u001b[0m\n\u001b[1;32m    179\u001b[0m     values \u001b[38;5;241m=\u001b[39m values\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 182\u001b[0m     values \u001b[38;5;241m=\u001b[39m \u001b[43m_astype_nansafe\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m \u001b[38;5;66;03m# in pandas we don't store numpy str dtypes, so convert to object\u001b[39;00m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(dtype, np\u001b[38;5;241m.\u001b[39mdtype) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(values\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;241m.\u001b[39mtype, \u001b[38;5;28mstr\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/CAI/lib/python3.9/site-packages/pandas/core/dtypes/astype.py:133\u001b[0m, in \u001b[0;36m_astype_nansafe\u001b[0;34m(arr, dtype, copy, skipna)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m copy \u001b[38;5;129;01mor\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mobject\u001b[39m:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# Explicit copy, or required since NumPy can't view from / to object.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43marr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mastype(dtype, copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'MISSING'"
     ]
    }
   ],
   "source": [
    "## normalise test dataset \n",
    "def normalized_tdata(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset\n",
    "test_dataset = normalized_tdata(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>consolidated_liabilities_ratio</th>\n",
       "      <th>tangible_assets_ratio</th>\n",
       "      <th>revenues</th>\n",
       "      <th>cr_available</th>\n",
       "      <th>region</th>\n",
       "      <th>geo_area</th>\n",
       "      <th>last_statement_age</th>\n",
       "      <th>overrun_freq_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>std_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>max_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>last_tension_a_revoca_autoliquidanti</th>\n",
       "      <th>avg_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>std_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>max_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>last_rel_used_a_revoca_autoliquidanti</th>\n",
       "      <th>overrun_freq_a_scadenza</th>\n",
       "      <th>avg_rel_used_a_scadenza</th>\n",
       "      <th>std_rel_used_a_scadenza</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0698090692124105</td>\n",
       "      <td>-0,0133630289532294</td>\n",
       "      <td>0,0454201362604088</td>\n",
       "      <td>0,39200477326969</td>\n",
       "      <td>1</td>\n",
       "      <td>449</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,554859166666667</td>\n",
       "      <td>0,146890245697462</td>\n",
       "      <td>0,83594</td>\n",
       "      <td>0,60264</td>\n",
       "      <td>0,123576651818857</td>\n",
       "      <td>0,032714976770036</td>\n",
       "      <td>0,186178173719376</td>\n",
       "      <td>0,134218262806236</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>1,27369933184855</td>\n",
       "      <td>0,028642038445761</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>46</td>\n",
       "      <td>101</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,169093471113199</td>\n",
       "      <td>0,00206611570247934</td>\n",
       "      <td>0,155359917141378</td>\n",
       "      <td>0,54062940347581</td>\n",
       "      <td>0,95959595959596</td>\n",
       "      <td>1402</td>\n",
       "      <td>False</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,941108491613086</td>\n",
       "      <td>0,0992007690627971</td>\n",
       "      <td>1,0864</td>\n",
       "      <td>1</td>\n",
       "      <td>0,137654704944179</td>\n",
       "      <td>0,115573259414523</td>\n",
       "      <td>0,267955342902711</td>\n",
       "      <td>0,0119617224880383</td>\n",
       "      <td>0</td>\n",
       "      <td>0,212708532695375</td>\n",
       "      <td>0,100377623990215</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>51</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,0589433072553853</td>\n",
       "      <td>0,0306451612903226</td>\n",
       "      <td>0,0043021855102392</td>\n",
       "      <td>0,640767334690816</td>\n",
       "      <td>0,980113636363636</td>\n",
       "      <td>1254</td>\n",
       "      <td>True</td>\n",
       "      <td>18</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,833333333333333</td>\n",
       "      <td>0,878429123495436</td>\n",
       "      <td>0,0566505328975202</td>\n",
       "      <td>0,972473824531666</td>\n",
       "      <td>0,903049655802421</td>\n",
       "      <td>0,252491959064328</td>\n",
       "      <td>0,0249197649236005</td>\n",
       "      <td>0,269318979266348</td>\n",
       "      <td>0,17658293460925</td>\n",
       "      <td>0</td>\n",
       "      <td>0,14559735513025</td>\n",
       "      <td>0,0113414597444539</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>72</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,135170603674541</td>\n",
       "      <td>-0,0755467196819085</td>\n",
       "      <td>0,0169851380042463</td>\n",
       "      <td>0,492125984251969</td>\n",
       "      <td>0,769345238095238</td>\n",
       "      <td>1463</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,722863999082564</td>\n",
       "      <td>0,0605656113993484</td>\n",
       "      <td>0,816631566033492</td>\n",
       "      <td>0,761046273164548</td>\n",
       "      <td>0,284641717931192</td>\n",
       "      <td>0,0245101240633782</td>\n",
       "      <td>0,315383458646616</td>\n",
       "      <td>0,306924812030075</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38485640236956</td>\n",
       "      <td>0,0307032798267901</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0,212602739726027</td>\n",
       "      <td>0,0300330872995673</td>\n",
       "      <td>0,000325626831650928</td>\n",
       "      <td>0,550319634703196</td>\n",
       "      <td>0,965474209650582</td>\n",
       "      <td>3929</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>0,962571308834391</td>\n",
       "      <td>0,0263028736043071</td>\n",
       "      <td>0,985825788026107</td>\n",
       "      <td>0,927813888888889</td>\n",
       "      <td>0,65057540086536</td>\n",
       "      <td>0,05203209285494</td>\n",
       "      <td>0,75066327309748</td>\n",
       "      <td>0,595085517943497</td>\n",
       "      <td>0</td>\n",
       "      <td>0,409035293119539</td>\n",
       "      <td>0,0730965006549573</td>\n",
       "      <td>0,548144311529651</td>\n",
       "      <td>0,548144311529651</td>\n",
       "      <td>14,4166666666667</td>\n",
       "      <td>1,44337567297406</td>\n",
       "      <td>17</td>\n",
       "      <td>16</td>\n",
       "      <td>3,91666666666667</td>\n",
       "      <td>1,97522534195852</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>48</td>\n",
       "      <td>71</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0806451612903226</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0469314079422383</td>\n",
       "      <td>0,625448028673835</td>\n",
       "      <td>1</td>\n",
       "      <td>144</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,40953703703704</td>\n",
       "      <td>0,241564672078251</td>\n",
       "      <td>2,74656944444444</td>\n",
       "      <td>2,72804166666667</td>\n",
       "      <td>2,33333333333333</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>16</td>\n",
       "      <td>0,181209150326797</td>\n",
       "      <td>0,132992097701149</td>\n",
       "      <td>0,0224453632604843</td>\n",
       "      <td>0,400326797385621</td>\n",
       "      <td>0,838453572661374</td>\n",
       "      <td>11604</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,801134920634921</td>\n",
       "      <td>0,162625295169213</td>\n",
       "      <td>0,997085714285714</td>\n",
       "      <td>0,989671428571429</td>\n",
       "      <td>0,0146629395036194</td>\n",
       "      <td>0,00938302515493416</td>\n",
       "      <td>0,02496035849707</td>\n",
       "      <td>0,00597009651844192</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,163601531081236</td>\n",
       "      <td>0,0316792029521103</td>\n",
       "      <td>0,195947948983109</td>\n",
       "      <td>0,131166494312306</td>\n",
       "      <td>4,58333333333333</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>52</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,456674473067916</td>\n",
       "      <td>0,0857664233576642</td>\n",
       "      <td>0,09</td>\n",
       "      <td>0,566744730679157</td>\n",
       "      <td>1</td>\n",
       "      <td>548</td>\n",
       "      <td>True</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,15715</td>\n",
       "      <td>0,171998635618267</td>\n",
       "      <td>0,48076</td>\n",
       "      <td>0,01578</td>\n",
       "      <td>0,014338503649635</td>\n",
       "      <td>0,0156933061695499</td>\n",
       "      <td>0,0438649635036496</td>\n",
       "      <td>0,00143978102189781</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0604969586374696</td>\n",
       "      <td>0,0183848321359603</td>\n",
       "      <td>0,0813248175182482</td>\n",
       "      <td>0,0813248175182482</td>\n",
       "      <td>1,41666666666667</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,0144619044637826</td>\n",
       "      <td>-0,454376163873371</td>\n",
       "      <td>0,004375</td>\n",
       "      <td>0,68690915920616</td>\n",
       "      <td>0,990120364572462</td>\n",
       "      <td>1074</td>\n",
       "      <td>True</td>\n",
       "      <td>17</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,550165188172043</td>\n",
       "      <td>0,35657406042894</td>\n",
       "      <td>0,89842380952381</td>\n",
       "      <td>0</td>\n",
       "      <td>0,214047098075729</td>\n",
       "      <td>0,140905816352211</td>\n",
       "      <td>0,351338919925512</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>4,63836052115501e-16</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>2,14089292364991</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>48</td>\n",
       "      <td>51</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0,31540847983454</td>\n",
       "      <td>0,0314009661835749</td>\n",
       "      <td>0,00859598853868195</td>\n",
       "      <td>0,641158221302999</td>\n",
       "      <td>0,294498381877023</td>\n",
       "      <td>414</td>\n",
       "      <td>True</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,432869884853596</td>\n",
       "      <td>0,252745760238384</td>\n",
       "      <td>0,817354668987479</td>\n",
       "      <td>0,0176624295172793</td>\n",
       "      <td>0,105709339774557</td>\n",
       "      <td>0,061668784045319</td>\n",
       "      <td>0,199628019323671</td>\n",
       "      <td>0,00434299516908213</td>\n",
       "      <td>0</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>0</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>0,072463768115942</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,141483516483516</td>\n",
       "      <td>-0,0277594183740912</td>\n",
       "      <td>0,10952380952381</td>\n",
       "      <td>0,68956043956044</td>\n",
       "      <td>0,980519480519481</td>\n",
       "      <td>1511</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0,166666666666667</td>\n",
       "      <td>0,389512666666667</td>\n",
       "      <td>0,324676924728493</td>\n",
       "      <td>0,86928</td>\n",
       "      <td>0,038832</td>\n",
       "      <td>0,0644461725126848</td>\n",
       "      <td>0,053718882317752</td>\n",
       "      <td>0,143825281270682</td>\n",
       "      <td>0,00642488418266049</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0887348334436356</td>\n",
       "      <td>0,0193342937616968</td>\n",
       "      <td>0,114889477167439</td>\n",
       "      <td>0,0469675711449371</td>\n",
       "      <td>5,83333333333333</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>57</td>\n",
       "      <td>91</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0,443548387096774</td>\n",
       "      <td>-0,107561929595828</td>\n",
       "      <td>0,0156569094622192</td>\n",
       "      <td>0,485483870967742</td>\n",
       "      <td>0,920870425321464</td>\n",
       "      <td>1598</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,680249537037037</td>\n",
       "      <td>0,231309785776821</td>\n",
       "      <td>0,982183333333333</td>\n",
       "      <td>0,441591666666667</td>\n",
       "      <td>0,153247705465165</td>\n",
       "      <td>0,0521098390986579</td>\n",
       "      <td>0,221267834793492</td>\n",
       "      <td>0,099482478097622</td>\n",
       "      <td>0</td>\n",
       "      <td>0,131861284939508</td>\n",
       "      <td>0,00617420704782303</td>\n",
       "      <td>0,134433667083855</td>\n",
       "      <td>0,122338548185232</td>\n",
       "      <td>4,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>50</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>0,0511390517698671</td>\n",
       "      <td>-0,202533995451803</td>\n",
       "      <td>0,00750618641737696</td>\n",
       "      <td>0,657252225774541</td>\n",
       "      <td>0,706839219915521</td>\n",
       "      <td>19058</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,583333333333333</td>\n",
       "      <td>0,798658440088396</td>\n",
       "      <td>0,0526465224978752</td>\n",
       "      <td>0,849462658254437</td>\n",
       "      <td>0,707507345829415</td>\n",
       "      <td>0,529653990450205</td>\n",
       "      <td>0,0881121454276001</td>\n",
       "      <td>0,696123675097072</td>\n",
       "      <td>0,477022405289117</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,735301321404834</td>\n",
       "      <td>0,0462155669116603</td>\n",
       "      <td>0,796762094658411</td>\n",
       "      <td>0,72403247979851</td>\n",
       "      <td>15,5</td>\n",
       "      <td>0,674199862463242</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>53</td>\n",
       "      <td>74</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0,383680555555556</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,120171673819742</td>\n",
       "      <td>0,58275462962963</td>\n",
       "      <td>0,996231155778894</td>\n",
       "      <td>1476</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,628923562838665</td>\n",
       "      <td>0,103512084354466</td>\n",
       "      <td>0,788404705882353</td>\n",
       "      <td>0,599674352174946</td>\n",
       "      <td>0,180249153116531</td>\n",
       "      <td>0,0288855083825645</td>\n",
       "      <td>0,227013550135501</td>\n",
       "      <td>0,172670054200542</td>\n",
       "      <td>0</td>\n",
       "      <td>0,502086720867209</td>\n",
       "      <td>0,0827169281291274</td>\n",
       "      <td>0,576208672086721</td>\n",
       "      <td>0,555310298102981</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,229961682960403</td>\n",
       "      <td>0,0296371270618898</td>\n",
       "      <td>0</td>\n",
       "      <td>0,370582043783666</td>\n",
       "      <td>1</td>\n",
       "      <td>946</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,407657248453215</td>\n",
       "      <td>0,0627932392858802</td>\n",
       "      <td>0,533127466391065</td>\n",
       "      <td>0,416367998645988</td>\n",
       "      <td>0,37710826286117</td>\n",
       "      <td>0,0585151705576629</td>\n",
       "      <td>0,49512156448203</td>\n",
       "      <td>0,384871035940803</td>\n",
       "      <td>0</td>\n",
       "      <td>1,9360563777308</td>\n",
       "      <td>0,181163318878327</td>\n",
       "      <td>2,27354334038055</td>\n",
       "      <td>2,02711522198731</td>\n",
       "      <td>8,16666666666667</td>\n",
       "      <td>0,834847109936722</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>24</td>\n",
       "      <td>96</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,229961682960403</td>\n",
       "      <td>0,0296371270618898</td>\n",
       "      <td>0</td>\n",
       "      <td>0,370582043783666</td>\n",
       "      <td>1</td>\n",
       "      <td>946</td>\n",
       "      <td>True</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,38907167988079</td>\n",
       "      <td>0,110072083071302</td>\n",
       "      <td>0,6557280310228</td>\n",
       "      <td>0,38673728171286</td>\n",
       "      <td>0,359894908386187</td>\n",
       "      <td>0,102254172902609</td>\n",
       "      <td>0,608458773784355</td>\n",
       "      <td>0,361408033826638</td>\n",
       "      <td>0</td>\n",
       "      <td>1,95689622973925</td>\n",
       "      <td>0,164308117930946</td>\n",
       "      <td>2,27354334038055</td>\n",
       "      <td>2,12585517970402</td>\n",
       "      <td>8,16666666666667</td>\n",
       "      <td>0,834847109936722</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>46</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,17374616171955</td>\n",
       "      <td>0,0262008733624454</td>\n",
       "      <td>0</td>\n",
       "      <td>0,323439099283521</td>\n",
       "      <td>0,997134670487106</td>\n",
       "      <td>2748</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,25</td>\n",
       "      <td>0,788993056125199</td>\n",
       "      <td>0,121123110275902</td>\n",
       "      <td>0,98285856519349</td>\n",
       "      <td>0,681517647956877</td>\n",
       "      <td>0,220619905385735</td>\n",
       "      <td>0,0347397205985855</td>\n",
       "      <td>0,268704876273654</td>\n",
       "      <td>0,168943959243086</td>\n",
       "      <td>0,25</td>\n",
       "      <td>0,446912148229015</td>\n",
       "      <td>0,0268070705445783</td>\n",
       "      <td>0,500278748180495</td>\n",
       "      <td>0,500278748180495</td>\n",
       "      <td>8</td>\n",
       "      <td>1,04446593573419</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1,04446593573419</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>0,3963133640553</td>\n",
       "      <td>0,00866425992779783</td>\n",
       "      <td>0,0558002936857562</td>\n",
       "      <td>0,412771560236998</td>\n",
       "      <td>0,973747016706444</td>\n",
       "      <td>1385</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>0,956168637915266</td>\n",
       "      <td>0,0358738162380265</td>\n",
       "      <td>1,0169875</td>\n",
       "      <td>1,0169875</td>\n",
       "      <td>0,0552298435619735</td>\n",
       "      <td>0,0020721683250733</td>\n",
       "      <td>0,0587429602888087</td>\n",
       "      <td>0,0587429602888087</td>\n",
       "      <td>0</td>\n",
       "      <td>0,120986642599278</td>\n",
       "      <td>0,00767103565035951</td>\n",
       "      <td>0,124258483754513</td>\n",
       "      <td>0,124258483754513</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0,240783889489889</td>\n",
       "      <td>0,0178091397849462</td>\n",
       "      <td>0,306265984654731</td>\n",
       "      <td>0,42939169509861</td>\n",
       "      <td>0,793959382051727</td>\n",
       "      <td>10918</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0,916666666666667</td>\n",
       "      <td>0,669427384796735</td>\n",
       "      <td>0,0992854648085776</td>\n",
       "      <td>0,800954430164723</td>\n",
       "      <td>0,504998383855887</td>\n",
       "      <td>0,147342072723942</td>\n",
       "      <td>0,0218651229538172</td>\n",
       "      <td>0,176202051657813</td>\n",
       "      <td>0,111044880014655</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,317335142272699</td>\n",
       "      <td>0,0455557481627097</td>\n",
       "      <td>0,379084264517311</td>\n",
       "      <td>0,272506777798131</td>\n",
       "      <td>5,91666666666667</td>\n",
       "      <td>0,668557923421522</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,0301587301587302</td>\n",
       "      <td>-0,0029130253849355</td>\n",
       "      <td>0,0754716981132075</td>\n",
       "      <td>0,307503607503608</td>\n",
       "      <td>0,866206589492431</td>\n",
       "      <td>4808</td>\n",
       "      <td>True</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,144379904014562</td>\n",
       "      <td>0,115279495811948</td>\n",
       "      <td>0,297076923076923</td>\n",
       "      <td>0</td>\n",
       "      <td>0,00393472684414864</td>\n",
       "      <td>0,00309533028142784</td>\n",
       "      <td>0,0080324459234609</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0,481517505546312</td>\n",
       "      <td>0,0267490915331625</td>\n",
       "      <td>0,522436772046589</td>\n",
       "      <td>0,522436772046589</td>\n",
       "      <td>7,66666666666667</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>76</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0,295138888888889</td>\n",
       "      <td>0,0121951219512195</td>\n",
       "      <td>0,00302114803625378</td>\n",
       "      <td>0,388888888888889</td>\n",
       "      <td>0,335834896810507</td>\n",
       "      <td>664</td>\n",
       "      <td>True</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,882571959792879</td>\n",
       "      <td>0,0627466955596793</td>\n",
       "      <td>0,959823809523809</td>\n",
       "      <td>0,887839900937936</td>\n",
       "      <td>0,292130647590362</td>\n",
       "      <td>0,028137245748139</td>\n",
       "      <td>0,347700301204819</td>\n",
       "      <td>0,347700301204819</td>\n",
       "      <td>0</td>\n",
       "      <td>0,172019076305221</td>\n",
       "      <td>0,0196131546324518</td>\n",
       "      <td>0,219200301204819</td>\n",
       "      <td>0,219200301204819</td>\n",
       "      <td>3,41666666666667</td>\n",
       "      <td>0,90033663737852</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>58</td>\n",
       "      <td>41</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,140170826988016</td>\n",
       "      <td>-0,00601684717208183</td>\n",
       "      <td>0,000402738622633911</td>\n",
       "      <td>0,413560219823876</td>\n",
       "      <td>0,587057314787412</td>\n",
       "      <td>7626</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0,75</td>\n",
       "      <td>0,86054493006993</td>\n",
       "      <td>0,0317146467326909</td>\n",
       "      <td>0,892214685314685</td>\n",
       "      <td>0,808557342657343</td>\n",
       "      <td>0,161366279832153</td>\n",
       "      <td>0,00594701610644478</td>\n",
       "      <td>0,16730487804878</td>\n",
       "      <td>0,151617755048518</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,379730822187254</td>\n",
       "      <td>0,006381729176409</td>\n",
       "      <td>0,389625753999475</td>\n",
       "      <td>0,371850642538683</td>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>2,16666666666667</td>\n",
       "      <td>0,577350269189626</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>14</td>\n",
       "      <td>55</td>\n",
       "      <td>48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,464636707194417</td>\n",
       "      <td>0,0125934084914631</td>\n",
       "      <td>0</td>\n",
       "      <td>0,416001808268284</td>\n",
       "      <td>1</td>\n",
       "      <td>410</td>\n",
       "      <td>True</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,61671781205978</td>\n",
       "      <td>0,343459428362498</td>\n",
       "      <td>0,9918</td>\n",
       "      <td>0,94058690744921</td>\n",
       "      <td>0,234048577235772</td>\n",
       "      <td>0,129814950290693</td>\n",
       "      <td>0,374948780487805</td>\n",
       "      <td>0,35570243902439</td>\n",
       "      <td>0</td>\n",
       "      <td>1,98546808943089</td>\n",
       "      <td>0,0420881814728821</td>\n",
       "      <td>2,04689756097561</td>\n",
       "      <td>2,02848536585366</td>\n",
       "      <td>6,66666666666667</td>\n",
       "      <td>0,778498944161523</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>47</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,363423212192263</td>\n",
       "      <td>0,0251382604323781</td>\n",
       "      <td>0,0212373037857802</td>\n",
       "      <td>0,78810082063306</td>\n",
       "      <td>0,855302705023615</td>\n",
       "      <td>1996</td>\n",
       "      <td>True</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0,257538076245022</td>\n",
       "      <td>0,234986131346604</td>\n",
       "      <td>0,654829931972789</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0482941299265197</td>\n",
       "      <td>0,0500603081420705</td>\n",
       "      <td>0,144679358717435</td>\n",
       "      <td>0</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,951946601536406</td>\n",
       "      <td>0,107436450056201</td>\n",
       "      <td>1,06908667334669</td>\n",
       "      <td>1,0667745490982</td>\n",
       "      <td>4,83333333333333</td>\n",
       "      <td>0,717740562565273</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,110410094637224</td>\n",
       "      <td>0,000302114803625378</td>\n",
       "      <td>0,000453514739229025</td>\n",
       "      <td>0,572780531771068</td>\n",
       "      <td>0,913793103448276</td>\n",
       "      <td>3535</td>\n",
       "      <td>True</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,760519982603886</td>\n",
       "      <td>0,0484556156116301</td>\n",
       "      <td>0,863583577551971</td>\n",
       "      <td>0,809404775069472</td>\n",
       "      <td>0,252594813767091</td>\n",
       "      <td>0,0220811476943254</td>\n",
       "      <td>0,279845827439887</td>\n",
       "      <td>0,256748231966054</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,0863115040075436</td>\n",
       "      <td>0,00295801997721993</td>\n",
       "      <td>0,0907448373408769</td>\n",
       "      <td>0,0897807637906648</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>46</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>0,16093023255814</td>\n",
       "      <td>0,0536082474226804</td>\n",
       "      <td>0,0098159509202454</td>\n",
       "      <td>0,562790697674419</td>\n",
       "      <td>0,334615384615385</td>\n",
       "      <td>514</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0,333333333333333</td>\n",
       "      <td>50547,6666666667</td>\n",
       "      <td>74663,8518663158</td>\n",
       "      <td>151643</td>\n",
       "      <td>0</td>\n",
       "      <td>7,76588845654993e-05</td>\n",
       "      <td>0,000209091450918547</td>\n",
       "      <td>0,000729571984435798</td>\n",
       "      <td>0</td>\n",
       "      <td>0,416666666666667</td>\n",
       "      <td>0,242317282749676</td>\n",
       "      <td>0,00677395747478242</td>\n",
       "      <td>0,25593579766537</td>\n",
       "      <td>0,233945525291829</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>20</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0,231349782293179</td>\n",
       "      <td>0,0194128787878788</td>\n",
       "      <td>0,0804071246819338</td>\n",
       "      <td>0,443251088534107</td>\n",
       "      <td>0,565540540540541</td>\n",
       "      <td>2148</td>\n",
       "      <td>True</td>\n",
       "      <td>16</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,733450051894817</td>\n",
       "      <td>0,0431962210755328</td>\n",
       "      <td>0,826521160104293</td>\n",
       "      <td>0,73129175245682</td>\n",
       "      <td>0,498746314400993</td>\n",
       "      <td>0,0334977524587498</td>\n",
       "      <td>0,533630819366853</td>\n",
       "      <td>0,530116387337058</td>\n",
       "      <td>0</td>\n",
       "      <td>0,55561351644941</td>\n",
       "      <td>0,0173859879616584</td>\n",
       "      <td>0,585378491620112</td>\n",
       "      <td>0,555938547486033</td>\n",
       "      <td>10,0833333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>52</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0,123490455784963</td>\n",
       "      <td>0,00589101620029455</td>\n",
       "      <td>0,00174520069808028</td>\n",
       "      <td>0,773276197896377</td>\n",
       "      <td>0,988740323715693</td>\n",
       "      <td>1358</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,817854559348955</td>\n",
       "      <td>0,0755611328793689</td>\n",
       "      <td>0,969013067603609</td>\n",
       "      <td>0,745015394081212</td>\n",
       "      <td>0,194098735886107</td>\n",
       "      <td>0,0224413326185982</td>\n",
       "      <td>0,229287187039764</td>\n",
       "      <td>0,226478645066274</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,370288659793814</td>\n",
       "      <td>0,0413559763129373</td>\n",
       "      <td>0,437880706921944</td>\n",
       "      <td>0,310402798232695</td>\n",
       "      <td>5,33333333333333</td>\n",
       "      <td>0,492365963917331</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0,583333333333333</td>\n",
       "      <td>0,514928650544437</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>80</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0,19488597097443</td>\n",
       "      <td>-0,0117508813160987</td>\n",
       "      <td>0,0157342657342657</td>\n",
       "      <td>0,387007601935038</td>\n",
       "      <td>0,970285714285714</td>\n",
       "      <td>1704</td>\n",
       "      <td>True</td>\n",
       "      <td>19</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0,902962083333333</td>\n",
       "      <td>0,109107650603728</td>\n",
       "      <td>0,99917</td>\n",
       "      <td>0,87729</td>\n",
       "      <td>0,078669014084507</td>\n",
       "      <td>0,0277018301862738</td>\n",
       "      <td>0,114713615023474</td>\n",
       "      <td>0,0514841549295775</td>\n",
       "      <td>0,0833333333333333</td>\n",
       "      <td>0,477285602503912</td>\n",
       "      <td>0,0236722918443658</td>\n",
       "      <td>0,506569248826291</td>\n",
       "      <td>0,502116197183099</td>\n",
       "      <td>4,75</td>\n",
       "      <td>0,452267016866645</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    external_score_ver01  external_score_ver02 external_score_ver03  age  \\\n",
       "0                      5                     1                   11    6   \n",
       "1                      8                     1                    9   46   \n",
       "2                      8                     1                    6   51   \n",
       "3                      8                     1                    9   51   \n",
       "4                      6                     1                    9   72   \n",
       "5                      6                     1                    7   25   \n",
       "6                      5                     1                    8   48   \n",
       "7                      6                     1                    7   60   \n",
       "8                      5                     1                    3   52   \n",
       "9                      6                     1                   10   47   \n",
       "10                     8                     1                   14   48   \n",
       "11                     7                     1                    5   53   \n",
       "12                     6                     1                    7   57   \n",
       "13                     9                     1                   14   50   \n",
       "14                     5                     1                    4   53   \n",
       "15                    10                     2                   11   24   \n",
       "16                    10                     2                   10   24   \n",
       "17                     6                     1                   11   46   \n",
       "18                     8                     1                   11    6   \n",
       "19                     9                     1                   14   10   \n",
       "20                     5                     1                    3   46   \n",
       "21                     7                     1                   10    6   \n",
       "22                     7                     1                   10   58   \n",
       "23                    10                     3                   14   55   \n",
       "24                     8                     1                   10   47   \n",
       "25                     8                     1                   14    6   \n",
       "26                     7                     1                    5   46   \n",
       "27                     7                     1                    9   20   \n",
       "28                     6                     1                   14   52   \n",
       "29                     4                     1                    7    6   \n",
       "\n",
       "   province juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0         5              1                3  0,0698090692124105   \n",
       "1       101              1                8   0,169093471113199   \n",
       "2        69              1               12  0,0589433072553853   \n",
       "3        69              1               12  0,0589433072553853   \n",
       "4        51              1               15   0,135170603674541   \n",
       "5         5              1                4   0,212602739726027   \n",
       "6        71              1                3  0,0806451612903226   \n",
       "7         1              5               16   0,181209150326797   \n",
       "8        22              1               15   0,456674473067916   \n",
       "9        68              1                1  0,0144619044637826   \n",
       "10       51              1               10    0,31540847983454   \n",
       "11       52              1               15   0,141483516483516   \n",
       "12       91              1                2   0,443548387096774   \n",
       "13        9              5               10  0,0511390517698671   \n",
       "14       74              1                6   0,383680555555556   \n",
       "15       96              1                3   0,229961682960403   \n",
       "16       96              1                3   0,229961682960403   \n",
       "17       21              1                3    0,17374616171955   \n",
       "18       76              1               15     0,3963133640553   \n",
       "19        9              1               12   0,240783889489889   \n",
       "20       10              4                3  0,0301587301587302   \n",
       "21       76              1               10   0,295138888888889   \n",
       "22       41              4                3   0,140170826988016   \n",
       "23       48              1                1   0,464636707194417   \n",
       "24        9              1                1   0,363423212192263   \n",
       "25       34              1                8   0,110410094637224   \n",
       "26       49              1               18    0,16093023255814   \n",
       "27       65              1                8   0,231349782293179   \n",
       "28       80              1                3   0,123490455784963   \n",
       "29       80              4                3    0,19488597097443   \n",
       "\n",
       "       core_income_ratio      cash_asset_ratio consolidated_liabilities_ratio  \\\n",
       "0    -0,0133630289532294    0,0454201362604088               0,39200477326969   \n",
       "1    0,00206611570247934     0,155359917141378               0,54062940347581   \n",
       "2     0,0306451612903226    0,0043021855102392              0,640767334690816   \n",
       "3     0,0306451612903226    0,0043021855102392              0,640767334690816   \n",
       "4    -0,0755467196819085    0,0169851380042463              0,492125984251969   \n",
       "5     0,0300330872995673  0,000325626831650928              0,550319634703196   \n",
       "6                      0    0,0469314079422383              0,625448028673835   \n",
       "7      0,132992097701149    0,0224453632604843              0,400326797385621   \n",
       "8     0,0857664233576642                  0,09              0,566744730679157   \n",
       "9     -0,454376163873371              0,004375               0,68690915920616   \n",
       "10    0,0314009661835749   0,00859598853868195              0,641158221302999   \n",
       "11   -0,0277594183740912      0,10952380952381               0,68956043956044   \n",
       "12    -0,107561929595828    0,0156569094622192              0,485483870967742   \n",
       "13    -0,202533995451803   0,00750618641737696              0,657252225774541   \n",
       "14    0,0833333333333333     0,120171673819742               0,58275462962963   \n",
       "15    0,0296371270618898                     0              0,370582043783666   \n",
       "16    0,0296371270618898                     0              0,370582043783666   \n",
       "17    0,0262008733624454                     0              0,323439099283521   \n",
       "18   0,00866425992779783    0,0558002936857562              0,412771560236998   \n",
       "19    0,0178091397849462     0,306265984654731               0,42939169509861   \n",
       "20   -0,0029130253849355    0,0754716981132075              0,307503607503608   \n",
       "21    0,0121951219512195   0,00302114803625378              0,388888888888889   \n",
       "22  -0,00601684717208183  0,000402738622633911              0,413560219823876   \n",
       "23    0,0125934084914631                     0              0,416001808268284   \n",
       "24    0,0251382604323781    0,0212373037857802               0,78810082063306   \n",
       "25  0,000302114803625378  0,000453514739229025              0,572780531771068   \n",
       "26    0,0536082474226804    0,0098159509202454              0,562790697674419   \n",
       "27    0,0194128787878788    0,0804071246819338              0,443251088534107   \n",
       "28   0,00589101620029455   0,00174520069808028              0,773276197896377   \n",
       "29   -0,0117508813160987    0,0157342657342657              0,387007601935038   \n",
       "\n",
       "   tangible_assets_ratio revenues  cr_available region geo_area  \\\n",
       "0                      1      449          True      5        4   \n",
       "1       0,95959595959596     1402         False     18        2   \n",
       "2      0,980113636363636     1254          True     18        2   \n",
       "3      0,980113636363636     1254          True     18        2   \n",
       "4      0,769345238095238     1463          True      2        1   \n",
       "5      0,965474209650582     3929          True      5        4   \n",
       "6                      1      144          True     19        4   \n",
       "7      0,838453572661374    11604          True      1        1   \n",
       "8                      1      548          True      7        2   \n",
       "9      0,990120364572462     1074          True     17        5   \n",
       "10     0,294498381877023      414          True      2        1   \n",
       "11     0,980519480519481     1511          True     16        3   \n",
       "12     0,920870425321464     1598          True     13        3   \n",
       "13     0,706839219915521    19058          True      9        2   \n",
       "14     0,996231155778894     1476          True     16        3   \n",
       "15                     1      946          True      3        2   \n",
       "16                     1      946          True      3        2   \n",
       "17     0,997134670487106     2748          True      1        1   \n",
       "18     0,973747016706444     1385          True     13        3   \n",
       "19     0,793959382051727    10918          True      9        2   \n",
       "20     0,866206589492431     4808          True     10        2   \n",
       "21     0,335834896810507      664          True     13        3   \n",
       "22     0,587057314787412     7626          True     15        2   \n",
       "23                     1      410          True     15        2   \n",
       "24     0,855302705023615     1996          True      9        2   \n",
       "25     0,913793103448276     3535          True      5        4   \n",
       "26     0,334615384615385      514          True     16        3   \n",
       "27     0,565540540540541     2148          True     16        3   \n",
       "28     0,988740323715693     1358          True     19        4   \n",
       "29     0,970285714285714     1704          True     19        4   \n",
       "\n",
       "    last_statement_age overrun_freq_a_revoca_autoliquidanti  \\\n",
       "0                    1                    0,166666666666667   \n",
       "1                    1                                    0   \n",
       "2                    2                    0,833333333333333   \n",
       "3                    2                    0,833333333333333   \n",
       "4                    2                                    0   \n",
       "5                    2                    0,333333333333333   \n",
       "6                    1                                    0   \n",
       "7                    2                                  0,5   \n",
       "8                    2                                    0   \n",
       "9                    1                                    0   \n",
       "10                   2                                    0   \n",
       "11                   1                    0,166666666666667   \n",
       "12                   2                   0,0833333333333333   \n",
       "13                   2                    0,583333333333333   \n",
       "14                   2                   0,0833333333333333   \n",
       "15                   2                                    0   \n",
       "16                   2                                    0   \n",
       "17                   1                                 0,25   \n",
       "18                   2                    0,333333333333333   \n",
       "19                   4                    0,916666666666667   \n",
       "20                   1                                    0   \n",
       "21                   2                   0,0833333333333333   \n",
       "22                   1                                 0,75   \n",
       "23                   2                   0,0833333333333333   \n",
       "24                   1                                    0   \n",
       "25                   3                                  0,5   \n",
       "26                   1                    0,333333333333333   \n",
       "27                   2                                    0   \n",
       "28                   2                                  0,5   \n",
       "29                   2                                    0   \n",
       "\n",
       "   avg_tension_a_revoca_autoliquidanti std_tension_a_revoca_autoliquidanti  \\\n",
       "0                    0,554859166666667                   0,146890245697462   \n",
       "1                                    0                                   0   \n",
       "2                    0,941108491613086                  0,0992007690627971   \n",
       "3                    0,878429123495436                  0,0566505328975202   \n",
       "4                    0,722863999082564                  0,0605656113993484   \n",
       "5                    0,962571308834391                  0,0263028736043071   \n",
       "6                                    0                                   0   \n",
       "7                    0,801134920634921                   0,162625295169213   \n",
       "8                              0,15715                   0,171998635618267   \n",
       "9                    0,550165188172043                    0,35657406042894   \n",
       "10                   0,432869884853596                   0,252745760238384   \n",
       "11                   0,389512666666667                   0,324676924728493   \n",
       "12                   0,680249537037037                   0,231309785776821   \n",
       "13                   0,798658440088396                  0,0526465224978752   \n",
       "14                   0,628923562838665                   0,103512084354466   \n",
       "15                   0,407657248453215                  0,0627932392858802   \n",
       "16                    0,38907167988079                   0,110072083071302   \n",
       "17                   0,788993056125199                   0,121123110275902   \n",
       "18                   0,956168637915266                  0,0358738162380265   \n",
       "19                   0,669427384796735                  0,0992854648085776   \n",
       "20                   0,144379904014562                   0,115279495811948   \n",
       "21                   0,882571959792879                  0,0627466955596793   \n",
       "22                    0,86054493006993                  0,0317146467326909   \n",
       "23                    0,61671781205978                   0,343459428362498   \n",
       "24                   0,257538076245022                   0,234986131346604   \n",
       "25                   0,760519982603886                  0,0484556156116301   \n",
       "26                    50547,6666666667                    74663,8518663158   \n",
       "27                   0,733450051894817                  0,0431962210755328   \n",
       "28                   0,817854559348955                  0,0755611328793689   \n",
       "29                   0,902962083333333                   0,109107650603728   \n",
       "\n",
       "   max_tension_a_revoca_autoliquidanti last_tension_a_revoca_autoliquidanti  \\\n",
       "0                              0,83594                              0,60264   \n",
       "1                                    0                                    0   \n",
       "2                               1,0864                                    1   \n",
       "3                    0,972473824531666                    0,903049655802421   \n",
       "4                    0,816631566033492                    0,761046273164548   \n",
       "5                    0,985825788026107                    0,927813888888889   \n",
       "6                                    0                                    0   \n",
       "7                    0,997085714285714                    0,989671428571429   \n",
       "8                              0,48076                              0,01578   \n",
       "9                     0,89842380952381                                    0   \n",
       "10                   0,817354668987479                   0,0176624295172793   \n",
       "11                             0,86928                             0,038832   \n",
       "12                   0,982183333333333                    0,441591666666667   \n",
       "13                   0,849462658254437                    0,707507345829415   \n",
       "14                   0,788404705882353                    0,599674352174946   \n",
       "15                   0,533127466391065                    0,416367998645988   \n",
       "16                     0,6557280310228                     0,38673728171286   \n",
       "17                    0,98285856519349                    0,681517647956877   \n",
       "18                           1,0169875                            1,0169875   \n",
       "19                   0,800954430164723                    0,504998383855887   \n",
       "20                   0,297076923076923                                    0   \n",
       "21                   0,959823809523809                    0,887839900937936   \n",
       "22                   0,892214685314685                    0,808557342657343   \n",
       "23                              0,9918                     0,94058690744921   \n",
       "24                   0,654829931972789                                    0   \n",
       "25                   0,863583577551971                    0,809404775069472   \n",
       "26                              151643                                    0   \n",
       "27                   0,826521160104293                     0,73129175245682   \n",
       "28                   0,969013067603609                    0,745015394081212   \n",
       "29                             0,99917                              0,87729   \n",
       "\n",
       "   avg_rel_used_a_revoca_autoliquidanti std_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                     0,123576651818857                    0,032714976770036   \n",
       "1                                     0                                    0   \n",
       "2                     0,137654704944179                    0,115573259414523   \n",
       "3                     0,252491959064328                   0,0249197649236005   \n",
       "4                     0,284641717931192                   0,0245101240633782   \n",
       "5                      0,65057540086536                     0,05203209285494   \n",
       "6                                     0                                    0   \n",
       "7                    0,0146629395036194                  0,00938302515493416   \n",
       "8                     0,014338503649635                   0,0156933061695499   \n",
       "9                     0,214047098075729                    0,140905816352211   \n",
       "10                    0,105709339774557                    0,061668784045319   \n",
       "11                   0,0644461725126848                    0,053718882317752   \n",
       "12                    0,153247705465165                   0,0521098390986579   \n",
       "13                    0,529653990450205                   0,0881121454276001   \n",
       "14                    0,180249153116531                   0,0288855083825645   \n",
       "15                     0,37710826286117                   0,0585151705576629   \n",
       "16                    0,359894908386187                    0,102254172902609   \n",
       "17                    0,220619905385735                   0,0347397205985855   \n",
       "18                   0,0552298435619735                   0,0020721683250733   \n",
       "19                    0,147342072723942                   0,0218651229538172   \n",
       "20                  0,00393472684414864                  0,00309533028142784   \n",
       "21                    0,292130647590362                    0,028137245748139   \n",
       "22                    0,161366279832153                  0,00594701610644478   \n",
       "23                    0,234048577235772                    0,129814950290693   \n",
       "24                   0,0482941299265197                   0,0500603081420705   \n",
       "25                    0,252594813767091                   0,0220811476943254   \n",
       "26                 7,76588845654993e-05                 0,000209091450918547   \n",
       "27                    0,498746314400993                   0,0334977524587498   \n",
       "28                    0,194098735886107                   0,0224413326185982   \n",
       "29                    0,078669014084507                   0,0277018301862738   \n",
       "\n",
       "   max_rel_used_a_revoca_autoliquidanti last_rel_used_a_revoca_autoliquidanti  \\\n",
       "0                     0,186178173719376                     0,134218262806236   \n",
       "1                                     0                                     0   \n",
       "2                     0,267955342902711                    0,0119617224880383   \n",
       "3                     0,269318979266348                      0,17658293460925   \n",
       "4                     0,315383458646616                     0,306924812030075   \n",
       "5                      0,75066327309748                     0,595085517943497   \n",
       "6                                     0                                     0   \n",
       "7                      0,02496035849707                   0,00597009651844192   \n",
       "8                    0,0438649635036496                   0,00143978102189781   \n",
       "9                     0,351338919925512                                     0   \n",
       "10                    0,199628019323671                   0,00434299516908213   \n",
       "11                    0,143825281270682                   0,00642488418266049   \n",
       "12                    0,221267834793492                     0,099482478097622   \n",
       "13                    0,696123675097072                     0,477022405289117   \n",
       "14                    0,227013550135501                     0,172670054200542   \n",
       "15                     0,49512156448203                     0,384871035940803   \n",
       "16                    0,608458773784355                     0,361408033826638   \n",
       "17                    0,268704876273654                     0,168943959243086   \n",
       "18                   0,0587429602888087                    0,0587429602888087   \n",
       "19                    0,176202051657813                     0,111044880014655   \n",
       "20                   0,0080324459234609                                     0   \n",
       "21                    0,347700301204819                     0,347700301204819   \n",
       "22                     0,16730487804878                     0,151617755048518   \n",
       "23                    0,374948780487805                      0,35570243902439   \n",
       "24                    0,144679358717435                                     0   \n",
       "25                    0,279845827439887                     0,256748231966054   \n",
       "26                 0,000729571984435798                                     0   \n",
       "27                    0,533630819366853                     0,530116387337058   \n",
       "28                    0,229287187039764                     0,226478645066274   \n",
       "29                    0,114713615023474                    0,0514841549295775   \n",
       "\n",
       "   overrun_freq_a_scadenza avg_rel_used_a_scadenza std_rel_used_a_scadenza  \\\n",
       "0        0,333333333333333        1,27369933184855       0,028642038445761   \n",
       "1                        0                       0                       0   \n",
       "2                        0       0,212708532695375       0,100377623990215   \n",
       "3                        0        0,14559735513025      0,0113414597444539   \n",
       "4                        0        0,38485640236956      0,0307032798267901   \n",
       "5                        0       0,409035293119539      0,0730965006549573   \n",
       "6                        0        2,40953703703704       0,241564672078251   \n",
       "7                      0,5       0,163601531081236      0,0316792029521103   \n",
       "8                        0      0,0604969586374696      0,0183848321359603   \n",
       "9                        0        2,14089292364991    4,63836052115501e-16   \n",
       "10                       0       0,072463768115942                       0   \n",
       "11                       0      0,0887348334436356      0,0193342937616968   \n",
       "12                       0       0,131861284939508     0,00617420704782303   \n",
       "13      0,0833333333333333       0,735301321404834      0,0462155669116603   \n",
       "14                       0       0,502086720867209      0,0827169281291274   \n",
       "15                       0         1,9360563777308       0,181163318878327   \n",
       "16                       0        1,95689622973925       0,164308117930946   \n",
       "17                    0,25       0,446912148229015      0,0268070705445783   \n",
       "18                       0       0,120986642599278     0,00767103565035951   \n",
       "19                     0,5       0,317335142272699      0,0455557481627097   \n",
       "20                       0       0,481517505546312      0,0267490915331625   \n",
       "21                       0       0,172019076305221      0,0196131546324518   \n",
       "22       0,416666666666667       0,379730822187254       0,006381729176409   \n",
       "23                       0        1,98546808943089      0,0420881814728821   \n",
       "24      0,0833333333333333       0,951946601536406       0,107436450056201   \n",
       "25      0,0833333333333333      0,0863115040075436     0,00295801997721993   \n",
       "26       0,416666666666667       0,242317282749676     0,00677395747478242   \n",
       "27                       0        0,55561351644941      0,0173859879616584   \n",
       "28      0,0833333333333333       0,370288659793814      0,0413559763129373   \n",
       "29      0,0833333333333333       0,477285602503912      0,0236722918443658   \n",
       "\n",
       "   max_rel_used_a_scadenza last_rel_used_a_scadenza avg_count_enti_affidanti  \\\n",
       "0         1,32464142538975         1,32464142538975         1,16666666666667   \n",
       "1                        0                        0                        1   \n",
       "2         0,33222009569378        0,320196172248804                        3   \n",
       "3        0,162240829346092        0,126861244019139                        3   \n",
       "4        0,478388926862611        0,356901572112098                        3   \n",
       "5        0,548144311529651        0,548144311529651         14,4166666666667   \n",
       "6         2,74656944444444         2,72804166666667         2,33333333333333   \n",
       "7        0,195947948983109        0,131166494312306         4,58333333333333   \n",
       "8       0,0813248175182482       0,0813248175182482         1,41666666666667   \n",
       "9         2,14089292364991         2,14089292364991                        0   \n",
       "10       0,072463768115942        0,072463768115942                        2   \n",
       "11       0,114889477167439       0,0469675711449371         5,83333333333333   \n",
       "12       0,134433667083855        0,122338548185232         4,91666666666667   \n",
       "13       0,796762094658411         0,72403247979851                     15,5   \n",
       "14       0,576208672086721        0,555310298102981                        3   \n",
       "15        2,27354334038055         2,02711522198731         8,16666666666667   \n",
       "16        2,27354334038055         2,12585517970402         8,16666666666667   \n",
       "17       0,500278748180495        0,500278748180495                        8   \n",
       "18       0,124258483754513        0,124258483754513                        1   \n",
       "19       0,379084264517311        0,272506777798131         5,91666666666667   \n",
       "20       0,522436772046589        0,522436772046589         7,66666666666667   \n",
       "21       0,219200301204819        0,219200301204819         3,41666666666667   \n",
       "22       0,389625753999475        0,371850642538683                       14   \n",
       "23        2,04689756097561         2,02848536585366         6,66666666666667   \n",
       "24        1,06908667334669          1,0667745490982         4,83333333333333   \n",
       "25      0,0907448373408769       0,0897807637906648                        6   \n",
       "26        0,25593579766537        0,233945525291829         1,08333333333333   \n",
       "27       0,585378491620112        0,555938547486033         10,0833333333333   \n",
       "28       0,437880706921944        0,310402798232695         5,33333333333333   \n",
       "29       0,506569248826291        0,502116197183099                     4,75   \n",
       "\n",
       "   std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0         0,389249472080761                         2   \n",
       "1                         0                         1   \n",
       "2                         0                         3   \n",
       "3                         0                         3   \n",
       "4                         0                         3   \n",
       "5          1,44337567297406                        17   \n",
       "6         0,492365963917331                         3   \n",
       "7         0,514928650544437                         5   \n",
       "8         0,514928650544437                         2   \n",
       "9                         0                         0   \n",
       "10                        0                         2   \n",
       "11        0,389249472080761                         6   \n",
       "12        0,288675134594813                         5   \n",
       "13        0,674199862463242                        16   \n",
       "14                        0                         3   \n",
       "15        0,834847109936722                         9   \n",
       "16        0,834847109936722                         9   \n",
       "17         1,04446593573419                        10   \n",
       "18                        0                         1   \n",
       "19        0,668557923421522                         7   \n",
       "20        0,492365963917331                         8   \n",
       "21         0,90033663737852                         5   \n",
       "22                        0                        14   \n",
       "23        0,778498944161523                         7   \n",
       "24        0,717740562565273                         6   \n",
       "25                        0                         6   \n",
       "26        0,288675134594813                         2   \n",
       "27        0,288675134594813                        11   \n",
       "28        0,492365963917331                         6   \n",
       "29        0,452267016866645                         5   \n",
       "\n",
       "    last_count_enti_affidanti avg_count_numero_prima_info  \\\n",
       "0                           2            1,08333333333333   \n",
       "1                           1                           1   \n",
       "2                           3            1,91666666666667   \n",
       "3                           3            1,91666666666667   \n",
       "4                           3            2,08333333333333   \n",
       "5                          16            3,91666666666667   \n",
       "6                           3                           0   \n",
       "7                           5                           4   \n",
       "8                           2                           0   \n",
       "9                           0                           0   \n",
       "10                          2                           1   \n",
       "11                          5                           0   \n",
       "12                          4                           0   \n",
       "13                         16                         0,5   \n",
       "14                          3                           0   \n",
       "15                          9                           1   \n",
       "16                          9                           1   \n",
       "17                         10                           1   \n",
       "18                          1                           2   \n",
       "19                          6           0,416666666666667   \n",
       "20                          8                           0   \n",
       "21                          5                           0   \n",
       "22                         14            2,16666666666667   \n",
       "23                          7                           0   \n",
       "24                          4                           0   \n",
       "25                          6                           1   \n",
       "26                          2                           2   \n",
       "27                         11                           0   \n",
       "28                          6           0,583333333333333   \n",
       "29                          4            1,08333333333333   \n",
       "\n",
       "   std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0            0,288675134594813                            2   \n",
       "1                            0                            1   \n",
       "2            0,288675134594813                            2   \n",
       "3            0,288675134594813                            2   \n",
       "4            0,288675134594813                            3   \n",
       "5             1,97522534195852                            6   \n",
       "6                            0                            0   \n",
       "7                            0                            4   \n",
       "8                            0                            0   \n",
       "9                            0                            0   \n",
       "10                           0                            1   \n",
       "11                           0                            0   \n",
       "12                           0                            0   \n",
       "13           0,522232967867094                            1   \n",
       "14                           0                            0   \n",
       "15                           0                            1   \n",
       "16                           0                            1   \n",
       "17            1,04446593573419                            2   \n",
       "18                           0                            2   \n",
       "19           0,514928650544437                            1   \n",
       "20                           0                            0   \n",
       "21                           0                            0   \n",
       "22           0,577350269189626                            4   \n",
       "23                           0                            0   \n",
       "24                           0                            0   \n",
       "25                           0                            1   \n",
       "26                           0                            2   \n",
       "27                           0                            0   \n",
       "28           0,514928650544437                            1   \n",
       "29           0,288675134594813                            2   \n",
       "\n",
       "    last_count_numero_prima_info  \n",
       "0                              1  \n",
       "1                              1  \n",
       "2                              2  \n",
       "3                              2  \n",
       "4                              3  \n",
       "5                              6  \n",
       "6                              0  \n",
       "7                              4  \n",
       "8                              0  \n",
       "9                              0  \n",
       "10                             1  \n",
       "11                             0  \n",
       "12                             0  \n",
       "13                             1  \n",
       "14                             0  \n",
       "15                             1  \n",
       "16                             1  \n",
       "17                             0  \n",
       "18                             2  \n",
       "19                             1  \n",
       "20                             0  \n",
       "21                             0  \n",
       "22                             4  \n",
       "23                             0  \n",
       "24                             0  \n",
       "25                             1  \n",
       "26                             2  \n",
       "27                             0  \n",
       "28                             1  \n",
       "29                             2  "
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "external_score_ver01  external_score_ver02  external_score_ver03  age   province  juridical_form  industry_sector  gross_margin_ratio  core_income_ratio  cash_asset_ratio  consolidated_liabilities_ratio  tangible_assets_ratio  revenues  cr_available  region  geo_area  last_statement_age  overrun_freq_a_revoca_autoliquidanti  avg_tension_a_revoca_autoliquidanti  std_tension_a_revoca_autoliquidanti  max_tension_a_revoca_autoliquidanti  last_tension_a_revoca_autoliquidanti  avg_rel_used_a_revoca_autoliquidanti  std_rel_used_a_revoca_autoliquidanti  max_rel_used_a_revoca_autoliquidanti  last_rel_used_a_revoca_autoliquidanti  overrun_freq_a_scadenza  avg_rel_used_a_scadenza  std_rel_used_a_scadenza  max_rel_used_a_scadenza  last_rel_used_a_scadenza  avg_count_enti_affidanti  std_count_enti_affidanti  max_count_enti_affidanti  last_count_enti_affidanti  avg_count_numero_prima_info  std_count_numero_prima_info  max_count_numero_prima_info  last_count_numero_prima_info  target\n",
       "7.0                   3.0                   10.0                  6.0   27.0      2.0             1.0               0.194286            0.104972          0.064935          0.217143                        1.000000               181.0     1.0           7.0     2.0       2.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.165746                 0.000000e+00             0.165746                 0.165746                  1.00                      0.000000                  1.0                       1.0                        1.250000                     0.452267                     2.0                          2.0                           0.0       4\n",
       "8.0                   2.0                   7.0                   6.0   27.0      1.0             2.0               0.058047            0.323232          0.000000          0.835532                        0.124719               198.0     0.0           7.0     2.0       2.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.000000                 0.000000e+00             0.000000                 0.000000                  0.00                      0.000000                  0.0                       0.0                        0.000000                     0.000000                     0.0                          0.0                           0.0       4\n",
       "10.0                  3.0                   8.0                   5.0   8.0       2.0             2.0               0.457291            0.068892          0.000000          0.369089                        1.000000               584.0     1.0           8.0     5.0       2.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.000000                 0.000000e+00             0.000000                 0.000000                  1.00                      0.000000                  1.0                       1.0                        0.083333                     0.288675                     1.0                          0.0                           0.0       4\n",
       "8.0                   3.0                   7.0                   3.0   2.0       2.0             3.0               0.037037            0.020690          0.117647          0.111111                        0.333333               145.0     0.0           2.0     1.0       2.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.000000                 0.000000e+00             0.000000                 0.000000                  0.00                      0.000000                  0.0                       0.0                        0.000000                     0.000000                     0.0                          0.0                           0.0       4\n",
       "                      2.0                   7.0                   4.0   11.0      1.0             2.0               0.491704            0.038974          0.057052          0.099548                        0.812500               1289.0    0.0           6.0     5.0       1.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.000000                 0.000000e+00             0.000000                 0.000000                  1.00                      0.000000                  1.0                       1.0                        5.000000                     0.000000                     5.0                          5.0                           0.0       4\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          ..\n",
       "6.0                   2.0                   4.0                   10.0  61.0      1.0             8.0              -0.111521           -0.505531          0.023855          0.522581                        0.418919               922.0     1.0           13.0    3.0       2.0                 0.166667                              0.677812                             0.113338                             0.868220                             0.762085                              0.368370                              0.050514                              0.439166                              0.385528                               0.0                      0.794226                 3.451094e-02             0.837130                 0.739547                  4.00                      0.000000                  4.0                       4.0                        0.000000                     0.000000                     0.0                          0.0                           0.0       1\n",
       "                                                                  9.0   81.0      1.0             2.0               0.439661            0.048283          0.101555          0.241355                        0.867284               1876.0    1.0           11.0    4.0       2.0                 0.000000                              0.000000                             0.000000                             0.000000                             0.000000                              0.000000                              0.000000                              0.000000                              0.000000                               0.0                      0.169912                 5.013281e-02             0.228026                 0.224788                  2.75                      0.452267                  3.0                       3.0                        1.166667                     0.389249                     2.0                          2.0                           0.0       1\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                              0.147019                 5.350992e-02             0.228026                 0.226413                  2.75                      0.452267                  3.0                       3.0                        1.166667                     0.389249                     2.0                          2.0                           0.0       1\n",
       "                                                                        56.0      1.0             7.0              -0.007273            0.045455          0.368421          0.327273                        0.049296               132.0     1.0           16.0    3.0       2.0                 0.000000                              0.000642                             0.000995                             0.002767                             0.000000                              0.000146                              0.000226                              0.000629                              0.000000                               0.0                      0.189394                 2.898975e-17             0.189394                 0.189394                  1.00                      0.000000                  1.0                       1.0                        0.416667                     0.514929                     1.0                          1.0                           0.0       1\n",
       "10.0                  3.0                   14.0                  53.0  16.0      3.0             8.0               0.299238           -0.042769          0.000000          0.401438                        1.000000               1038.5    1.0           11.0    4.0       2.0                 0.666667                              0.753458                             0.097356                             0.853064                             0.826196                              0.635653                              0.081032                              0.723792                              0.663188                               0.0                      0.642869                 8.948603e-02             0.777409                 0.777409                  0.00                      0.000000                  0.0                       0.0                        0.000000                     0.000000                     0.0                          0.0                           0.0       1\n",
       "Name: count, Length: 31315, dtype: int64"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Compute The Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'collections.OrderedDict' object has no attribute 'eval'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[293], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m model_index \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_models):\n\u001b[1;32m      3\u001b[0m         model \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_index\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.pth\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 4\u001b[0m         \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meval\u001b[49m()\n\u001b[1;32m      5\u001b[0m         \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m                 X_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'collections.OrderedDict' object has no attribute 'eval'"
     ]
    }
   ],
   "source": [
    "results = np.array([])\n",
    "for model_index in range(num_models):\n",
    "        model = torch.load(f'model_{model_index}.pth')\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "                X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "                outputs = model(X_test_tensor)\n",
    "                predicted = (outputs >= 0.5).float()\n",
    "                results = np.append(results, predicted)\n",
    "results_mean = results.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export The CSV File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_np = results_mean.numpy().flatten()\n",
    "# Export the array to a CSV file with column name 'label' and each number on a different row\n",
    "np.savetxt('prediction.csv', predicted_np, fmt='%d', delimiter=',', header='label', comments='')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CAI",
   "language": "python",
   "name": "cai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
