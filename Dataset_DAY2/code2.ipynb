{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"../Dataset_DAY1/Data/train_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ej2yjUAA</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>7256587870</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q2X00000ZWC5LUAX</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>6178307100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q2X00000XcCCQUA3</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>7692855390</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ejSs3UAE</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>5752241730</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000eiRidUAE</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>7533506540</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01   \n",
       "0  a1Q7R00000ej2yjUAA    2021-11-30  7256587870                    10  \\\n",
       "1  a1Q2X00000ZWC5LUAX    2020-10-06  6178307100                     7   \n",
       "2  a1Q2X00000XcCCQUA3    2020-02-11  7692855390                     7   \n",
       "3  a1Q7R00000ejSs3UAE    2022-01-18  5752241730                     8   \n",
       "4  a1Q7R00000eiRidUAE    2021-09-16  7533506540                     4   \n",
       "\n",
       "   external_score_ver02  late_payment_score   \n",
       "0                     3                 NaN  \\\n",
       "1                     3                 NaN   \n",
       "2                     3                 NaN   \n",
       "3                     2                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate   \n",
       "0                                     NaN                      NaN  \\\n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  ...  avg_count_enti_affidanti   \n",
       "0                     NaN              MISSING  ...                         1  \\\n",
       "1                     NaN                    H  ...                         1   \n",
       "2                     NaN              MISSING  ...                         1   \n",
       "3                     NaN              MISSING  ...                         1   \n",
       "4                     NaN              MISSING  ...                         0   \n",
       "\n",
       "  std_count_enti_affidanti max_count_enti_affidanti last_count_enti_affidanti   \n",
       "0                        0                        1                         1  \\\n",
       "1                        0                        1                         1   \n",
       "2                        0                        1                         1   \n",
       "3                        0                        1                         1   \n",
       "4                        0                        0                         0   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info   \n",
       "0                           0                           0  \\\n",
       "1                           2                           0   \n",
       "2                           1                           0   \n",
       "3                         0,5           0,522232967867094   \n",
       "4                           0                           0   \n",
       "\n",
       "  max_count_numero_prima_info last_count_numero_prima_info days_to_default   \n",
       "0                           0                            0             522  \\\n",
       "1                           2                            2            1498   \n",
       "2                           1                            1             779   \n",
       "3                           1                            0            1498   \n",
       "4                           0                            0            1498   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features\n",
    "def Drop_unneed_columns(dataset):\n",
    "    cols= ['application_ID', 'company_ID', 'decision_date']\n",
    "    dataset= dataset.drop(columns=cols)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_values(dataset):\n",
    "    column_names = dataset.columns.tolist()\n",
    "    drop_columns = []\n",
    "    for name in column_names:\n",
    "        nan_count = dataset[name].isna().sum()\n",
    "        print(f\"column {name}: {nan_count}\")\n",
    "        if (nan_count/28000) > 0.5:\n",
    "            print(f\"Number of NaN values in column '{name}': {nan_count}\")\n",
    "            drop_columns.append(name)\n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_cate_to_value(column_name, dataset):\n",
    "    # Extract categories\n",
    "\n",
    "    # Extract unique category names from the column\n",
    "    unique_categories = dataset[column_name].unique()\n",
    "\n",
    "    # convert 'numpy.ndarray' in to a python list\n",
    "    l = unique_categories.tolist()\n",
    "    \n",
    "    if 'MISSING' in l:\n",
    "        l.remove('MISSING')\n",
    "        l.sort(reverse=True)\n",
    "\n",
    "    print(l)\n",
    "    \n",
    "    dic = { l[i]:i+1 for i in range(0, len(l))}\n",
    "\n",
    "    # Replace values in the column based on the dictionary mapping\n",
    "    dataset[column_name] = dataset[column_name].replace(dic)\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Category_values(dataset):\n",
    "    column_names = ['industry_sector','region', 'geo_area','external_score_ver03', 'province','juridical_form']\n",
    "    dic = {}\n",
    "    for column_name in column_names:\n",
    "        category_dic, dataset = Replace_cate_to_value(column_name, dataset)\n",
    "        dic[column_name] = category_dic\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_bool_toNumbers(dataset):\n",
    "    dataset['cr_available'] = [int(dataset['cr_available'][i]) for i in range(len(dataset['cr_available']))]\n",
    "    dataset['cr_available']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var03(dataset):\n",
    "    s0, s1, c0, c1 = 0,0,0,0\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row['external_score_ver03'] != 'MISSING':\n",
    "            if row['target'] == 0:\n",
    "                s0 += row['external_score_ver03']\n",
    "                c0 +=1\n",
    "            elif row['target'] == 1:\n",
    "                s1 +=  row['external_score_ver03']\n",
    "                c1 += 1\n",
    "\n",
    "    m0 = round(s0/c0)\n",
    "    m1 = round(s1/c1)\n",
    "    print(m0)\n",
    "    print(m1)\n",
    "    return m0,m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing(dataset, m0, m1):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset['target'] == 1) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m1\n",
    "    dataset.loc[(dataset['target'] == 0) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m0\n",
    "    dataset['external_score_ver03']\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column external_score_ver01: 0\n",
      "column external_score_ver02: 0\n",
      "column late_payment_score: 27488\n",
      "Number of NaN values in column 'late_payment_score': 27488\n",
      "column external_score_late_payment_integrated: 27488\n",
      "Number of NaN values in column 'external_score_late_payment_integrated': 27488\n",
      "column external_score_moderate: 27208\n",
      "Number of NaN values in column 'external_score_moderate': 27208\n",
      "column external_score_adverse: 27208\n",
      "Number of NaN values in column 'external_score_adverse': 27208\n",
      "column external_score_ver03: 0\n",
      "column age: 0\n",
      "column province: 2654\n",
      "column juridical_form: 0\n",
      "column industry_sector: 0\n",
      "column gross_margin_ratio: 0\n",
      "column core_income_ratio: 0\n",
      "column cash_asset_ratio: 0\n",
      "column consolidated_liabilities_ratio: 0\n",
      "column tangible_assets_ratio: 0\n",
      "column revenues: 0\n",
      "column cr_available: 0\n",
      "column region: 0\n",
      "column geo_area: 0\n",
      "column last_statement_age: 0\n",
      "column overrun_freq_a_revoca_autoliquidanti: 0\n",
      "column avg_tension_a_revoca_autoliquidanti: 0\n",
      "column std_tension_a_revoca_autoliquidanti: 0\n",
      "column max_tension_a_revoca_autoliquidanti: 0\n",
      "column last_tension_a_revoca_autoliquidanti: 0\n",
      "column avg_rel_used_a_revoca_autoliquidanti: 0\n",
      "column std_rel_used_a_revoca_autoliquidanti: 0\n",
      "column max_rel_used_a_revoca_autoliquidanti: 0\n",
      "column last_rel_used_a_revoca_autoliquidanti: 0\n",
      "column overrun_freq_a_scadenza: 0\n",
      "column avg_rel_used_a_scadenza: 0\n",
      "column std_rel_used_a_scadenza: 0\n",
      "column max_rel_used_a_scadenza: 0\n",
      "column last_rel_used_a_scadenza: 0\n",
      "column avg_count_enti_affidanti: 0\n",
      "column std_count_enti_affidanti: 0\n",
      "column max_count_enti_affidanti: 0\n",
      "column last_count_enti_affidanti: 0\n",
      "column avg_count_numero_prima_info: 0\n",
      "column std_count_numero_prima_info: 0\n",
      "column max_count_numero_prima_info: 0\n",
      "column last_count_numero_prima_info: 0\n",
      "column days_to_default: 0\n",
      "column target: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop columns \n",
    "train_dataset = Drop_unneed_columns(train_dataset)\n",
    "drop_columns = Nan_values(train_dataset)\n",
    "train_dataset = train_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Servizi', 'Costruzioni e materiali per costruzioni', 'Distribuzione', 'Trasporti', 'Utility', 'Editoria e stampa', 'Elettrotecnica ed elettronica', 'Altri beni di consumo', 'Sistema moda', 'Metallurgia e prodotti in metallo', 'Meccanica', 'Chimica di base e intermedi', 'Elettrodomestici', 'Agricoltura', 'Alimentare', 'Energia ed estrazione', 'Largo consumo / attività ricreativo-culturali', 'Mezzi di trasporto', 'Holding, finanziarie ed altro', 'Farmaceutica']\n",
      "['Sicilia', 'Sardegna', 'Puglia', 'Lazio', 'Veneto', 'Lombardia', 'Campania', 'Piemonte', 'Abruzzo', 'Basilicata', 'Emilia-Romagna', 'Umbria', 'Toscana', \"Valle d'Aosta/Vallée d'Aoste\", 'Calabria', 'Marche', 'Liguria', 'Molise', 'Friuli-Venezia Giulia', 'Trentino-Alto Adige/Südtirol']\n",
      "['Isole', 'Sud', 'Centro', 'Nord-est', 'Nord-ovest']\n",
      "['P', 'O', 'N', 'M', 'L', 'I', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A']\n",
      "['TP', 'CA', 'LE', 'RM', 'PD', 'MI', 'SA', 'TO', 'CH', 'PZ', 'LC', 'OR', 'LT', 'MO', 'PG', 'BO', 'TV', 'VE', 'BA', 'PI', 'PA', 'AV', 'CT', 'BG', 'SR', 'MB', nan, 'TA', 'NU', 'FR', 'RA', 'FC', 'CE', 'VI', 'AO', 'LO', 'VA', 'SU', 'BS', 'ME', 'CS', 'VR', 'PV', 'PC', 'BR', 'BN', 'RC', 'CZ', 'FM', 'CR', 'SS', 'MC', 'AG', 'MN', 'RG', 'AP', 'LU', 'CO', 'MS', 'VB', 'AR', 'VV', 'NO', 'SP', 'PU', 'TE', 'PO', 'IM', 'CB', 'RN', 'PN', 'KR', 'RO', 'AN', 'AQ', 'SI', 'TN', 'CN', 'FI', 'UD', 'PR', 'GE', 'VT', 'SV', 'BI', 'RE', 'GR', 'BZ', 'CL', 'AL', 'PT', 'BT', 'VC', 'PE', 'SO', 'FG', 'TS', 'BL', 'MT', 'TR', 'IS', 'GO', 'FE', 'LI', 'EN', 'AT', 'RI']\n",
      "['SR', 'RS', 'SU', 'SC', 'SP', 'CO', 'CL', 'AU', 'OO', 'SL', 'OC', 'CC', 'SO', 'PS']\n"
     ]
    }
   ],
   "source": [
    "# replace bool values to numerical ones \n",
    "category_dics, train_dataset = Category_values(train_dataset)\n",
    "train_dataset = Replace_bool_toNumbers(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# v03 column with missing values \n",
    "m0, m1= mean_var03(train_dataset)\n",
    "train_dataset = Replace_missing(train_dataset, m0, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                  int64\n",
      "juridical_form                            int64\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                    int64\n",
      "geo_area                                  int64\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "days_to_default                           int64\n",
      "target                                    int64\n",
      "dtype: object\n",
      "DataFrame does not contain any NaN values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.136150</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   external_score_ver01  external_score_ver02  external_score_ver03   age   \n",
       "0                  10.0                   3.0                  10.0  15.0  \\\n",
       "1                   7.0                   3.0                   7.0   5.0   \n",
       "2                   7.0                   3.0                  10.0   5.0   \n",
       "3                   8.0                   2.0                   8.0   6.0   \n",
       "4                   4.0                   1.0                   8.0   5.0   \n",
       "\n",
       "   province  juridical_form  industry_sector  gross_margin_ratio   \n",
       "0       1.0             1.0              1.0            0.464637  \\\n",
       "1       2.0             2.0              2.0            0.372340   \n",
       "2       3.0             1.0              3.0            0.270000   \n",
       "3       4.0             1.0              1.0            0.419929   \n",
       "4       5.0             1.0              1.0            0.526316   \n",
       "\n",
       "   core_income_ratio  cash_asset_ratio  ...  avg_count_enti_affidanti   \n",
       "0           0.012593          0.000000  ...                       1.0  \\\n",
       "1           0.115385          0.235955  ...                       1.0   \n",
       "2           0.006369          0.359375  ...                       1.0   \n",
       "3           0.152174          0.136150  ...                       1.0   \n",
       "4           0.083333          0.233333  ...                       0.0   \n",
       "\n",
       "   std_count_enti_affidanti  max_count_enti_affidanti   \n",
       "0                       0.0                       1.0  \\\n",
       "1                       0.0                       1.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       0.0                       1.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   last_count_enti_affidanti  avg_count_numero_prima_info   \n",
       "0                        1.0                          0.0  \\\n",
       "1                        1.0                          2.0   \n",
       "2                        1.0                          1.0   \n",
       "3                        1.0                          0.5   \n",
       "4                        0.0                          0.0   \n",
       "\n",
       "   std_count_numero_prima_info  max_count_numero_prima_info   \n",
       "0                     0.000000                          0.0  \\\n",
       "1                     0.000000                          2.0   \n",
       "2                     0.000000                          1.0   \n",
       "3                     0.522233                          1.0   \n",
       "4                     0.000000                          0.0   \n",
       "\n",
       "   last_count_numero_prima_info  days_to_default  target  \n",
       "0                           0.0            522.0     1.0  \n",
       "1                           2.0           1498.0     0.0  \n",
       "2                           1.0            779.0     1.0  \n",
       "3                           0.0           1498.0     0.0  \n",
       "4                           0.0           1498.0     0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = normalized_data(train_dataset)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_dataset['days_to_default'].to_numpy() # labels\n",
    "X = train_dataset.drop(columns=['days_to_default']).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> SVM Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming Y contains the target variable for regression\n",
    "\n",
    "# Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_dataset.drop(columns='days_to_default'))\n",
    "\n",
    "\n",
    "# Standardize the target variable Y\n",
    "Y = train_dataset['days_to_default']\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y.values.reshape(-1, 1))  # Reshape Y to be a 2D array for StandardScaler\n",
    "\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=20)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.1, random_state=2)\n",
    "\n",
    "# Create SVR (Support Vector Regression) model\n",
    "regressor = SVR(C=0.1, kernel='linear', gamma='scale')\n",
    "\n",
    "# Fit the model on the training data\n",
    "regressor.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) as a metric\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 92.62571610518452\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "y = train_dataset['days_to_default'].to_numpy() # labels\n",
    "X = train_dataset.drop(columns=['days_to_default']).to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Train the model\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse = mean_squared_error(y_test, y_pred_rf, squared=False)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"../Dataset_DAY1/Data/test_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Drop_unneed_columns(test_dataset)\n",
    "test_dataset = test_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dics[\"juridical_form\"][\"SS\"] = 15\n",
    "category_dics[\"juridical_form\"][\"OS\"] = 16\n",
    "for k,v in category_dics.items():\n",
    "    test_dataset.replace({k:v}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find columns with MISSING values \n",
    "columns = []\n",
    "for column in list(test_dataset.columns):\n",
    "    # Check if there is a value \"MISSING\" in the 'column_name' column\n",
    "    missing_values = test_dataset[column] == 'MISSING'\n",
    "\n",
    "    # Check if any row contains the value \"MISSING\" in the specified column\n",
    "    if missing_values.any():\n",
    "        print(f\"'MISSING' in the column: {column}\")\n",
    "        columns.append(column)\n",
    "\n",
    "# Sum values in the specified columns\n",
    "dic = {}\n",
    "for column in columns:\n",
    "    column_name = column\n",
    "\n",
    "    count = 0\n",
    "    sum_values = 0\n",
    "    # Iterate over the DataFrame\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        # Access the value of the specified column for each row\n",
    "        count +=1\n",
    "        if isinstance(row[column_name], str):\n",
    "            continue\n",
    "        elif isinstance(row[column_name], int):\n",
    "            sum_values += row[column_name]\n",
    "    \n",
    "    dic[column] = int(sum_values/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing_test(dataset,val, column):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset[column] == 'MISSING'), column] = val\n",
    "\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dic.items():\n",
    "    test_dataset = Replace_missing_test(test_dataset,v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Replace_bool_toNumbers(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## normalise test dataset \n",
    "def normalized_tdata(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "test_dataset = normalized_tdata(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset.head()\n",
    "print(test_dataset.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
