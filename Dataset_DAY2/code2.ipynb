{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process Train Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = pd.read_csv(\"../Dataset_DAY1/Data/train_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ej2yjUAA</td>\n",
       "      <td>2021-11-30</td>\n",
       "      <td>7256587870</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>522</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q2X00000ZWC5LUAX</td>\n",
       "      <td>2020-10-06</td>\n",
       "      <td>6178307100</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>H</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q2X00000XcCCQUA3</td>\n",
       "      <td>2020-02-11</td>\n",
       "      <td>7692855390</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>779</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ejSs3UAE</td>\n",
       "      <td>2022-01-18</td>\n",
       "      <td>5752241730</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0,5</td>\n",
       "      <td>0,522232967867094</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000eiRidUAE</td>\n",
       "      <td>2021-09-16</td>\n",
       "      <td>7533506540</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MISSING</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1498</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 48 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ej2yjUAA    2021-11-30  7256587870                    10   \n",
       "1  a1Q2X00000ZWC5LUAX    2020-10-06  6178307100                     7   \n",
       "2  a1Q2X00000XcCCQUA3    2020-02-11  7692855390                     7   \n",
       "3  a1Q7R00000ejSs3UAE    2022-01-18  5752241730                     8   \n",
       "4  a1Q7R00000eiRidUAE    2021-09-16  7533506540                     4   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     3                 NaN   \n",
       "1                     3                 NaN   \n",
       "2                     3                 NaN   \n",
       "3                     2                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     NaN                      NaN   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  ...  avg_count_enti_affidanti  \\\n",
       "0                     NaN              MISSING  ...                         1   \n",
       "1                     NaN                    H  ...                         1   \n",
       "2                     NaN              MISSING  ...                         1   \n",
       "3                     NaN              MISSING  ...                         1   \n",
       "4                     NaN              MISSING  ...                         0   \n",
       "\n",
       "  std_count_enti_affidanti max_count_enti_affidanti last_count_enti_affidanti  \\\n",
       "0                        0                        1                         1   \n",
       "1                        0                        1                         1   \n",
       "2                        0                        1                         1   \n",
       "3                        0                        1                         1   \n",
       "4                        0                        0                         0   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0                           0                           0   \n",
       "1                           2                           0   \n",
       "2                           1                           0   \n",
       "3                         0,5           0,522232967867094   \n",
       "4                           0                           0   \n",
       "\n",
       "  max_count_numero_prima_info last_count_numero_prima_info days_to_default  \\\n",
       "0                           0                            0             522   \n",
       "1                           2                            2            1498   \n",
       "2                           1                            1             779   \n",
       "3                           1                            0            1498   \n",
       "4                           0                            0            1498   \n",
       "\n",
       "  target  \n",
       "0      1  \n",
       "1      0  \n",
       "2      1  \n",
       "3      0  \n",
       "4      0  \n",
       "\n",
       "[5 rows x 48 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop features\n",
    "def Drop_unneed_columns(dataset):\n",
    "    cols= ['application_ID', 'company_ID', 'decision_date']\n",
    "    dataset= dataset.drop(columns=cols)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Nan_values(dataset):\n",
    "    column_names = dataset.columns.tolist()\n",
    "    drop_columns = []\n",
    "    for name in column_names:\n",
    "        nan_count = dataset[name].isna().sum()\n",
    "        print(f\"column {name}: {nan_count}\")\n",
    "        if (nan_count/28000) > 0.5:\n",
    "            print(f\"Number of NaN values in column '{name}': {nan_count}\")\n",
    "            drop_columns.append(name)\n",
    "    return drop_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_cate_to_value(column_name, dataset):\n",
    "    # Extract categories\n",
    "\n",
    "    # Extract unique category names from the column\n",
    "    unique_categories = dataset[column_name].unique()\n",
    "\n",
    "    # convert 'numpy.ndarray' in to a python list\n",
    "    l = unique_categories.tolist()\n",
    "    \n",
    "    if 'MISSING' in l:\n",
    "        l.remove('MISSING')\n",
    "        l.sort(reverse=True)\n",
    "\n",
    "    print(l)\n",
    "    \n",
    "    dic = { l[i]:i+1 for i in range(0, len(l))}\n",
    "\n",
    "    # Replace values in the column based on the dictionary mapping\n",
    "    dataset[column_name] = dataset[column_name].replace(dic)\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Category_values(dataset):\n",
    "    column_names = ['industry_sector','region', 'geo_area','external_score_ver03', 'province','juridical_form']\n",
    "    dic = {}\n",
    "    for column_name in column_names:\n",
    "        category_dic, dataset = Replace_cate_to_value(column_name, dataset)\n",
    "        dic[column_name] = category_dic\n",
    "    return dic, dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_bool_toNumbers(dataset):\n",
    "    dataset['cr_available'] = [int(dataset['cr_available'][i]) for i in range(len(dataset['cr_available']))]\n",
    "    dataset['cr_available']\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_var03(dataset):\n",
    "    s0, s1, c0, c1 = 0,0,0,0\n",
    "    # unique_labels = dataset['target'].unique()\n",
    "    for index, row in dataset.iterrows():\n",
    "        if row['external_score_ver03'] != 'MISSING':\n",
    "            if row['target'] == 0:\n",
    "                s0 += row['external_score_ver03']\n",
    "                c0 +=1\n",
    "            elif row['target'] == 1:\n",
    "                s1 +=  row['external_score_ver03']\n",
    "                c1 += 1\n",
    "\n",
    "    m0 = round(s0/c0)\n",
    "    m1 = round(s1/c1)\n",
    "    print(m0)\n",
    "    print(m1)\n",
    "    return m0,m1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing(dataset, m0, m1):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset['target'] == 1) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m1\n",
    "    dataset.loc[(dataset['target'] == 0) & (dataset['external_score_ver03'] == 'MISSING'), 'external_score_ver03'] = m0\n",
    "    dataset['external_score_ver03']\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "column external_score_ver01: 0\n",
      "column external_score_ver02: 0\n",
      "column late_payment_score: 27488\n",
      "Number of NaN values in column 'late_payment_score': 27488\n",
      "column external_score_late_payment_integrated: 27488\n",
      "Number of NaN values in column 'external_score_late_payment_integrated': 27488\n",
      "column external_score_moderate: 27208\n",
      "Number of NaN values in column 'external_score_moderate': 27208\n",
      "column external_score_adverse: 27208\n",
      "Number of NaN values in column 'external_score_adverse': 27208\n",
      "column external_score_ver03: 0\n",
      "column age: 0\n",
      "column province: 2654\n",
      "column juridical_form: 0\n",
      "column industry_sector: 0\n",
      "column gross_margin_ratio: 0\n",
      "column core_income_ratio: 0\n",
      "column cash_asset_ratio: 0\n",
      "column consolidated_liabilities_ratio: 0\n",
      "column tangible_assets_ratio: 0\n",
      "column revenues: 0\n",
      "column cr_available: 0\n",
      "column region: 0\n",
      "column geo_area: 0\n",
      "column last_statement_age: 0\n",
      "column overrun_freq_a_revoca_autoliquidanti: 0\n",
      "column avg_tension_a_revoca_autoliquidanti: 0\n",
      "column std_tension_a_revoca_autoliquidanti: 0\n",
      "column max_tension_a_revoca_autoliquidanti: 0\n",
      "column last_tension_a_revoca_autoliquidanti: 0\n",
      "column avg_rel_used_a_revoca_autoliquidanti: 0\n",
      "column std_rel_used_a_revoca_autoliquidanti: 0\n",
      "column max_rel_used_a_revoca_autoliquidanti: 0\n",
      "column last_rel_used_a_revoca_autoliquidanti: 0\n",
      "column overrun_freq_a_scadenza: 0\n",
      "column avg_rel_used_a_scadenza: 0\n",
      "column std_rel_used_a_scadenza: 0\n",
      "column max_rel_used_a_scadenza: 0\n",
      "column last_rel_used_a_scadenza: 0\n",
      "column avg_count_enti_affidanti: 0\n",
      "column std_count_enti_affidanti: 0\n",
      "column max_count_enti_affidanti: 0\n",
      "column last_count_enti_affidanti: 0\n",
      "column avg_count_numero_prima_info: 0\n",
      "column std_count_numero_prima_info: 0\n",
      "column max_count_numero_prima_info: 0\n",
      "column last_count_numero_prima_info: 0\n",
      "column days_to_default: 0\n",
      "column target: 0\n"
     ]
    }
   ],
   "source": [
    "# Drop columns \n",
    "train_dataset = Drop_unneed_columns(train_dataset)\n",
    "drop_columns = Nan_values(train_dataset)\n",
    "train_dataset = train_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Servizi', 'Costruzioni e materiali per costruzioni', 'Distribuzione', 'Trasporti', 'Utility', 'Editoria e stampa', 'Elettrotecnica ed elettronica', 'Altri beni di consumo', 'Sistema moda', 'Metallurgia e prodotti in metallo', 'Meccanica', 'Chimica di base e intermedi', 'Elettrodomestici', 'Agricoltura', 'Alimentare', 'Energia ed estrazione', 'Largo consumo / attività ricreativo-culturali', 'Mezzi di trasporto', 'Holding, finanziarie ed altro', 'Farmaceutica']\n",
      "['Sicilia', 'Sardegna', 'Puglia', 'Lazio', 'Veneto', 'Lombardia', 'Campania', 'Piemonte', 'Abruzzo', 'Basilicata', 'Emilia-Romagna', 'Umbria', 'Toscana', \"Valle d'Aosta/Vallée d'Aoste\", 'Calabria', 'Marche', 'Liguria', 'Molise', 'Friuli-Venezia Giulia', 'Trentino-Alto Adige/Südtirol']\n",
      "['Isole', 'Sud', 'Centro', 'Nord-est', 'Nord-ovest']\n",
      "['P', 'O', 'N', 'M', 'L', 'I', 'H', 'G', 'F', 'E', 'D', 'C', 'B', 'A']\n",
      "['TP', 'CA', 'LE', 'RM', 'PD', 'MI', 'SA', 'TO', 'CH', 'PZ', 'LC', 'OR', 'LT', 'MO', 'PG', 'BO', 'TV', 'VE', 'BA', 'PI', 'PA', 'AV', 'CT', 'BG', 'SR', 'MB', nan, 'TA', 'NU', 'FR', 'RA', 'FC', 'CE', 'VI', 'AO', 'LO', 'VA', 'SU', 'BS', 'ME', 'CS', 'VR', 'PV', 'PC', 'BR', 'BN', 'RC', 'CZ', 'FM', 'CR', 'SS', 'MC', 'AG', 'MN', 'RG', 'AP', 'LU', 'CO', 'MS', 'VB', 'AR', 'VV', 'NO', 'SP', 'PU', 'TE', 'PO', 'IM', 'CB', 'RN', 'PN', 'KR', 'RO', 'AN', 'AQ', 'SI', 'TN', 'CN', 'FI', 'UD', 'PR', 'GE', 'VT', 'SV', 'BI', 'RE', 'GR', 'BZ', 'CL', 'AL', 'PT', 'BT', 'VC', 'PE', 'SO', 'FG', 'TS', 'BL', 'MT', 'TR', 'IS', 'GO', 'FE', 'LI', 'EN', 'AT', 'RI']\n",
      "['SR', 'RS', 'SU', 'SC', 'SP', 'CO', 'CL', 'AU', 'OO', 'SL', 'OC', 'CC', 'SO', 'PS']\n"
     ]
    }
   ],
   "source": [
    "# replace bool values to numerical ones \n",
    "category_dics, train_dataset = Category_values(train_dataset)\n",
    "train_dataset = Replace_bool_toNumbers(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "m0, m1= mean_var03(train_dataset)\n",
    "train_dataset = Replace_missing(train_dataset, m0, m1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_data(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                  int64\n",
      "juridical_form                            int64\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                    int64\n",
      "geo_area                                  int64\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "days_to_default                           int64\n",
      "target                                    int64\n",
      "dtype: object\n",
      "DataFrame does not contain any NaN values.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>age</th>\n",
       "      <th>province</th>\n",
       "      <th>juridical_form</th>\n",
       "      <th>industry_sector</th>\n",
       "      <th>gross_margin_ratio</th>\n",
       "      <th>core_income_ratio</th>\n",
       "      <th>cash_asset_ratio</th>\n",
       "      <th>...</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "      <th>days_to_default</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.464637</td>\n",
       "      <td>0.012593</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>522.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.372340</td>\n",
       "      <td>0.115385</td>\n",
       "      <td>0.235955</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.270000</td>\n",
       "      <td>0.006369</td>\n",
       "      <td>0.359375</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>779.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.419929</td>\n",
       "      <td>0.152174</td>\n",
       "      <td>0.136150</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.522233</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.526316</td>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.233333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1498.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   external_score_ver01  external_score_ver02  external_score_ver03   age  \\\n",
       "0                  10.0                   3.0                  10.0  15.0   \n",
       "1                   7.0                   3.0                   7.0   5.0   \n",
       "2                   7.0                   3.0                  10.0   5.0   \n",
       "3                   8.0                   2.0                   8.0   6.0   \n",
       "4                   4.0                   1.0                   8.0   5.0   \n",
       "\n",
       "   province  juridical_form  industry_sector  gross_margin_ratio  \\\n",
       "0       1.0             1.0              1.0            0.464637   \n",
       "1       2.0             2.0              2.0            0.372340   \n",
       "2       3.0             1.0              3.0            0.270000   \n",
       "3       4.0             1.0              1.0            0.419929   \n",
       "4       5.0             1.0              1.0            0.526316   \n",
       "\n",
       "   core_income_ratio  cash_asset_ratio  ...  avg_count_enti_affidanti  \\\n",
       "0           0.012593          0.000000  ...                       1.0   \n",
       "1           0.115385          0.235955  ...                       1.0   \n",
       "2           0.006369          0.359375  ...                       1.0   \n",
       "3           0.152174          0.136150  ...                       1.0   \n",
       "4           0.083333          0.233333  ...                       0.0   \n",
       "\n",
       "   std_count_enti_affidanti  max_count_enti_affidanti  \\\n",
       "0                       0.0                       1.0   \n",
       "1                       0.0                       1.0   \n",
       "2                       0.0                       1.0   \n",
       "3                       0.0                       1.0   \n",
       "4                       0.0                       0.0   \n",
       "\n",
       "   last_count_enti_affidanti  avg_count_numero_prima_info  \\\n",
       "0                        1.0                          0.0   \n",
       "1                        1.0                          2.0   \n",
       "2                        1.0                          1.0   \n",
       "3                        1.0                          0.5   \n",
       "4                        0.0                          0.0   \n",
       "\n",
       "   std_count_numero_prima_info  max_count_numero_prima_info  \\\n",
       "0                     0.000000                          0.0   \n",
       "1                     0.000000                          2.0   \n",
       "2                     0.000000                          1.0   \n",
       "3                     0.522233                          1.0   \n",
       "4                     0.000000                          0.0   \n",
       "\n",
       "   last_count_numero_prima_info  days_to_default  target  \n",
       "0                           0.0            522.0     1.0  \n",
       "1                           2.0           1498.0     0.0  \n",
       "2                           1.0            779.0     1.0  \n",
       "3                           0.0           1498.0     0.0  \n",
       "4                           0.0           1498.0     0.0  \n",
       "\n",
       "[5 rows x 41 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = normalized_data(train_dataset)\n",
    "train_dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> SVM Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 13191.330677910846\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming Y contains the target variable for regression\n",
    "\n",
    "# Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_dataset.drop(columns='days_to_default'))\n",
    "\n",
    "\n",
    "# Standardize the target variable Y\n",
    "Y = train_dataset['days_to_default']\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y.values.reshape(-1, 1))  # Reshape Y to be a 2D array for StandardScaler\n",
    "\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=30)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_pca, Y, test_size=0.1, random_state=2)\n",
    "\n",
    "# Create SVR (Support Vector Regression) model\n",
    "regressor = SVR(C=0.1, kernel='linear', gamma='scale')\n",
    "\n",
    "# Fit the model on the training data\n",
    "regressor.fit(X_train, Y_train)\n",
    "\n",
    "# Predict on the testing data\n",
    "Y_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) as a metric\n",
    "mse = mean_squared_error(Y_test, Y_pred)\n",
    "print(\"Mean Squared Error:\", mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error: 112155.19969535676\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "X = train_dataset.drop(columns=['days_to_default', 'target'])\n",
    "y = train_dataset['days_to_default'] # labels\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_regressor.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error:\", mse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n",
      "/Users/andreasalinetti/anaconda3/lib/python3.10/site-packages/sklearn/ensemble/_forest.py:413: FutureWarning: `max_features='auto'` has been deprecated in 1.1 and will be removed in 1.3. To keep the past behaviour, explicitly set `max_features=1.0` or remove this parameter as it is also the default value for RandomForestRegressors and ExtraTreesRegressors.\n",
      "  warn(\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 26\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# Perform GridSearchCV for hyperparameter tuning\u001b[39;00m\n\u001b[1;32m     25\u001b[0m grid_search \u001b[38;5;241m=\u001b[39m GridSearchCV(estimator\u001b[38;5;241m=\u001b[39mrf_regressor, param_grid\u001b[38;5;241m=\u001b[39mparam_grid, cv\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, scoring\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mneg_mean_squared_error\u001b[39m\u001b[38;5;124m'\u001b[39m, n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 26\u001b[0m \u001b[43mgrid_search\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Get the best hyperparameters\u001b[39;00m\n\u001b[1;32m     29\u001b[0m best_params \u001b[38;5;241m=\u001b[39m grid_search\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:874\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    868\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[1;32m    869\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[1;32m    870\u001b[0m     )\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[0;32m--> 874\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[1;32m    878\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:1388\u001b[0m, in \u001b[0;36mGridSearchCV._run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1386\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[1;32m   1387\u001b[0m     \u001b[38;5;124;03m\"\"\"Search all candidates in param_grid\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1388\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\u001b[43mParameterGrid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_grid\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/model_selection/_search.py:821\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    814\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\n\u001b[1;32m    815\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFitting \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m folds for each of \u001b[39m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;124m candidates,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    816\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m totalling \u001b[39m\u001b[38;5;132;01m{2}\u001b[39;00m\u001b[38;5;124m fits\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    817\u001b[0m             n_splits, n_candidates, n_candidates \u001b[38;5;241m*\u001b[39m n_splits\n\u001b[1;32m    818\u001b[0m         )\n\u001b[1;32m    819\u001b[0m     )\n\u001b[0;32m--> 821\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_score\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    823\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase_estimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m        \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    826\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    827\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    828\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparameters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mparameters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    829\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_splits\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcandidate_progress\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_candidates\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    831\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_and_score_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    832\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcand_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43msplit_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mproduct\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    834\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcandidate_params\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgroups\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    835\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    836\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    838\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    839\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    840\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo fits were performed. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    841\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWas the CV iterator empty? \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    842\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mWere there no candidates?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    843\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/sklearn/utils/parallel.py:63\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m     58\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[1;32m     59\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m     60\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[1;32m     62\u001b[0m )\n\u001b[0;32m---> 63\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:1061\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1058\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterating \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1061\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mretrieve\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1062\u001b[0m \u001b[38;5;66;03m# Make sure that we get a last message telling us we are done\u001b[39;00m\n\u001b[1;32m   1063\u001b[0m elapsed_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_time\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/parallel.py:938\u001b[0m, in \u001b[0;36mParallel.retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    937\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msupports_timeout\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 938\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(\u001b[43mjob\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    939\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    940\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_output\u001b[38;5;241m.\u001b[39mextend(job\u001b[38;5;241m.\u001b[39mget())\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/site-packages/joblib/_parallel_backends.py:542\u001b[0m, in \u001b[0;36mLokyBackend.wrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m\"\"\"Wrapper for Future.result to implement the same behaviour as\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03mAsyncResults.get from multiprocessing.\"\"\"\u001b[39;00m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 542\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfuture\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    543\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m CfTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    544\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/concurrent/futures/_base.py:453\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[1;32m    451\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__get_result()\n\u001b[0;32m--> 453\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_condition\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;129;01min\u001b[39;00m [CANCELLED, CANCELLED_AND_NOTIFIED]:\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.10/threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:    \u001b[38;5;66;03m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[1;32m    319\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 320\u001b[0m         \u001b[43mwaiter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m         gotit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    322\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Assuming 'days_to_default' is your target variable\n",
    "X = train_dataset.drop(columns=['days_to_default', 'target'])\n",
    "y = train_dataset['days_to_default']\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create a Random Forest Regressor\n",
    "rf_regressor = RandomForestRegressor()\n",
    "\n",
    "# Define the hyperparameters grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['auto', 'sqrt', 'log2']\n",
    "}\n",
    "\n",
    "# Perform GridSearchCV for hyperparameter tuning\n",
    "grid_search = GridSearchCV(estimator=rf_regressor, param_grid=param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "# Train the model with the best hyperparameters\n",
    "best_rf_regressor = RandomForestRegressor(**best_params)\n",
    "best_rf_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred_rf = best_rf_regressor.predict(X_test)\n",
    "\n",
    "# Calculate Mean Squared Error (MSE) as a metric\n",
    "mse = mean_squared_error(y_test, y_pred_rf)\n",
    "print(\"Mean Squared Error:\", mse)\n",
    "print(\"Best Hyperparameters:\", best_params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE in KNN: 19985.281\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(train_dataset.drop(columns='days_to_default'))\n",
    "\n",
    "# Standardize the target variable Y\n",
    "Y = train_dataset['days_to_default']\n",
    "scaler_Y = StandardScaler()\n",
    "Y_scaled = scaler_Y.fit_transform(Y.values.reshape(-1, 1))\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scaled, Y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the KNeighborsRegressor\n",
    "knn_regressor = KNeighborsRegressor(n_neighbors=5)  # You can adjust the number of neighbors as needed\n",
    "\n",
    "# Train the model\n",
    "knn_regressor.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred_knn = knn_regressor.predict(X_test)\n",
    "\n",
    "# Calculate RMSE (Root Mean Squared Error)\n",
    "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
    "print(\"MSE in KNN:\", mse_knn)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-process Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = pd.read_csv(\"../Dataset_DAY1/Data/test_set.csv\", delimiter=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>application_ID</th>\n",
       "      <th>decision_date</th>\n",
       "      <th>company_ID</th>\n",
       "      <th>external_score_ver01</th>\n",
       "      <th>external_score_ver02</th>\n",
       "      <th>late_payment_score</th>\n",
       "      <th>external_score_late_payment_integrated</th>\n",
       "      <th>external_score_moderate</th>\n",
       "      <th>external_score_adverse</th>\n",
       "      <th>external_score_ver03</th>\n",
       "      <th>...</th>\n",
       "      <th>max_rel_used_a_scadenza</th>\n",
       "      <th>last_rel_used_a_scadenza</th>\n",
       "      <th>avg_count_enti_affidanti</th>\n",
       "      <th>std_count_enti_affidanti</th>\n",
       "      <th>max_count_enti_affidanti</th>\n",
       "      <th>last_count_enti_affidanti</th>\n",
       "      <th>avg_count_numero_prima_info</th>\n",
       "      <th>std_count_numero_prima_info</th>\n",
       "      <th>max_count_numero_prima_info</th>\n",
       "      <th>last_count_numero_prima_info</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>a1Q7R00000ZWFXwUAP</td>\n",
       "      <td>2020-10-12</td>\n",
       "      <td>1321219660</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>D</td>\n",
       "      <td>...</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,32464142538975</td>\n",
       "      <td>1,16666666666667</td>\n",
       "      <td>0,389249472080761</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a1Q7R00000ZWJX2UAP</td>\n",
       "      <td>2020-11-12</td>\n",
       "      <td>1420617490</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a1Q7R00000a3E9nUAE</td>\n",
       "      <td>2021-07-05</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I</td>\n",
       "      <td>...</td>\n",
       "      <td>0,33222009569378</td>\n",
       "      <td>0,320196172248804</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>a1Q7R00000ZWRR6UAP</td>\n",
       "      <td>2021-01-19</td>\n",
       "      <td>137667970</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0,162240829346092</td>\n",
       "      <td>0,126861244019139</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1,91666666666667</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a1Q7R00000g6DWvUAM</td>\n",
       "      <td>2022-05-09</td>\n",
       "      <td>2412739090</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>F</td>\n",
       "      <td>...</td>\n",
       "      <td>0,478388926862611</td>\n",
       "      <td>0,356901572112098</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2,08333333333333</td>\n",
       "      <td>0,288675134594813</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       application_ID decision_date  company_ID  external_score_ver01  \\\n",
       "0  a1Q7R00000ZWFXwUAP    2020-10-12  1321219660                     5   \n",
       "1  a1Q7R00000ZWJX2UAP    2020-11-12  1420617490                     8   \n",
       "2  a1Q7R00000a3E9nUAE    2021-07-05   137667970                     8   \n",
       "3  a1Q7R00000ZWRR6UAP    2021-01-19   137667970                     8   \n",
       "4  a1Q7R00000g6DWvUAM    2022-05-09  2412739090                     6   \n",
       "\n",
       "   external_score_ver02  late_payment_score  \\\n",
       "0                     1                 8.0   \n",
       "1                     1                 NaN   \n",
       "2                     1                 NaN   \n",
       "3                     1                 NaN   \n",
       "4                     1                 NaN   \n",
       "\n",
       "   external_score_late_payment_integrated  external_score_moderate  \\\n",
       "0                                     5.0                      6.0   \n",
       "1                                     NaN                      NaN   \n",
       "2                                     NaN                      NaN   \n",
       "3                                     NaN                      NaN   \n",
       "4                                     NaN                      NaN   \n",
       "\n",
       "   external_score_adverse external_score_ver03  ...  max_rel_used_a_scadenza  \\\n",
       "0                     7.0                    D  ...         1,32464142538975   \n",
       "1                     NaN                    F  ...                        0   \n",
       "2                     NaN                    I  ...         0,33222009569378   \n",
       "3                     NaN                    F  ...        0,162240829346092   \n",
       "4                     NaN                    F  ...        0,478388926862611   \n",
       "\n",
       "  last_rel_used_a_scadenza avg_count_enti_affidanti std_count_enti_affidanti  \\\n",
       "0         1,32464142538975         1,16666666666667        0,389249472080761   \n",
       "1                        0                        1                        0   \n",
       "2        0,320196172248804                        3                        0   \n",
       "3        0,126861244019139                        3                        0   \n",
       "4        0,356901572112098                        3                        0   \n",
       "\n",
       "  max_count_enti_affidanti last_count_enti_affidanti  \\\n",
       "0                        2                         2   \n",
       "1                        1                         1   \n",
       "2                        3                         3   \n",
       "3                        3                         3   \n",
       "4                        3                         3   \n",
       "\n",
       "  avg_count_numero_prima_info std_count_numero_prima_info  \\\n",
       "0            1,08333333333333           0,288675134594813   \n",
       "1                           1                           0   \n",
       "2            1,91666666666667           0,288675134594813   \n",
       "3            1,91666666666667           0,288675134594813   \n",
       "4            2,08333333333333           0,288675134594813   \n",
       "\n",
       "  max_count_numero_prima_info last_count_numero_prima_info  \n",
       "0                           2                            1  \n",
       "1                           1                            1  \n",
       "2                           2                            2  \n",
       "3                           2                            2  \n",
       "4                           3                            3  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Drop_unneed_columns(test_dataset)\n",
    "test_dataset = test_dataset.drop(columns=drop_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_dics[\"juridical_form\"][\"SS\"] = 15\n",
    "category_dics[\"juridical_form\"][\"OS\"] = 16\n",
    "for k,v in category_dics.items():\n",
    "    test_dataset.replace({k:v}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'MISSING' in the column: external_score_ver03\n",
      "'MISSING' in the column: province\n",
      "'MISSING' in the column: region\n",
      "'MISSING' in the column: geo_area\n"
     ]
    }
   ],
   "source": [
    "# find columns with MISSING values \n",
    "columns = []\n",
    "for column in list(test_dataset.columns):\n",
    "    # Check if there is a value \"MISSING\" in the 'column_name' column\n",
    "    missing_values = test_dataset[column] == 'MISSING'\n",
    "\n",
    "    # Check if any row contains the value \"MISSING\" in the specified column\n",
    "    if missing_values.any():\n",
    "        print(f\"'MISSING' in the column: {column}\")\n",
    "        columns.append(column)\n",
    "\n",
    "# Sum values in the specified columns\n",
    "dic = {}\n",
    "for column in columns:\n",
    "    column_name = column\n",
    "\n",
    "    count = 0\n",
    "    sum_values = 0\n",
    "    # Iterate over the DataFrame\n",
    "    for index, row in test_dataset.iterrows():\n",
    "        # Access the value of the specified column for each row\n",
    "        count +=1\n",
    "        if isinstance(row[column_name], str):\n",
    "            continue\n",
    "        elif isinstance(row[column_name], int):\n",
    "            sum_values += row[column_name]\n",
    "    \n",
    "    dic[column] = int(sum_values/count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Replace_missing_test(dataset,val, column):\n",
    "    # Assuming df is your DataFrame and 'column_to_change' is the column you want to change\n",
    "    # 'condition_column' is the column based on which you want to change the content\n",
    "    dataset.loc[(dataset[column] == 'MISSING'), column] = val\n",
    "\n",
    "\n",
    "    # For example, if you want to change the content of 'column_to_change' to 'new_value' where 'condition_column' is True\n",
    "    # Replace 'new_value', 'column_to_change', and 'condition_column' with your actual values\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in dic.items():\n",
    "    test_dataset = Replace_missing_test(test_dataset,v,k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_dataset = Replace_bool_toNumbers(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "external_score_ver01                      int64\n",
      "external_score_ver02                      int64\n",
      "external_score_ver03                      int64\n",
      "age                                       int64\n",
      "province                                  int64\n",
      "juridical_form                            int64\n",
      "industry_sector                           int64\n",
      "gross_margin_ratio                       object\n",
      "core_income_ratio                        object\n",
      "cash_asset_ratio                         object\n",
      "consolidated_liabilities_ratio           object\n",
      "tangible_assets_ratio                    object\n",
      "revenues                                 object\n",
      "cr_available                              int64\n",
      "region                                    int64\n",
      "geo_area                                  int64\n",
      "last_statement_age                        int64\n",
      "overrun_freq_a_revoca_autoliquidanti     object\n",
      "avg_tension_a_revoca_autoliquidanti      object\n",
      "std_tension_a_revoca_autoliquidanti      object\n",
      "max_tension_a_revoca_autoliquidanti      object\n",
      "last_tension_a_revoca_autoliquidanti     object\n",
      "avg_rel_used_a_revoca_autoliquidanti     object\n",
      "std_rel_used_a_revoca_autoliquidanti     object\n",
      "max_rel_used_a_revoca_autoliquidanti     object\n",
      "last_rel_used_a_revoca_autoliquidanti    object\n",
      "overrun_freq_a_scadenza                  object\n",
      "avg_rel_used_a_scadenza                  object\n",
      "std_rel_used_a_scadenza                  object\n",
      "max_rel_used_a_scadenza                  object\n",
      "last_rel_used_a_scadenza                 object\n",
      "avg_count_enti_affidanti                 object\n",
      "std_count_enti_affidanti                 object\n",
      "max_count_enti_affidanti                  int64\n",
      "last_count_enti_affidanti                 int64\n",
      "avg_count_numero_prima_info              object\n",
      "std_count_numero_prima_info              object\n",
      "max_count_numero_prima_info               int64\n",
      "last_count_numero_prima_info              int64\n",
      "dtype: object\n",
      "DataFrame does not contain any NaN values.\n"
     ]
    }
   ],
   "source": [
    "## normalise test dataset \n",
    "def normalized_tdata(dataset):\n",
    "    # Replace commas with periods in all columns\n",
    "    dataset = dataset.replace(',', '.', regex=True)\n",
    "    print(dataset.dtypes)\n",
    "    dataset = dataset.astype('float32')\n",
    "\n",
    "    # check if the dataset has any nan value\n",
    "    has_nan_values = dataset.isna().any().any()\n",
    "\n",
    "    if has_nan_values:\n",
    "        print(\"DataFrame contains NaN values.\")\n",
    "    else:\n",
    "        print(\"DataFrame does not contain any NaN values.\")\n",
    "\n",
    "    return dataset\n",
    "\n",
    "test_dataset = normalized_tdata(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10678, 39)\n"
     ]
    }
   ],
   "source": [
    "test_dataset.head()\n",
    "print(test_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> SVM Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standardize the features (mean=0 and variance=1)\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "\n",
    "# Create PCA object\n",
    "pca = PCA(n_components=30)  # Specify the number of components (desired dimensionality)\n",
    "\n",
    "# Fit PCA to the standardized data and transform the data\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# Accuracy score on test data\n",
    "X_test_prediction_final = regressor.predict(X_pca)\n",
    "\n",
    "\n",
    "\n",
    "# Assuming X_test_prediction_final contains your predictions\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_SVM = pd.DataFrame(X_test_prediction_final_int)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_SVM.to_csv('predictions_rg_SVM.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"yellow\"> Random Forest Predictions  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(test_dataset)\n",
    "#print(X_scaled)\n",
    "\n",
    "# Predict on the scaled test data\n",
    "X_test_prediction_final = rf_regressor.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to integers\n",
    "X_test_prediction_final_int = X_test_prediction_final.astype(int)\n",
    "\n",
    "# Create a DataFrame with the integer predictions\n",
    "predictions_RF = pd.DataFrame(X_test_prediction_final_int)\n",
    "\n",
    "# Write the DataFrame to a CSV file\n",
    "predictions_RF.to_csv('predictions_rg_rf.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
